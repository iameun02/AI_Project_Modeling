{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-active",
   "metadata": {},
   "source": [
    "# ke-t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-tribe",
   "metadata": {},
   "source": [
    "## 0. pip 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-security",
   "metadata": {},
   "source": [
    "### pip upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adopted-anthropology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ubuntu/anaconda3/lib/python3.7/site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 19.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-23.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "functional-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- -------------------\n",
      "absl-py                            1.4.0\n",
      "alabaster                          0.7.12\n",
      "anaconda-client                    1.7.2\n",
      "anaconda-project                   0.9.1\n",
      "anyio                              3.3.0\n",
      "appdirs                            1.4.4\n",
      "argh                               0.26.2\n",
      "argon2-cffi                        20.1.0\n",
      "asn1crypto                         1.4.0\n",
      "astroid                            2.5\n",
      "astropy                            4.2\n",
      "astunparse                         1.6.3\n",
      "async-generator                    1.10\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              20.3.0\n",
      "autopep8                           1.5.5\n",
      "autovizwidget                      0.19.1\n",
      "Babel                              2.9.0\n",
      "backcall                           0.2.0\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "beautifulsoup4                     4.9.3\n",
      "bitarray                           1.6.3\n",
      "bkcharts                           0.2\n",
      "black                              19.10b0\n",
      "bleach                             3.3.0\n",
      "bokeh                              2.2.3\n",
      "boto                               2.49.0\n",
      "boto3                              1.18.34\n",
      "botocore                           1.21.34\n",
      "Bottleneck                         1.3.2\n",
      "brotlipy                           0.7.0\n",
      "cachetools                         5.3.0\n",
      "certifi                            2020.12.5\n",
      "cffi                               1.14.0\n",
      "chardet                            3.0.4\n",
      "charset-normalizer                 2.0.4\n",
      "click                              7.1.2\n",
      "cloudpickle                        1.6.0\n",
      "clyent                             1.2.2\n",
      "colorama                           0.4.4\n",
      "conda                              4.8.4\n",
      "conda-package-handling             1.7.0\n",
      "contextlib2                        0.6.0.post1\n",
      "coverage                           5.5\n",
      "cryptography                       3.4.8\n",
      "cycler                             0.10.0\n",
      "Cython                             0.29.22\n",
      "cytoolz                            0.11.0\n",
      "dask                               2021.2.0\n",
      "decorator                          4.4.2\n",
      "defusedxml                         0.6.0\n",
      "diff-match-patch                   20200713\n",
      "dill                               0.3.4\n",
      "distributed                        2021.2.0\n",
      "docutils                           0.16\n",
      "entrypoints                        0.3\n",
      "environment-kernels                1.1.1\n",
      "et-xmlfile                         1.0.1\n",
      "fastcache                          1.1.0\n",
      "filelock                           3.0.12\n",
      "flake8                             3.8.4\n",
      "Flask                              1.1.2\n",
      "Flask-Cors                         3.0.10\n",
      "flatbuffers                        23.3.3\n",
      "fsspec                             0.8.3\n",
      "future                             0.18.2\n",
      "gast                               0.4.0\n",
      "gevent                             21.1.1\n",
      "glob2                              0.7\n",
      "gmpy2                              2.0.8\n",
      "google-auth                        2.17.3\n",
      "google-auth-oauthlib               0.4.6\n",
      "google-pasta                       0.2.0\n",
      "greenlet                           1.0.0\n",
      "grpcio                             1.54.0\n",
      "h5py                               2.10.0\n",
      "hdijupyterutils                    0.19.1\n",
      "HeapDict                           1.0.1\n",
      "html5lib                           1.1\n",
      "huggingface-hub                    0.14.1\n",
      "idna                               2.9\n",
      "imagecodecs                        2021.1.11\n",
      "imageio                            2.9.0\n",
      "imagesize                          1.2.0\n",
      "importlib-metadata                 6.6.0\n",
      "iniconfig                          1.1.1\n",
      "intervaltree                       3.1.0\n",
      "ipykernel                          5.3.4\n",
      "ipython                            7.20.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         7.6.3\n",
      "isort                              5.7.0\n",
      "itsdangerous                       1.1.0\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.17.2\n",
      "jeepney                            0.6.0\n",
      "Jinja2                             2.11.3\n",
      "jmespath                           0.10.0\n",
      "joblib                             1.0.1\n",
      "json5                              0.9.5\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     6.1.7\n",
      "jupyter-console                    6.2.0\n",
      "jupyter-core                       4.7.1\n",
      "jupyter-server                     1.10.2\n",
      "jupyterlab                         3.1.10\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab-server                  2.7.2\n",
      "jupyterlab-widgets                 1.0.0\n",
      "keras                              2.11.0\n",
      "keyring                            22.0.1\n",
      "kiwisolver                         1.3.1\n",
      "lazy-object-proxy                  1.5.2\n",
      "libarchive-c                       2.9\n",
      "libclang                           16.0.0\n",
      "llvmlite                           0.34.0\n",
      "locket                             0.2.1\n",
      "lxml                               4.6.3\n",
      "Markdown                           3.4.3\n",
      "MarkupSafe                         1.1.1\n",
      "matplotlib                         3.3.4\n",
      "mccabe                             0.6.1\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.2.1\n",
      "mkl-random                         1.1.1\n",
      "mkl-service                        2.3.0\n",
      "mock                               4.0.3\n",
      "more-itertools                     8.7.0\n",
      "mpmath                             1.1.0\n",
      "msgpack                            1.0.2\n",
      "multipledispatch                   0.6.0\n",
      "multiprocess                       0.70.12.2\n",
      "mypy-extensions                    0.4.3\n",
      "nbclassic                          0.3.1\n",
      "nbclient                           0.5.2\n",
      "nbconvert                          6.0.7\n",
      "nbformat                           5.1.2\n",
      "nest-asyncio                       1.5.1\n",
      "networkx                           2.5\n",
      "nltk                               3.5\n",
      "nose                               1.3.7\n",
      "notebook                           6.4.3\n",
      "numba                              0.51.2\n",
      "numexpr                            2.7.2\n",
      "numpy                              1.21.6\n",
      "numpydoc                           1.1.0\n",
      "oauthlib                           3.2.2\n",
      "olefile                            0.46\n",
      "opencv-python                      4.5.3.56\n",
      "openpyxl                           3.0.6\n",
      "opt-einsum                         3.3.0\n",
      "packaging                          20.9\n",
      "pandas                             1.2.2\n",
      "pandocfilters                      1.4.3\n",
      "parso                              0.7.0\n",
      "partd                              1.1.0\n",
      "path                               15.1.2\n",
      "pathlib2                           2.3.5\n",
      "pathos                             0.2.8\n",
      "pathspec                           0.7.0\n",
      "pathtools                          0.1.2\n",
      "patsy                              0.5.1\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             8.3.1\n",
      "pip                                23.1.2\n",
      "pkginfo                            1.7.0\n",
      "plotly                             5.3.1\n",
      "pluggy                             0.13.1\n",
      "ply                                3.11\n",
      "pox                                0.3.0\n",
      "ppft                               1.6.6.4\n",
      "prometheus-client                  0.9.0\n",
      "prompt-toolkit                     3.0.8\n",
      "protobuf                           3.19.6\n",
      "protobuf3-to-dict                  0.1.5\n",
      "psutil                             5.8.0\n",
      "psycopg2                           2.7.5\n",
      "ptyprocess                         0.7.0\n",
      "py                                 1.10.0\n",
      "pyasn1                             0.5.0\n",
      "pyasn1-modules                     0.3.0\n",
      "pycodestyle                        2.6.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.20\n",
      "pycrypto                           2.6.1\n",
      "pycurl                             7.43.0.5\n",
      "pydocstyle                         5.1.1\n",
      "pyerfa                             1.7.2\n",
      "pyflakes                           2.2.0\n",
      "pygal                              2.4.0\n",
      "Pygments                           2.8.0\n",
      "pyinstrument                       3.4.2\n",
      "pyinstrument-cext                  0.2.4\n",
      "pykerberos                         1.2.1\n",
      "pylint                             2.7.0\n",
      "pyls-black                         0.4.6\n",
      "pyls-spyder                        0.3.2\n",
      "pyodbc                             4.0.0-unsupported\n",
      "pyOpenSSL                          19.1.0\n",
      "pyparsing                          2.4.7\n",
      "pyrsistent                         0.17.3\n",
      "PySocks                            1.7.1\n",
      "pytest                             6.2.2\n",
      "python-dateutil                    2.8.1\n",
      "python-jsonrpc-server              0.4.0\n",
      "python-language-server             0.36.2\n",
      "pytz                               2021.1\n",
      "PyWavelets                         1.1.1\n",
      "pyxdg                              0.27\n",
      "PyYAML                             5.3.1\n",
      "pyzmq                              20.0.0\n",
      "QDarkStyle                         2.8.1\n",
      "QtAwesome                          1.0.1\n",
      "qtconsole                          5.0.2\n",
      "QtPy                               1.9.0\n",
      "regex                              2020.11.13\n",
      "requests                           2.26.0\n",
      "requests-kerberos                  0.12.0\n",
      "requests-oauthlib                  1.3.1\n",
      "requests-unixsocket                0.2.0\n",
      "rope                               0.18.0\n",
      "rsa                                4.9\n",
      "Rtree                              0.9.4\n",
      "ruamel_yaml                        0.15.87\n",
      "s3transfer                         0.5.0\n",
      "sagemaker                          2.59.0\n",
      "scikit-image                       0.17.2\n",
      "scikit-learn                       0.23.2\n",
      "scipy                              1.6.1\n",
      "seaborn                            0.11.1\n",
      "SecretStorage                      3.3.1\n",
      "Send2Trash                         1.5.0\n",
      "sentencepiece                      0.1.99\n",
      "setuptools                         46.4.0.post20200518\n",
      "shap                               0.39.0\n",
      "simplegeneric                      0.8.1\n",
      "singledispatch                     0.0.0\n",
      "six                                1.14.0\n",
      "slicer                             0.0.7\n",
      "smdebug                            1.0.12\n",
      "smdebug-rulesconfig                1.0.1\n",
      "sniffio                            1.2.0\n",
      "snowballstemmer                    2.1.0\n",
      "sortedcollections                  2.1.0\n",
      "sortedcontainers                   2.3.0\n",
      "soupsieve                          2.2\n",
      "sparkmagic                         0.15.0\n",
      "Sphinx                             3.5.1\n",
      "sphinxcontrib-applehelp            1.0.2\n",
      "sphinxcontrib-devhelp              1.0.2\n",
      "sphinxcontrib-htmlhelp             1.0.3\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.3\n",
      "sphinxcontrib-serializinghtml      1.1.4\n",
      "sphinxcontrib-websupport           1.2.4\n",
      "spyder                             4.2.1\n",
      "spyder-kernels                     1.10.2\n",
      "SQLAlchemy                         1.3.23\n",
      "statsmodels                        0.12.2\n",
      "sympy                              1.7.1\n",
      "tables                             3.6.1\n",
      "tblib                              1.7.0\n",
      "tenacity                           8.0.1\n",
      "tensorboard                        2.11.2\n",
      "tensorboard-data-server            0.6.1\n",
      "tensorboard-plugin-wit             1.8.1\n",
      "tensorflow                         2.11.0\n",
      "tensorflow-estimator               2.11.0\n",
      "tensorflow-hub                     0.13.0\n",
      "tensorflow-io-gcs-filesystem       0.32.0\n",
      "tensorflow-text                    2.11.0\n",
      "termcolor                          2.3.0\n",
      "terminado                          0.9.2\n",
      "testpath                           0.4.4\n",
      "textdistance                       4.2.1\n",
      "threadpoolctl                      2.1.0\n",
      "three-merge                        0.1.1\n",
      "tifffile                           2021.1.14\n",
      "tokenizers                         0.13.3\n",
      "toml                               0.10.1\n",
      "toolz                              0.11.1\n",
      "tornado                            6.1\n",
      "tqdm                               4.46.0\n",
      "traitlets                          5.0.5\n",
      "transformers                       4.28.1\n",
      "typed-ast                          1.4.2\n",
      "typing-extensions                  3.7.4.3\n",
      "ujson                              4.0.2\n",
      "unicodecsv                         0.14.1\n",
      "urllib3                            1.26.6\n",
      "watchdog                           1.0.2\n",
      "wcwidth                            0.2.5\n",
      "webencodings                       0.5.1\n",
      "websocket-client                   1.2.1\n",
      "Werkzeug                           1.0.1\n",
      "wheel                              0.34.2\n",
      "widgetsnbextension                 3.5.1\n",
      "wrapt                              1.12.1\n",
      "wurlitzer                          2.0.1\n",
      "xlrd                               2.0.1\n",
      "XlsxWriter                         1.3.7\n",
      "xlwt                               1.3.0\n",
      "yapf                               0.30.0\n",
      "zict                               2.0.0\n",
      "zipp                               3.4.0\n",
      "zope.event                         4.5.0\n",
      "zope.interface                     5.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-spectacular",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-artist",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "continuing-ozone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 17.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: dataclasses in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 113.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 106.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers) (4.62.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers) (4.8.3)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers) (2.26.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=23ffc73ed35e3534fff109e0c2091e9232de1318f690ddad33ab62cedbf0138e\n",
      "  Stored in directory: /home/lab01/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "genuine-license",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.18.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-ethnic",
   "metadata": {},
   "source": [
    "### sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "military-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in /home/ubuntu/anaconda3/lib/python3.7/site-packages (4.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (1.19.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (20.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (2020.11.13)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.0.12)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (4.46.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (2.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.14.1)\n",
      "Requirement already satisfied: protobuf<=3.20.2 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.15.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (0.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from packaging>=20.0->transformers[sentencepiece]) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from protobuf<=3.20.2->transformers[sentencepiece]) (1.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from importlib-metadata->transformers[sentencepiece]) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (2.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (1.26.6)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers[sentencepiece]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-collins",
   "metadata": {},
   "source": [
    "### 파이 토치 설치를 위한 버젼확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-removal",
   "metadata": {},
   "source": [
    "Ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dirty-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.142.00  Wed Jun 16 11:29:20 UTC 2021\r\n",
      "GCC version:  gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04) \r\n"
     ]
    }
   ],
   "source": [
    "cat /proc/driver/nvidia/version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-abuse",
   "metadata": {},
   "source": [
    "nvidia GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "weekly-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  8 11:28:05 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   27C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-allowance",
   "metadata": {},
   "source": [
    "Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rolled-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version 10.0.130\r\n"
     ]
    }
   ],
   "source": [
    "cat /usr/local/cuda/version.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-burden",
   "metadata": {},
   "source": [
    "CUDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "utility-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#define CUDNN_MAJOR 7\r\n",
      "#define CUDNN_MINOR 5\r\n",
      "#define CUDNN_PATCHLEVEL 1\r\n",
      "--\r\n",
      "#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n",
      "\r\n",
      "#include \"driver_types.h\"\r\n"
     ]
    }
   ],
   "source": [
    "cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-blogger",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "silver-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - pytorch-cuda=10.0.130\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/pytorch/linux-64\n",
      "  - https://conda.anaconda.org/pytorch/noarch\n",
      "  - https://conda.anaconda.org/nvidia/linux-64\n",
      "  - https://conda.anaconda.org/nvidia/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision torchaudio pytorch-cuda=10.0.130 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-choice",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rolled-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "\u001b[K     |████████████████████▊           | 297.0 MB 128.6 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 458.3 MB 2.6 kB/s \n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 74.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 100.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 71.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 84.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 117.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.15.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cached-property in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 101.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 66.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.0.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 109.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 13.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (49.6.0.post20210108)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 111.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.4.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 5.7 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.1)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 113.6 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=ccb5bf138b51a9f79920724ab870ebbe5e97d172340efae706e75ee0b61967c6\n",
      "  Stored in directory: /home/lab01/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=212bcb03e8478c05494500a49e0686bbabda718252d8e90aa7f06487d63ea8e9\n",
      "  Stored in directory: /home/lab01/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.7.0\n",
      "    Uninstalling importlib-metadata-3.7.0:\n",
      "      Successfully uninstalled importlib-metadata-3.7.0\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-4.2.4 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 importlib-metadata-4.8.3 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.7 oauthlib-3.2.2 opt-einsum-3.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-train",
   "metadata": {},
   "source": [
    "정상설치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "convertible-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-10 12:33:26.959798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 12:33:32.689743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 12:33:32.690457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 12:33:32.691394: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 12:33:32.691722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 12:33:32.692351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 12:33:32.692905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 12:33:34.814926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 12:33:34.815537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 12:33:34.816096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-10 12:33:34.816622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13803 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "tf.Tensor(829.4397, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-tiger",
   "metadata": {},
   "source": [
    "### Tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "active-release",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (2.6.2)\n",
      "Requirement already satisfied: tensorflow_text in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (2.6.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: clang~=5.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.48.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow_text) (0.13.0)\n",
      "Requirement already satisfied: cached-property in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-wesley",
   "metadata": {},
   "source": [
    "## 2. 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opened-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import tensorflow_hub as hub\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-cotton",
   "metadata": {},
   "source": [
    "## 3. 모델 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-frontier",
   "metadata": {},
   "source": [
    "### 1. Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-kuwait",
   "metadata": {},
   "source": [
    "1) 허깅페이스 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-effectiveness",
   "metadata": {},
   "source": [
    "pre-trained model : \"KETI-AIR/ke-t5-large-newslike\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "juvenile-consequence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (4.18.0)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (5.4.1)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (2020.11.13)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (3.0.12)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (4.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (4.62.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (20.9)\n",
      "Requirement already satisfied: dataclasses in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (0.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (1.19.5)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: protobuf in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from transformers[sentencepiece]) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging>=20.0->transformers[sentencepiece]) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata->transformers[sentencepiece]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers[sentencepiece]) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers[sentencepiece]) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers[sentencepiece]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->transformers[sentencepiece]) (1.26.6)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers[sentencepiece]) (1.15.0)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from sacremoses->transformers[sentencepiece]) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "passive-leeds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (0.12.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excessive-planner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KETI-AIR/ke-t5-large-newslike were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "model = AutoModel.from_pretrained(\"KETI-AIR/ke-t5-large-newslike\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KETI-AIR/ke-t5-large-newslike\", use_fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-picnic",
   "metadata": {},
   "source": [
    "### 2. Down-stream Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-overhead",
   "metadata": {},
   "source": [
    "2-1. small version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "polyphonic-separate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/saved_model.pb\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/variables/\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/variables/variables.data-00001-of-00002\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/variables/variables.index\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/variables/variables.data-00000-of-00002\n"
     ]
    }
   ],
   "source": [
    "!tar -zxvf \"/home/lab01/t5.1.1.small.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-decade",
   "metadata": {},
   "source": [
    "2-2. Large Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "failing-making",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/saved_model.pb\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/variables/\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/variables/variables.data-00001-of-00002\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/variables/variables.index\n",
      "downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/variables/variables.data-00000-of-00002\n"
     ]
    }
   ],
   "source": [
    "!tar -zxvf \"/home/lab01/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-opposition",
   "metadata": {},
   "source": [
    "## 4-0. Sample Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlikely-guidance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'shared/embedding:0' shape=(64128, 512) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/rms_norm/scale:0' shape=(512,) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/q:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/k:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/v:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'shared/embedding:0' shape=(64128, 512) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/rms_norm/scale:0' shape=(512,) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/q:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/k:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/v:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'shared/embedding:0' shape=(64128, 512) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/rms_norm/scale:0' shape=(512,) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/q:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/k:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/v:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'shared/embedding:0' shape=(64128, 512) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/rms_norm/scale:0' shape=(512,) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/q:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/k:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'encoder/block_000/layer_000/SelfAttention/v:0' shape=(512, 384) dtype=bfloat16_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "['summarize_topic: “처음에는 ‘금방 끝나겠지’라고 생각했는데 어느덧 100일이 됐네요. 그동안 춥고 아프고 힘들었지만 인간으로서 대우를 받을 수만 있다면 끝까지 버틸 수 있습니다.” LG트윈타워 청소 노동자들이 고용승계를 주장하며 파업에 나선지 100일째를 하루 앞둔 24일 서울 여의도 LG트윈타워 앞 ‘행복한 고용승계 텐트촌’에서 만난 박상설(63)씨는 힘들었던 투쟁 과정을 회상하며 눈시울을 붉혔다. 박씨는 2017년부터 LG트윈타워에서 청소 노동을 했지만 지난 1월 1일부로 계약이 종료돼 직장을 떠났다. 자동차 소음과 불편한 잠자리로 텐트에서 매일 밤잠을 설치지만 투쟁을 포기할 수 없다고 한다. 그는 “LG가 그동안 사회적 책임과 정도경영을 강조해 왔기에 파업이 금방 끝날 줄 알았다”며 “버티지 못하고 점점 떠나는 동지들을 바라볼 때마다 마음이 아프지만 정당한 노동 권리를 인정받기 위해 끝까지 투쟁할 것”이라고 강조했다. 지난해 11월 26일부터 파업에 돌입한 청소 노동자들은 25일 파업 100일째를 맞는다. 건물 1층 로비에서 시위를 하던 25명의 청소 노동자들은 지난 22일부터 정문 앞 도보에 텐트촌을 설치하고 장소를 옮겼다. 파업 100일에 맞춰 25일까지 시민연대와 함께 텐트 100개를 설치하고 주·야간 연대 시위를 이어가겠다는 뜻에서다. 노동자들은 한 명이 간신히 누울 수 있는 크기의 텐트 안에서 딱딱한 시멘트 바닥에 몸을 기대 쪽잠을 청하고 있다. LG트윈타워를 관리하는 LG그룹 계열사 ‘에스엔아이코퍼레이션’은 지난해 말 ‘지수아이앤씨’와 청소 용역 계약을 끝내고 다른 업체와 새로 계약했다. 사측은 ‘품질 저하’를 이유로 들었다. 반면 노동자들은 2019년 노조를 결성하고 권리를 주장하기 시작하면서 사측 눈 밖에 났다고 주장한다. 그동안 업체가 변경되더라도 기존 업체 노동자들이 새 업체에 고용승계가 되는 게 관례였지만 새 업체는 고용승계를 보장할 수 없다고 밝혔다. 지난달까지 고용노동부 중재로 수차례 노사 교섭이 있었지만 상황은 달라지지 않았다. 사측은 대신 노동자들에게 다른 사업장에서 일을 하게 해주겠다고 권유했다. 하지만 노동자들은 노조를 인정하지 않는 대기업의 행태를 묵인한 채 사측의 권유에 따른다면 어느 사업장에서 일을 하던 똑같은 행태가 반복될 수밖에 없다고 목소리를 높인다. 때문에 반드시 LG트윈타워에서 정당한 권리를 인정받고 노동을 이어가야만 한다고 말한다. 이들은 구광모 LG그룹 회장이 나서 문제를 해결해야 한다고 주장한다. 이혜정 LG트윈타워 공동대책위원회 집행위원은 “구 회장이 책임있는 답변을 내놓을 때까지 시민사회 단위와 함께 결의를 담아 끝까지 텐트촌을 유지할 것”이라고 강조했다.']\n",
      "['LG트윈타워 청소 노동자들이 고용승계를 주장하며 파업에 나선지 100일째를 하루 앞둔 24일 서울 여의도 LG트윈타워 앞 ‘행복한 고용승계 텐트촌’에서 만난 박상설(63)씨는 힘들었던 투쟁 과정을 회상하며 눈물을 터뜨렸다. 지난해 11월 26일부터 파업에 돌입한 청소 노동자들은 25일 파업 100일째를 맞는다. 하지만 노동자들은 노조를 인정하지 않는 대기업의 행태를 묵인한 채 사측의 권유에 따라다면 어느 사업장에서 일을 하던 똑같은 행태가 반복될 수밖에 없다고 목소리를 높인다.']\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/lab01/downstream_exported/t5.1.1.small.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/'\n",
    "loaded = tf.saved_model.load(model_path)\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "\n",
    "# source: https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=081&aid=0003173411\n",
    "# press: 서울신문(www.seoul.co.kr)\n",
    "# author: 이주원 기자 starjuwon@seoul.co.kr\n",
    "input_str = \"\"\"“처음에는 ‘금방 끝나겠지’라고 생각했는데 어느덧 100일이 됐네요. \\\n",
    "그동안 춥고 아프고 힘들었지만 인간으로서 대우를 받을 수만 있다면 끝까지 버틸 수 있습니다.” \\\n",
    "LG트윈타워 청소 노동자들이 고용승계를 주장하며 파업에 나선지 100일째를 하루 앞둔 24일 \\\n",
    "서울 여의도 LG트윈타워 앞 ‘행복한 고용승계 텐트촌’에서 만난 박상설(63)씨는 힘들었던 투쟁 과정을 \\\n",
    "회상하며 눈시울을 붉혔다. 박씨는 2017년부터 LG트윈타워에서 청소 노동을 했지만 지난 1월 1일부로 \\\n",
    "계약이 종료돼 직장을 떠났다. 자동차 소음과 불편한 잠자리로 텐트에서 매일 밤잠을 설치지만 투쟁을 \\\n",
    "포기할 수 없다고 한다. 그는 “LG가 그동안 사회적 책임과 정도경영을 강조해 왔기에 파업이 금방 끝날 \\\n",
    "줄 알았다”며 “버티지 못하고 점점 떠나는 동지들을 바라볼 때마다 마음이 아프지만 정당한 노동 권리를 \\\n",
    "인정받기 위해 끝까지 투쟁할 것”이라고 강조했다. 지난해 11월 26일부터 파업에 돌입한 청소 \\\n",
    "노동자들은 25일 파업 100일째를 맞는다. 건물 1층 로비에서 시위를 하던 25명의 청소 노동자들은 지난 \\\n",
    "22일부터 정문 앞 도보에 텐트촌을 설치하고 장소를 옮겼다. 파업 100일에 맞춰 25일까지 시민연대와 \\\n",
    "함께 텐트 100개를 설치하고 주·야간 연대 시위를 이어가겠다는 뜻에서다. 노동자들은 한 명이 간신히 \\\n",
    "누울 수 있는 크기의 텐트 안에서 딱딱한 시멘트 바닥에 몸을 기대 쪽잠을 청하고 있다. LG트윈타워를 \\\n",
    "관리하는 LG그룹 계열사 ‘에스엔아이코퍼레이션’은 지난해 말 ‘지수아이앤씨’와 청소 용역 계약을 \\\n",
    "끝내고 다른 업체와 새로 계약했다. 사측은 ‘품질 저하’를 이유로 들었다. 반면 노동자들은 2019년 \\\n",
    "노조를 결성하고 권리를 주장하기 시작하면서 사측 눈 밖에 났다고 주장한다. 그동안 업체가 \\\n",
    "변경되더라도 기존 업체 노동자들이 새 업체에 고용승계가 되는 게 관례였지만 새 업체는 고용승계를 \\\n",
    "보장할 수 없다고 밝혔다. 지난달까지 고용노동부 중재로 수차례 노사 교섭이 있었지만 상황은 달라지지 \\\n",
    "않았다. 사측은 대신 노동자들에게 다른 사업장에서 일을 하게 해주겠다고 권유했다. 하지만 노동자들은 \\\n",
    "노조를 인정하지 않는 대기업의 행태를 묵인한 채 사측의 권유에 따른다면 어느 사업장에서 일을 하던 \\\n",
    "똑같은 행태가 반복될 수밖에 없다고 목소리를 높인다. 때문에 반드시 LG트윈타워에서 정당한 권리를 \\\n",
    "인정받고 노동을 이어가야만 한다고 말한다. 이들은 구광모 LG그룹 회장이 나서 문제를 해결해야 한다고 \\\n",
    "주장한다. 이혜정 LG트윈타워 공동대책위원회 집행위원은 “구 회장이 책임있는 답변을 내놓을 때까지 \\\n",
    "시민사회 단위와 함께 결의를 담아 끝까지 텐트촌을 유지할 것”이라고 강조했다.\"\"\"\n",
    "\n",
    "input_str_topic = \"summarize_topic: \" + input_str\n",
    "input_str_summary = \"summarize_summary: \" + input_str\n",
    "\n",
    "x = tf.constant([input_str_topic])\n",
    "\n",
    "result = infer(x)\n",
    "print([out.decode('utf-8') for out in result['inputs'].numpy()])\n",
    "print([out.decode('utf-8') for out in result['outputs'].numpy()])\n",
    "\n",
    "# summarize_topic\n",
    "# 'LG트윈타워 청소 노동자가 고용승계를 주장하며 파업에 나선지 100일째를 하루 앞둔 24일 서울 \\\n",
    "# 여의도 LG트윈타워 앞 ‘행복한 고용승계 텐트촌’에서 만난 박상설(63)씨는 힘들었던 투쟁 과정을 \\\n",
    "# 회상하며 눈시울을 붉혔다. 반면 노동자들은 2019년 노조를 결성하고 권리를 주장하기 시작하면서 사측 \\\n",
    "# 눈 밖에 났다고 주장한다. 때문에 반드시 LG트윈타워에서 정당한 권리를 인정받고 노동을 이어가야 \\\n",
    "# 한다고 말한다.\n",
    "\n",
    "# summarize_summary\n",
    "# 'LG트윈타워 청소 노동자가 고용승계를 주장하며 파업에 나선지 100일째를 맞았다. LG트윈타워를 \\\n",
    "# 관리하는 LG그룹 계열사 ‘에스엔아이코퍼레이션’은 지난해 말 ‘지수아이앤씨’와 청소 용역 계약을 \\\n",
    "# 끝내고 다른 업체와 새로 계약했다. 그러나 노동자들은 노조를 인정하지 않는 대기업의 행태를 묵인한 \\\n",
    "# 채 사측의 권유에 따라 노동을 이어가라고 주장한다.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-tuition",
   "metadata": {},
   "source": [
    "## 4-1. 모델적용 (Small Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "temporal-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summarize_topic: 소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다 지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다 소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다 최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다 워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다 연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다 1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다 2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다 일반 쥐의 고환 무게는 75mg 이상이지만, 바이러스에 감염된 쥐의 경우 50mg도 되지 않았다 3주 뒤 쥐의 고환 크기는 더욱 감소했으며 무게는 25mg 미만으로 줄어들었다 연구진은 고환을 구성하는 세포가 죽었고, 고환 내부의 구조도 손상된 것을 확인했다 수컷의 핵심 생식기관인 고환이 지카바이러스의 공격으로 점차 기능을 잃어간 것이다 고환은 생식세포인 정자와 성호르몬인 테스토스테론을 만드는 기관이다 지카바이러스에 감염된 쥐는 고환의 크기가 작을 뿐 아니라 정자 수와 성호르몬 수치도 정상에 비해 적었다 정자의 운동성도 현저히 감소했다 오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다 연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다 사람의 정자 속에서 지카바이러스가 발견된 적은 있다 또 지카바이러스는 정액 속에서 수개월을 산다고 알려졌다 이에 따라 세계보건기구(WHO)와 미국 질병예방통제센터(CDC)는 증상이 없더라도 지카 발생국가를 방문한 남성은 최소 6개월간 성관계 때 콘돔을 사용하라고 권고하고 있다']\n",
      "['지카바이러스는 태아에게 소두증을 유발한다고 알려진 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춘 연구들이 많았다 소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다 최근에는 미국, 동남아시아에서도 환자가 발생하고 있다']\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/lab01/downstream_exported/t5.1.1.small.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/'\n",
    "loaded = tf.saved_model.load(model_path)\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "\n",
    "# source: \n",
    "# press: \n",
    "# author: \n",
    "input_str = \"\"\" 소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다\n",
    "1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다\n",
    "지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다\n",
    "소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다\n",
    "최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다\n",
    "워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다\n",
    "연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다\n",
    "1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다\n",
    "2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다\n",
    "일반 쥐의 고환 무게는 75mg 이상이지만, 바이러스에 감염된 쥐의 경우 50mg도 되지 않았다\n",
    "3주 뒤 쥐의 고환 크기는 더욱 감소했으며 무게는 25mg 미만으로 줄어들었다\n",
    "연구진은 고환을 구성하는 세포가 죽었고, 고환 내부의 구조도 손상된 것을 확인했다\n",
    "수컷의 핵심 생식기관인 고환이 지카바이러스의 공격으로 점차 기능을 잃어간 것이다\n",
    "고환은 생식세포인 정자와 성호르몬인 테스토스테론을 만드는 기관이다\n",
    "지카바이러스에 감염된 쥐는 고환의 크기가 작을 뿐 아니라 정자 수와 성호르몬 수치도 정상에 비해 적었다\n",
    "정자의 운동성도 현저히 감소했다\n",
    "오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다\n",
    "연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다\n",
    "사람의 정자 속에서 지카바이러스가 발견된 적은 있다\n",
    "또 지카바이러스는 정액 속에서 수개월을 산다고 알려졌다\n",
    "이에 따라 세계보건기구(WHO)와 미국 질병예방통제센터(CDC)는 증상이 없더라도 지카 발생국가를 방문한 남성은 최소 6개월간 성관계 때 콘돔을 사용하라고 권고하고 있다\n",
    "\"\"\"\n",
    "input_str_topic = \"summarize_topic: \" + input_str\n",
    "input_str_summary = \"summarize_summary: \" + input_str\n",
    "\n",
    "x = tf.constant([input_str_topic])\n",
    "\n",
    "result = infer(x)\n",
    "print([out.decode('utf-8') for out in result['inputs'].numpy()])\n",
    "print([out.decode('utf-8') for out in result['outputs'].numpy()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-portrait",
   "metadata": {},
   "source": [
    "## 4-2. 모델적용 (Large Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sized-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['summarize_topic: 소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다 지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다 소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다 최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다 워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다 연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다 1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다 2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다 일반 쥐의 고환 무게는 75mg 이상이지만, 바이러스에 감염된 쥐의 경우 50mg도 되지 않았다 3주 뒤 쥐의 고환 크기는 더욱 감소했으며 무게는 25mg 미만으로 줄어들었다 연구진은 고환을 구성하는 세포가 죽었고, 고환 내부의 구조도 손상된 것을 확인했다 수컷의 핵심 생식기관인 고환이 지카바이러스의 공격으로 점차 기능을 잃어간 것이다 고환은 생식세포인 정자와 성호르몬인 테스토스테론을 만드는 기관이다 지카바이러스에 감염된 쥐는 고환의 크기가 작을 뿐 아니라 정자 수와 성호르몬 수치도 정상에 비해 적었다 정자의 운동성도 현저히 감소했다 오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다 연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다 사람의 정자 속에서 지카바이러스가 발견된 적은 있다 또 지카바이러스는 정액 속에서 수개월을 산다고 알려졌다 이에 따라 세계보건기구(WHO)와 미국 질병예방통제센터(CDC)는 증상이 없더라도 지카 발생국가를 방문한 남성은 최소 6개월간 성관계 때 콘돔을 사용하라고 권고하고 있다']\n",
      "['소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다 지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다 오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자 수와 성호르몬 수치도 정상에 비해 적었다.']\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/lab01/downstream_exported/t5.1.1.large.gin.ke.ke.newslike_v100_span_corruption.ke_t5_nikl_summary_mixture_equal/'\n",
    "loaded = tf.saved_model.load(model_path)\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "\n",
    "# source: \n",
    "# press: \n",
    "# author: \n",
    "input_str = \"\"\" 소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다\n",
    "1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다\n",
    "지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다\n",
    "소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다\n",
    "최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다\n",
    "워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다\n",
    "연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다\n",
    "1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다\n",
    "2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다\n",
    "일반 쥐의 고환 무게는 75mg 이상이지만, 바이러스에 감염된 쥐의 경우 50mg도 되지 않았다\n",
    "3주 뒤 쥐의 고환 크기는 더욱 감소했으며 무게는 25mg 미만으로 줄어들었다\n",
    "연구진은 고환을 구성하는 세포가 죽었고, 고환 내부의 구조도 손상된 것을 확인했다\n",
    "수컷의 핵심 생식기관인 고환이 지카바이러스의 공격으로 점차 기능을 잃어간 것이다\n",
    "고환은 생식세포인 정자와 성호르몬인 테스토스테론을 만드는 기관이다\n",
    "지카바이러스에 감염된 쥐는 고환의 크기가 작을 뿐 아니라 정자 수와 성호르몬 수치도 정상에 비해 적었다\n",
    "정자의 운동성도 현저히 감소했다\n",
    "오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다\n",
    "연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다\n",
    "사람의 정자 속에서 지카바이러스가 발견된 적은 있다\n",
    "또 지카바이러스는 정액 속에서 수개월을 산다고 알려졌다\n",
    "이에 따라 세계보건기구(WHO)와 미국 질병예방통제센터(CDC)는 증상이 없더라도 지카 발생국가를 방문한 남성은 최소 6개월간 성관계 때 콘돔을 사용하라고 권고하고 있다\n",
    "\"\"\"\n",
    "\n",
    "input_str_topic = \"summarize_topic: \" + input_str\n",
    "input_str_summary = \"summarize_summary: \" + input_str\n",
    "\n",
    "x = tf.constant([input_str_topic])\n",
    "\n",
    "result = infer(x)\n",
    "print([out.decode('utf-8') for out in result['inputs'].numpy()])\n",
    "print([out.decode('utf-8') for out in result['outputs'].numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-hampshire",
   "metadata": {},
   "source": [
    "## 5. Data for Performace Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-giving",
   "metadata": {},
   "source": [
    "https://github.com/theeluwin/sci-news-sum-kr-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "optional-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/theeluwin/sci-news-sum-kr-50.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precious-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번 전문 : \n",
      "소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다\n",
      "1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다\n",
      "지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다\n",
      "소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다\n",
      "최근에는 브라질 등 남미 뿐 아니라 미국, 동남아시아에서도 환자가 발생하고 있다\n",
      "워싱턴대 연구진은 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춰 연구를 진행했다\n",
      "연구진은 우선 수컷 쥐에게 지카바이러스를 감염시켰다\n",
      "1주가 지나자 생식기관인 고환에서도 바이러스가 발견됐다\n",
      "2주 뒤에는 수컷 쥐의 고환 크기가 현격하게 줄고 무게도 감소했다\n",
      "일반 쥐의 고환 무게는 75mg 이상이지만, 바이러스에 감염된 쥐의 경우 50mg도 되지 않았다\n",
      "3주 뒤 쥐의 고환 크기는 더욱 감소했으며 무게는 25mg 미만으로 줄어들었다\n",
      "연구진은 고환을 구성하는 세포가 죽었고, 고환 내부의 구조도 손상된 것을 확인했다\n",
      "수컷의 핵심 생식기관인 고환이 지카바이러스의 공격으로 점차 기능을 잃어간 것이다\n",
      "고환은 생식세포인 정자와 성호르몬인 테스토스테론을 만드는 기관이다\n",
      "지카바이러스에 감염된 쥐는 고환의 크기가 작을 뿐 아니라 정자 수와 성호르몬 수치도 정상에 비해 적었다\n",
      "정자의 운동성도 현저히 감소했다\n",
      "오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다\n",
      "연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다\n",
      "사람의 정자 속에서 지카바이러스가 발견된 적은 있다\n",
      "또 지카바이러스는 정액 속에서 수개월을 산다고 알려졌다\n",
      "이에 따라 세계보건기구(WHO)와 미국 질병예방통제센터(CDC)는 증상이 없더라도 지카 발생국가를 방문한 남성은 최소 6개월간 성관계 때 콘돔을 사용하라고 권고하고 있다\n",
      "1 번 Topic 문장 :\n",
      "소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다\n",
      "1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다\n",
      "오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다\n",
      "연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다\n",
      "2 번 전문 : \n",
      "러시아·미국·일본 우주인 3명이 지구로 돌아왔다\n",
      "국제우주정거장(ISS)에서 체류한지 115일 만이다\n",
      "러시아 모스크바 인근 우주비행통제센터는 30일(현지시간) 러시아 우주인 아나톨리 이바니쉰, 미국 여성 우주인 캐슬린 루빈스, 일본 우주인 오니시 다쿠야 등을 태운 소유스 우주선 귀환캡슐이 카자흐스탄 남동부 초원 지대에 무사히 착륙했다고 밝혔다\n",
      "7월 초 국제우주정거장(ISS)로 발사된 소유스 MS-01호\n",
      "우주인은 귀환 직후 수색구조팀에 발견돼 안전한 곳으로 후송됐다\n",
      "개량형 우주선 `소유스 MS-01`을 타고 지난 7월 지구를 떠난 우주인 3명은 우주정거장에서 40여가지 과학 실험을 수행했다\n",
      "우주 환경이 생체나 물질에 미치는 영향 등이 대표적이다\n",
      "첫 비행이었던 소유스 MS-01의 성능도 점검했다\n",
      "다음달 17일에도 우주인 3명이 ISS로 떠날 예정이다\n",
      "현재 ISS에는 러시아와 미국 우주인 3명이 남아있다\n",
      "2 번 Topic 문장 :\n",
      "러시아·미국·일본 우주인 3명이 지구로 돌아왔다\n",
      "러시아 모스크바 인근 우주비행통제센터는 30일(현지시간) 러시아 우주인 아나톨리 이바니쉰, 미국 여성 우주인 캐슬린 루빈스, 일본 우주인 오니시 다쿠야 등을 태운 소유스 우주선 귀환캡슐이 카자흐스탄 남동부 초원 지대에 무사히 착륙했다고 밝혔다\n",
      "개량형 우주선 `소유스 MS-01`을 타고 지난 7월 지구를 떠난 우주인 3명은 우주정거장에서 40여가지 과학 실험을 수행했다\n",
      "3 번 전문 : \n",
      "‘알록달록한 과녁 한가운데 이중나선 모양의 DNA가 꽂혀 있다\n",
      "기초과학연구원(IBS) 유전체교정 연구단이 제작한 이 일러스트는 크리스퍼 유전자 가위의 정확성을 비교한 그림이다\n",
      "유전 정보를 담은 DNA를 자르고 편집하는 유전자 가위는 최근 생명과학계에서 가장 주목받는 기술로 손꼽힌다\n",
      "2013년 처음 발표된 3세대 크리스퍼 유전자 가위(CRISPR-Cas9)가 등장한 데 이어 지난해 유전자 가위의 절단효소로 사용하는 Cas9을 대체할 새 단백질(Cpf1)을 찾아냈다\n",
      "이 신형 유전자 가위는 올초 기존 유전자 가위보다 정확도가 훨씬 높다는 사실이 입증됐다\n",
      "정확도가 떨어지는 과녁 바깥쪽 둘레 노란색 영역이 기존 유전자 가위를 뜻하고, 과녁 중심에 가까운 빨간색과 파란색 영역은 새 유전자 가위의 정확도를 뜻한다\n",
      "유전자 가위의 정확도를 다트게임으로 묘사한 이 그림은 지난 8월 국제학술지 네이처 바이오테크놀로지 표지를 장식했다\n",
      "시냅스뇌질환연구단이 촬영한 작품 '연못'은 생쥐 내측전전두엽에 있는 다양한 단백질을 색깔별로 나타낸다\n",
      "IBS가 오는 21일 개원 5주년을 기념해 최고의 과학 사진과 그림을 뽑는 ‘아트 인 사이언스’ 선정작을 공개했다\n",
      "지난해에 이어 두 번째로 열린 이번 공모전에는 IBS 산하 26개 연구단 연구원들이 한 해 동안 발견한 미시 세계의 신비한 사진과 컴퓨터가 만들어낸 예술 작품 같은 그림 16편이 선정됐다\n",
      "시냅스뇌질환연구단이 촬영한 작품 ‘연못’은 프랑스 인상주의 화가 클로드 모네가 그린 수련 그림을 떠올리게 한다\n",
      "생쥐 내측전전두엽에 존재하는 다양한 단백질이 빨간색(파브알부민)과 초록색(PTP델타), 파란색(DNA염색 단백질) 등 다채로운 색상의 수련처럼 보인다\n",
      "연구진은 “뇌에서 일어나는 다양하고 복잡한 현상을 표현하는 화려한 색의 단백질이 연못을 가득 채운 수련처럼 보인다”고 밝혔다\n",
      "초저온 진공 상태에서 티탄산 스트론튬 표면 위에 나타난 전자 밀도를 촬영한 '전자들의 비명'\n",
      "강상관계물질연구단은 극저온·초고진공 상태에서 티탄산스트론튬 표면에서 나타난 독특한 전자의 운동을 포착했다\n",
      "색깔별로 나타난 전자 밀도 차가 노르웨이 화가 에드바르트 뭉크의 대표작 ‘절규’에 등장하는 두 손을 얼굴에 모으고 비명을 지르는 주인공 모습 같다\n",
      "3 번 Topic 문장 :\n",
      "유전 정보를 담은 DNA를 자르고 편집하는 유전자 가위는 최근 생명과학계에서 가장 주목받는 기술로 손꼽힌다\n",
      "2013년 처음 발표된 3세대 크리스퍼 유전자 가위(CRISPR-Cas9)가 등장한 데 이어 지난해 유전자 가위의 절단효소로 사용하는 Cas9을 대체할 새 단백질(Cpf1)을 찾아냈다\n",
      "이 신형 유전자 가위는 올초 기존 유전자 가위보다 정확도가 훨씬 높다는 사실이 입증됐다\n",
      "지난해에 이어 두 번째로 열린 이번 공모전에는 IBS 산하 26개 연구단 연구원들이 한 해 동안 발견한 미시 세계의 신비한 사진과 컴퓨터가 만들어낸 예술 작품 같은 그림 16편이 선정됐다\n",
      "4 번 전문 : \n",
      "68년만에 지구에 가장 근접하는 `슈퍼문`을 14일 저녁에 볼 수 있다\n",
      "이날 하늘의 둥근 보름달을 놓치면 이 크기는 18년 후에나 다시 볼 수 있게 된다\n",
      "◇68년 만의 슈퍼문…서울에선 17시 29분부터 달 떠\n",
      "한국천문연구원은 14일 슈퍼문은 올해 가장 작았던 보름달(4월 22일)보다 약 14% 더 커보인다고 밝혔다\n",
      "이날 달이 더 크게 보이는 원리는 망(望)인 동시에 달이 지구와 가장 가까워지는 근지점을 통과해 달과 지구 거리가 짧아지기 때문이다\n",
      "망은 지구를 기준으로 해와 달이 정반대편에 위치할 때다\n",
      "음력 날짜로는 15일 즈음 해당한다\n",
      "슈퍼문은 달이 지구와 가까워지면서 볼 수 있다\n",
      "달이 지구를 도는 궤도는 타원형이라 달이 근지점을 지날 때 지구와 거리가 가까워진다\n",
      "11월 14일 달이 커 보이는 원리\n",
      "지구를 기준으로 태양과 달이 정반대편에 일직선으로 위치할 때 보름달을 볼 수 있으며, 타원 궤도를 도는 달이 근지점을 통과할 때 달이 더 커보인다\n",
      "추석 한가위에는 이번보다 덜 차오른 달을 볼 수 있었다\n",
      "달이 지구 주위를 타원궤도로 공전하기 때문에 태양 방향(합삭)에서 태양의 정 반대편(망)까지 가는데 더 많은 시간이 필요하다\n",
      "14일 달이 지구와 최고로 가까워지는 시각은 20시 21분경이다\n",
      "동쪽 하늘 고도 32도 부근에서 볼 수 있다\n",
      "이 시각 달과 지구의 거리는 35만6509㎞로 달과 지구의 평균거리인 38만4400㎞보다 가깝다\n",
      "올해 가장 큰달(2016.11.14.)과 작은달(2016.4.22.) 비교사진-큰달이 작은달보다 14% 더 크다\n",
      "망보다 더 거리가 가까웠거나 가장 근접한 날들은 1948년 1월 26일, 2034년 11월 26일이다\n",
      "이번보다 더 지구와 가까워진 달은 18년 후에나 다시 볼 수 있다\n",
      "달과 지구의 물리적인 거리가 조금 더 가까워지긴 하지만 달이 크게 보이는 데에는 대기의 상태나 주관적인 부분도 작용하기에 육안으로는 특별한 차이를 못 느낄 수 있다\n",
      "14일 달이 뜨는 시각은 서울 기준으로 17시 29분이며, 지는 시각은 15일 06시 16분이다\n",
      "◇지구의 그림자에 가려지는 개기월식은?\n",
      "월식은 달이 지구 그림자에 들어가는 현상이다\n",
      "즉, 지구가 달과 태양 사이에 위치해 지구 그림자에 달이 가려진다\n",
      "보름달일 때 생기며 지구가 밤인 곳에서는 어디서나 볼 수 있다\n",
      "달 궤도와 지구 궤도가 약 5도 기울어져 있어 보름달일 때도 월식이 일어나지 않는 경우가 있다\n",
      "달 전체가 가려지는 개기월식과 일부만 가려지는 부분월식으로 나뉜다\n",
      "지구 그림자에 달의 일부가 들어가면 부분월식이 일어난다\n",
      "달의 전부가 들어갈 때 개기월식이 일어난다\n",
      "달이 지구 그림자에 들어간다고 안보이는 것은 아니다\n",
      "월식의 원리\n",
      "개기월식이 일어날 때 달이 붉게 보인다\n",
      "지구 대기를 지난 빛이 굴절되며 달에 도달한다\n",
      "그런데 지구 대기를 지나면서 산란이 일어나 붉은 빛이 달에 도달하기 때문이다\n",
      "월식이 일어날 때마다 달의 붉은색이 조금씩 다르게 보이는데, 이를 통해 지구 대기의 상태를 확인 할 수 있다\n",
      "개기월식이 일어나면 달, 지구, 태양 순으로 일직선이 되므로 달에서는 지구 뒤로 태양이 지나가는 일식과 같은 현상을 볼 수 있다\n",
      "지구에서 보는 일식은 달과 태양의 겉보기 크기가 같아서 두 개가 똑같이 겹쳐진다\n",
      "달에서는 지구가 태양보다 훨씬 커보이기 때문에 토성-달 엄폐와 같이 태양이 지구 뒤를 지나가는 모습이 될 것이다\n",
      "커다란 지구 뒤로 작은 태양이 지나가게 돼 지구에서 보는 일식 보다 더 오래 진행된다\n",
      "◇개기일식은 달이 태양 가리는 것\n",
      "일식이란 달이 지구와 태양 사이를 지나면서 달이 태양을 가리는 현상이다\n",
      "달이 해의 전부를 가리는 현상은 개기일식이라 한다\n",
      "개기일식\n",
      "개기일식은 지구의 공전궤도면과 달의 공전궤도면이 약 5도 정도 기울어져 있어 항상 일어나는 현상은 아니다\n",
      "보통 4년에 세 번꼴로 일어나며 식이 일어나는 지역이 한정되므로 모든 지역에서 이 현상을 관측하기는 쉽지 않다\n",
      "개기일식은 태양 대기를 관측하는 천문학자에게 많은 정보를 얻을 수 있는 기회다\n",
      "태양 대기의 활동은 지구 상층 대기에 변화를 줘 우리 생활에 직접적으로 영향을 미친다\n",
      "태양의 대기를 관측할 때 개기일식과 코로나그래프(coronagraph)를 이용하곤 한다\n",
      "개기일식은 광구의 산란광 효과를 최소화시켜 태양의 대기를 정확하게 관측할 수 있다\n",
      "개기일식, 월식은 모두 과거에도 있던 현상이다\n",
      "고대 그리스 시대 아리스토텔레스는 월식을 관측하다가 달에 드리운 그림자가 지구의 그림자라는 것을 알아챘다\n",
      "그 그림자로 지구가 둥글다는 과학적인 주장을 내놓았다\n",
      "4 번 Topic 문장 :\n",
      "68년만에 지구에 가장 근접하는 `슈퍼문`을 14일 저녁에 볼 수 있다\n",
      "이날 달이 더 크게 보이는 원리는 망(望)인 동시에 달이 지구와 가장 가까워지는 근지점을 통과해 달과 지구 거리가 짧아지기 때문이다\n",
      "지구를 기준으로 태양과 달이 정반대편에 일직선으로 위치할 때 보름달을 볼 수 있으며, 타원 궤도를 도는 달이 근지점을 통과할 때 달이 더 커보인다\n",
      "월식은 달이 지구 그림자에 들어가는 현상이다\n",
      "개기월식이 일어날 때 달이 붉게 보인다\n",
      "일식이란 달이 지구와 태양 사이를 지나면서 달이 태양을 가리는 현상이다\n",
      "5 번 전문 : \n",
      "애니메이션에서나 볼 수 있었던 자동차 변신 로봇이 일본에서 실제로 만들어진다\n",
      "11일 소프트뱅크 계열 로봇 제조업체인 아스라테크(Asratec)와 산세이 테크놀로지, 브레이브 로보틱스가 3사 합작으로 변신 로봇 '제이 다이트 라이드(J-deite RIDE)'를 제작한다고 발표했다\n",
      "이 로봇은 아스라테크와 브레이브 로보틱스가 참여한 로봇 제조 계획 \"프로젝트 제이 다이트'의 일환으로 지난해 6월부터 개발이 진행되고 있다\n",
      "하드웨어 설계 ·제작은 브레이브 로보틱스가 맡고 제어용 소프트웨어 '브이시도(V-Sido)'의 개발은 아스라테크가 담당한다\n",
      "산세이 테크놀로지는 로봇의 양산화를 위해서 합류했다\n",
      "'제이 다이트 라이드'는 내년에 완성돼 테마 파크와 각종 이벤트 참여, 기업 홍보 등의 목적으로 쓰이게 된다\n",
      "이후에는 기체의 크기를 키워 2020년에는 5m에 달하는 '제이 다이트 오리지널'로 재탄생할 예정이다\n",
      "디자인은 애니메이션 '기동전사 건담', '달려라 번개호' 등 유명 애니메이션에 등장하는 로봇을 창조한 오오카와라 쿠니오가 맡았다\n",
      "오오카와라는 '제이 다이트 라이드' 외에 프로젝트에서 제작할 예정인 다른 로봇의 디자인도 맡는다\n",
      "'제이다이트 라이드'의 머리 부분 스케치\n",
      "언뜻 보기에도 건담이 연상된다\n",
      "이 로봇은 10초만에 자동차로 변신할 수 있으며 전체 길이는 약 4m이다\n",
      "로봇 모드에서는 두 다리로 걸을 수 있다\n",
      "차량 모드에서는 평범한 자동차와 마찬가지로 사람이 운전석에 앉아 조작하면 된다\n",
      "'철인28호'처럼 로봇과 떨어져 원격 조종을 해도 된다\n",
      "최대 2명이 탈 수 있다\n",
      "로봇이 두 다리로 걷는 속도는 시속 5km에 불과하지만 발 부분의 바퀴를 이용하면 한시간에 최고 30km를 갈 수 있다\n",
      "차로 변신했을 때 최고 속도는 시속 60km이다\n",
      "한편 '제이다이트 라이드'의 1.5m짜리 시제품은 14일(현지시간) 미국 올랜도에서 열리는 '국제 놀이기구 엑스포(IAAPA Attractions Expo 2016)'에서 선보일 예정이다\n",
      "5 번 Topic 문장 :\n",
      "애니메이션에서나 볼 수 있었던 자동차 변신 로봇이 일본에서 실제로 만들어진다\n",
      "11일 소프트뱅크 계열 로봇 제조업체인 아스라테크(Asratec)와 산세이 테크놀로지, 브레이브 로보틱스가 3사 합작으로 변신 로봇 '제이 다이트 라이드(J-deite RIDE)'를 제작한다고 발표했다\n",
      "이 로봇은 아스라테크와 브레이브 로보틱스가 참여한 로봇 제조 계획 \"프로젝트 제이 다이트'의 일환으로 지난해 6월부터 개발이 진행되고 있다\n",
      "6 번 전문 : \n",
      "접는 스마트폰 개발 전쟁이 치열하게 붙었다\n",
      "삼성전자가 지난 4월 접는 스마트폰의 특허를 특허청에 출원했다고 독일의 온라인 매체 ‘갤럭시 클럽’이 9일(현지시간) 보도했다\n",
      "반으로 접을 수도 있다\n",
      "갤럭시 클럽이 입수한 특허 신청서의 도면에 따르면 이 스마트폰은 반으로 접거나 휠 수 있다\n",
      "갖고 다닐 때는 스마트폰을 반으로 접고, 통화를 할 때는 살짝 휘어 얼굴에 부드럽게 갖다 댈 수 있는 것으로 보인다\n",
      "도면에는 ‘반자동으로 접히거나 펴진다’는 설명도 함께 있다\n",
      "또 ‘스마트폰이 접혀 화면이 가려질 경우 2차 화면이 나타난다’고 돼 있다\n",
      "한가운데 여러 겹의 힌지가 있다\n",
      "삼성전자는 오랜 기간 동안 ‘프로젝트 밸리’ 또는 ‘갤럭시 X’라는 코드명으로 접는 스마트폰 개발을 진행 중이다\n",
      "지난해 삼성전자가 특허출원한 스마트폰은 화면을 접을 수 있을 뿐 아니라 두루마리 형태로 둘둘 말 수 있는 형태였다\n",
      "업계에선 이르면 내년 삼성전자의 접는 스마트폰이 나올 것으로 전망하고 있다\n",
      "애플이 특허출원한 접는 스마트폰\n",
      "애플도 최근 미국 특허청에 반으로 접을 수 있는 스마트폰 특허를 출원했다\n",
      "LG전자도 접는 스마트폰 개발에 힘을 기울이고 있다\n",
      "6 번 Topic 문장 :\n",
      "접는 스마트폰 개발 전쟁이 치열하게 붙었다\n",
      "삼성전자가 지난 4월 접는 스마트폰의 특허를 특허청에 출원했다고 독일의 온라인 매체 ‘갤럭시 클럽’이 9일(현지시간) 보도했다\n",
      "갤럭시 클럽이 입수한 특허 신청서의 도면에 따르면 이 스마트폰은 반으로 접거나 휠 수 있다\n",
      "지난해 삼성전자가 특허출원한 스마트폰은 화면을 접을 수 있을 뿐 아니라 두루마리 형태로 둘둘 말 수 있는 형태였다\n",
      "7 번 전문 : \n",
      "공대 기계항공공학부 최만수 교수 연구팀\n",
      "국내 연구진이 페로브스카이트(Perovskite) 태양전지가 내구성이 부족한 이유를 처음으로 밝혔다\n",
      "서울대 공대는 기계항공공학부 최만수 교수 연구팀이 페로브스카이트 태양전지의 내구성 저하에 대한 메커니즘을 최초로 규명하고, 고효율 및 고안정성 페로브스카이트 태양전지를 개발했다고 10일 밝혔다\n",
      "페브로스카이트는 부도체, 반도체, 도체 등의 성질은 물론 초전도 현상까지 보이는 특이한 구조의 결정구조 물질로 에너지 변환효율이 높아 태양전지 시장에서 주목받고 있다\n",
      "그러나 대기 조건에서 내구성이 부족해 실리콘 태양전지처럼 상용화는 어려웠다\n",
      "연구팀이 실험을 통해 태양전지를 잘라 분석해 본 결과, 다결정 구조인 페브로스카이트의 계면(결정과 결정이 만나는 면)에 전하가 축적돼 필름을 변화시키는 것으로 나타났다\n",
      "페브로스카이트는 대기 중 수분이나 산소와 화학반응을 일으킨다는 사실이 알려져 있었지만, 내구성이 저하되는 구체적인 메커니즘이 밝혀진 것은 처음이라고 연구팀은 설명했다\n",
      "연구팀은 이에 따라 축적되는 전하를 최소화하는 소자 구조를 도입하는 동시에 안정적인 결정 구조를 갖는 페로브스카이트 물질을 합성해 20%의 고효율 고안정성 페로브스카이트 태양전지 기술을 개발했다\n",
      "최 교수는 \"이번 연구결과로 안정된 태양전지를 만들 수 있는 단초가 열렸다\"며 \"유연하고 가벼운 차세대 페로브스카이트 태양전지를 상용화한다면 기존의 실리콘 태양전지에서는 구현이 불가능했던 웨어러블 전자기기에도 응용 가능할 것\"이라고 말했다\n",
      "이번 연구는 미래창조과학부가 지원하는 글로벌프론티어 멀티스케일 에너지시스템 연구단의 지원으로 진행됐으며, 연구 결과는 네이쳐 커뮤니케이션즈에 10일자로 게재됐다\n",
      "7 번 Topic 문장 :\n",
      "국내 연구진이 페로브스카이트(Perovskite) 태양전지가 내구성이 부족한 이유를 처음으로 밝혔다\n",
      "서울대 공대는 기계항공공학부 최만수 교수 연구팀이 페로브스카이트 태양전지의 내구성 저하에 대한 메커니즘을 최초로 규명하고, 고효율 및 고안정성 페로브스카이트 태양전지를 개발했다고 10일 밝혔다\n",
      "연구팀이 실험을 통해 태양전지를 잘라 분석해 본 결과, 다결정 구조인 페브로스카이트의 계면(결정과 결정이 만나는 면)에 전하가 축적돼 필름을 변화시키는 것으로 나타났다\n",
      "8 번 전문 : \n",
      "‘융합’의 바람은 기계공학에서도 거세게 불고 있다\n",
      "나노·바이오·에너지가 공학과 만나 새로운 학문이 속속 등장하고 있으며 기계공학자들이 이들 신생 연구 분야에 뛰어들고 있다\n",
      "조맹효 서울대 기계항공공학부 교수는 “고전적 기계공학의 외연을 넓히려는 시도가 지난 10여년 동안 급박하게 진행됐다”며 “융합·협력 연구는 이미 세계적인 추세”라고 말했다\n",
      "조 교수의 이번 연구 성과도 기계공학에 재료과학, 역학적 시각을 더해 이뤄낸 것이다\n",
      "학문 간 융합은 시선을 돌리는 이치와 같다\n",
      "각도를 달리 보면 난제를 해결할 방법과 의도치 않게 맞닥뜨릴 수 있다는 것이 조 교수의 설명이다\n",
      "기계공학뿐만이 아니다\n",
      "전기나 토목·건축 등 주로 물리학을 기반으로 하는 학문에서도 변화의 조짐이 보인다\n",
      "해당 학문들은 물리학의 특성상 방정식을 통해 데이터(해)를 구하는 것이 특성인데 반대로 축적된 데이터로 공식을 만드는 시도가 이뤄지는 것이다\n",
      "전산학의 영역이라고 여겨졌던 데이터 과학과 물리학이 만나기 시작한 것이다\n",
      "데이터 활용은 필연적으로 컴퓨터가 데이터 분석으로 스스로 학습해 궁극적으로 수많은 데이터를 분석하도록 하는 딥러닝 인공지능(AI)과의 접점을 형성한다\n",
      "조 교수는 “예를 들어 미국 항공우주국(NASA)에는 그동안의 비행 관련 실험이 무수히 쌓여 있는데 이를 데이터베이스화해서 데이터를 추출하고 의미 있는 정보로 만드는 ‘역순’으로 계산식을 도출하는 형태”라고 설명했다\n",
      "데이터를 분석해 모형을 설계하는 것도 가능하다\n",
      "하지만 융합은 말처럼 쉽지 않다\n",
      "‘다학제’ 연구를 하려면 여러 전문 분야를 알아야 한다\n",
      "그래야 연결 고리를 찾을 수 있기 때문이다\n",
      "또 학문·분야 간 접점을 찾으려는 노력이 중요하다\n",
      "조 교수는 새로운 시도를 강조하지만 연구 방법은 우직해야 한다고 믿는다\n",
      "“연구를 진행하면서 연구자 본인이 자신의 방법을 의심하기 시작하면 연구는 미궁으로 빠집니다\n",
      "연구의 갈래를 결정하기 위해 반드시 숙고해야 하지만 방향이 설정되면 끈기 있게 앞으로 나아가야 하죠\n",
      "결국 과학은 고난을 극복하고 답을 찾는 과정입니다.”\n",
      "8 번 Topic 문장 :\n",
      "나노·바이오·에너지가 공학과 만나 새로운 학문이 속속 등장하고 있으며 기계공학자들이 이들 신생 연구 분야에 뛰어들고 있다\n",
      "조맹효 서울대 기계항공공학부 교수는 “고전적 기계공학의 외연을 넓히려는 시도가 지난 10여년 동안 급박하게 진행됐다”며 “융합·협력 연구는 이미 세계적인 추세”라고 말했다\n",
      "데이터 활용은 필연적으로 컴퓨터가 데이터 분석으로 스스로 학습해 궁극적으로 수많은 데이터를 분석하도록 하는 딥러닝 인공지능(AI)과의 접점을 형성한다\n",
      "조 교수는 “예를 들어 미국 항공우주국(NASA)에는 그동안의 비행 관련 실험이 무수히 쌓여 있는데 이를 데이터베이스화해서 데이터를 추출하고 의미 있는 정보로 만드는 ‘역순’으로 계산식을 도출하는 형태”라고 설명했다\n",
      "9 번 전문 : \n",
      "펜실베니아 대학교 인간-기계 상호작용 연구소의 슬랙 채널에서는 보통 지난 강의의 요약, 그리고 벽을 타고 올라가는 로봇의 동영상이 나온다\n",
      "그러나 지난 여름, 테슬라 오토파일럿이 첫 치명 교통사고를 일으키자 해당 채널은 자율주행 자동차에 대한 비판의 목소리로 가득 찼다\n",
      "연구 조수인 어느 대학원생은 이런 말을 했다\n",
      "“누구나 새로운 물건을 출시할 때면 이 물건들이 사람들을 흥분시킬 거라고 주장하곤 하죠.”\n",
      "또한 “기술이 충분히 발전할 때까지 이런 사고는 피할 수 없습니다\n",
      "테슬라가 운 나쁘게 가장 처음으로 걸렸을 뿐입니다\n",
      "앞으로 이 기술은 더욱 엄격하게 다듬어져야 합니다.”슬랙 채널에서의 논쟁은 수일간이나 지속되었다\n",
      "찬반 양측 주장 모두 타당한 논리가 있었다\n",
      "그래서 사고를 더욱 자세히 조사했다\n",
      "이 사고에서는 테슬라 모델 S를 타고 오토파일럿을 작동시킨 채로 운전을 하던 한 오하이오 주민이 숨졌다\n",
      "필자는 오토파일럿 시스템이 가장 발전된 인간-기계 상호작용 실험 중 왜 오류를 일으켰는지 알고 싶었다\n",
      "피해자의 차는 플로리다의 27A 고속도로에서 트랙터 트레일러와 충돌했다\n",
      "테슬라의 초기 사고 보고서에 따르면, 차량의 비상 제동장치가 맑은 하늘과 트랙터 트레일러의 흰색 옆구리를 분간하지 못했기 때문이라고 한다\n",
      "기술적으로 볼 때 결함은 이 부분이다\n",
      "그러나 자동 안전장치 전문가들과 테슬라에게 더 중요한 사실은 운전자가 임박한 충돌을 눈치 채지 못했다는 것이다\n",
      "결국 운전자는 브레이크를 걸지 않았고 차는 트레일러를 들이받았다\n",
      "자율주행 자동차가 거리에 나서기 시작하면서 일상 속 로봇에 대해 오랫동안 갖고 있던 잘못된 개념을 다시 돌아볼 때가 되었다\n",
      "많은 사람들은 드라마 <전격 Z작전>의 인공지능 자동차 <키트>처럼 모든 것을 다 아는 자동차가 나올 거라는 믿음을 갖고 살았다\n",
      "<전격 Z작전>은 픽션일 뿐이다\n",
      "그러나 그로 인해 생긴 믿음은 룸바, 지능형 식기세척기 등의 설정 후 망각형 가정용 로봇들로 인해 더욱 확고해졌다\n",
      "사용자들은 테슬라의 말을 들었을까? 듣기도 했고 안 듣기도 했다\n",
      "얼리 어답터들은 환상을 더욱 부추겼다\n",
      "기계가 알아서 운전하는 동안 어른들이 자동차 뒷좌석에 앉아서 젠가를 플레이하는 멋진 유튜브 동영상들이 나왔다\n",
      "조회수가 약 50만 회에 달하는 어느 리뷰에서는 다음과 같은 주의사항을 전달했지만, 사람들에게 큰 도움이 된 것 같지는 않다\n",
      "‘주의 : 이 동영상 속 상황은 연출 및 편집된 것입니다\n",
      "안전은 무엇보다도 중요합니다\n",
      "절대 멍청한 짓을 하지 마십시오\n",
      "언제나 주변 상황을 살피십시오.’\n",
      "분할 제어가 실은 반자율 운전 게임의 이름이라는 사실은 흥분 속에 잊혀졌다.전투 조종사 훈련을 들여다보면 이런 인간-기계간 관계에 대해 많은 것을 알 수 있다\n",
      "카터 대통령 재임 시절 이후, 수동 조종 방식은 전투기의 제어 방식으로 쓰이지 않는다\n",
      "그 대신 플라이 바이 와이어 시스템을 비롯한 여러 비행 자동화 기술이 쓰인다\n",
      "그러나 오토파일럿과 마찬가지로 이런 기술들은 조종사의 조종 능력을 대신하는 것이 아니라 보완할 뿐이다\n",
      "조종사들은 실제 전투기를 조종해 보기까지 수년간의 훈련을 받는다\n",
      "컴퓨터가 어떤 정보를 받아들이고 그것을 어떻게 처리해 결정을 내리는지에 대해서도 이 때 배운다\n",
      "또한 언제나 상황 인식능력을 유지하고, 만약의 상황에 즉각 대처하는 방법도 배운다\n",
      "첨단 기술이 있음에도 그런 교육을 받는다\n",
      "절대 비행기에 모든 것을 일임하지 않는다\n",
      "물론 운전자들에게 이만한 훈련을 시키기는 어렵다\n",
      "하지만 그래도 시켜야 하는지를 자동차 회사들과 정부는 결정해야 한다\n",
      "오토파일럿 소프트웨어 업데이트 설치 시 화면에 나타나는 수준 이상의 것을 제공해야 한다\n",
      "일부 주에서는 보트 운전면허를 따려면 주말에 교육을 받아야 한다\n",
      "자동차 회사들도 그것과 비슷한 단기 교육 프로그램을 만들어 운전자들에게 자동화 시스템의 작동방식은 물론, 이 시스템이 어떤 상황에서는 작동되고 어떤 상황에서는 작동되지 않으며, 인간이 필요시 개입해야 하는 이유가 뭔지 가르쳐야 한다\n",
      "미 공군의 전 수석 과학자이자 자동화 및 인간-기계간 상호작용 전문가인 미카 엔즐리는 이렇게 말한다\n",
      "“오류가 발생했을 때 사람이 명령 체계를 떠나 있는 경우가 많다는 것, 그리고 오류를 발견하고 시정하는 데 시간이 많이 걸린다는 것이 오토파일럿과 같은 자동화 기술의 문제입니다.”\n",
      "운전자 교육은 시작에 불과하다\n",
      "하지만 자율주행 소프트웨어는 이런 교육을 받은 운전자를 보완하는 존재여야 한다\n",
      "엔지니어들은 인간의 인식 능력이 기계가 아닌 타인과 교류하는 데 더 뛰어나다는 것을 알아야 한다\n",
      "다행히도, 자동차 회사와 학계에서는 최근 이러한 상호작용에 더욱 관심을 기울이고 연구하고 있다\n",
      "스탠포드 대학의 상호작용 설계 전문가들은 자율주행 자동차의 논리, 카메라, 레이더, 센서 등의 측정값을 인간이 더욱 이해하기 쉽게 개량하는 방법을 연구하고 있다\n",
      "자동차 회사들에 따르면, 구어체로 된 지시 음성(“장애물입니다\n",
      "멈추십시오.” 같은), 제어 장치의 물리적 변화(운전대의 각도 변화 등)를 사용해 운전자들에게 상황의 변화(끼어들기)를 알리고, 아무 것도 모르고 지나가다가 사고를 내는 것을 예방해야 한다고 한다\n",
      "현재의 전환 신호는 더 강하게 바꿔야 할 필요가 있다\n",
      "운전자에게 테슬라의 제어권을 넘겨줘야 할 때 나오는 신호는 신호음 및 대시보드의 색상 변경뿐이다\n",
      "캐딜락과 볼보의 운전자 보조 시스템은 좌석 또는 운전대를 진동시킨다\n",
      "자동차 회사들은 좀 더 적극적이 되어야 한다\n",
      "최근 스탠포드 대학의 연구에 의하면 여러 감각기관을 동시에 자극하는 것이 좋다고 한다\n",
      "한꺼번에 운전대에서도 경보음이 나오고, 인간의 목소리로 지시가 나오고, 신호등이 깜박여야 사람들은 빨리 대응한다는 것이다\n",
      "반자율주행 자동차의 세계에서는 운전자들은 여전히 주변 상황에 주의 및 집중을 해야 한다\n",
      "기술이 고속도로 주행 중 사람들의 주의력을 낮추거나 졸게까지 할 수 있다면, 그것을 운용하는 인간은 더 많은 훈련을 받아야 하며 더욱 지능적인 경고 시스템도 필요하다\n",
      "지난 5월의 사고는 치명적인 시나리오가 현실로 드러난 것이었고, 매우 비극적이었다\n",
      "그러나 자동차의 명령 체계에 사람이 반드시 있어야 한다는 점을 보여준 사례이기도 하다\n",
      "9 번 Topic 문장 :\n",
      "이 사고에서는 테슬라 모델 S를 타고 오토파일럿을 작동시킨 채로 운전을 하던 한 오하이오 주민이 숨졌다\n",
      "필자는 오토파일럿 시스템이 가장 발전된 인간-기계 상호작용 실험 중 왜 오류를 일으켰는지 알고 싶었다\n",
      "피해자의 차는 플로리다의 27A 고속도로에서 트랙터 트레일러와 충돌했다\n",
      "테슬라의 초기 사고 보고서에 따르면, 차량의 비상 제동장치가 맑은 하늘과 트랙터 트레일러의 흰색 옆구리를 분간하지 못했기 때문이라고 한다\n",
      "그러나 자동 안전장치 전문가들과 테슬라에게 더 중요한 사실은 운전자가 임박한 충돌을 눈치 채지 못했다는 것이다\n",
      "자율주행 자동차가 거리에 나서기 시작하면서 일상 속 로봇에 대해 오랫동안 갖고 있던 잘못된 개념을 다시 돌아볼 때가 되었다\n",
      "자동차 회사들도 그것과 비슷한 단기 교육 프로그램을 만들어 운전자들에게 자동화 시스템의 작동방식은 물론, 이 시스템이 어떤 상황에서는 작동되고 어떤 상황에서는 작동되지 않으며, 인간이 필요시 개입해야 하는 이유가 뭔지 가르쳐야 한다\n",
      "“오류가 발생했을 때 사람이 명령 체계를 떠나 있는 경우가 많다는 것, 그리고 오류를 발견하고 시정하는 데 시간이 많이 걸린다는 것이 오토파일럿과 같은 자동화 기술의 문제입니다.”\n",
      "멈추십시오.” 같은), 제어 장치의 물리적 변화(운전대의 각도 변화 등)를 사용해 운전자들에게 상황의 변화(끼어들기)를 알리고, 아무 것도 모르고 지나가다가 사고를 내는 것을 예방해야 한다고 한다\n",
      "기술이 고속도로 주행 중 사람들의 주의력을 낮추거나 졸게까지 할 수 있다면, 그것을 운용하는 인간은 더 많은 훈련을 받아야 하며 더욱 지능적인 경고 시스템도 필요하다\n",
      "10 번 전문 : \n",
      "DNA의 염기서열 정보를 이용해 움직이는 초미세로봇 기술이 개발됐다\n",
      "박소정 이화여대 교수와 이대연·존 크로커 미국 펜실베이니아대 교수 연구진으로 구성된 한미 공동연구팀이 DNA의 염기서열 정보를 이용해 원하는 대로 구동하는 ‘연성재질 미세로봇’ 핵심 기술을 세계 처음으로 개발하는 데 성공했다고 7일 밝혔다\n",
      "연성재질 미세로봇은 고분자, 나노입자 등 유연재료로 이뤄진 초소형 로봇이다\n",
      "전기 신호뿐만 아니라 다양한 물리적, 화학적 자극 등으로 새로운 개념의 구조 제어 기술로 구동된다\n",
      "DNA는 구아닌(G), 사이토신(C), 아데닌(A), 티민(T) 등 4가지 염기 정보로 구성된다\n",
      "DNA는 일반적으로 2개의 단일 가닥 DNA가 이중나선 형태로 결합하며 만들어진다\n",
      "이 때 두 단일 가닥 DNA는 염기서열 정보가 꼭 맞는 경우에만 결합이 일어난다\n",
      "연구팀은 DNA가 단일 가닥일 때와 염기간 결합 후 이중나선구조를 가질 때 나타나는 DNA의 분자 길이 변화에 주목했다\n",
      "DNA를 활용하면 염기서열정보에 따라 길이가 달라지는 구조체를 만들 수 있기 때문이다\n",
      "연구팀은 염기서열 정보 조작을 통해 제작한 DNA를 금 나노 입자에 붙여 DNA-금 나노 입자 구조체를 만들었다\n",
      "ATTGCG, TGCCGAT 등 다양한 염기서열을 가질 수 있도록 인공 합성하는 기술을 도입하면 염기서열을 조작할 수 있다\n",
      "DNA 가닥교환반응에 의한 DNA-금나노입자 구조체의 구동기술 모식도(왼쪽)\n",
      "가닥교환반응에 의해 연속적으로 모양을 변형하는 구조체의 모습(오른쪽)/한국연구재단 제공\n",
      "연구팀이 만든 DNA-금 나노 입자 구조체에 DNA 이중나선 구조 결합 및 해체가 가능한 제 3의 단일 가닥 DNA를 통해 이른바 ‘가닥교환반응’을 유도했다\n",
      "이 반응은 DNA의 이중나선 구조를 제 3의 DNA를 통해 결합 및 해체시키는 반응이다\n",
      "그 결과 말리거나 뒤집는 등의 기계적 움직임이 가능해졌다\n",
      "박소정 교수는 “DNA의 염기서열 조작과 반응을 통해 다양한 방식으로 움직이는 나노 구조체를 최초로 구현했다”이라며 “정해진 자극에 따라 복잡한 움직임을 수행할 수 있는 나노로봇 제작 가능성을 열었다”고 설명했다\n",
      "이번 연구 논문의 제1저자인 심태섭(사진) 아주대 교수는 “0과 1의 2진수로 제어하는 컴퓨터와 달리 A와 T, G, C 등 4진수의 정보를 갖는 DNA 염기서열을 통해 보다 다양하고 복잡한 명령을 내릴 수 있는 나노로봇”이라며 “제어기술이 더욱 발전하면 약물 전달이나 혈관 확장 등 복잡하고 까다로운 환경에서도 정교한 구동이 가능한 미세로봇 제작이 가능할 것”이라고 말했다\n",
      "이번 연구 결과는 국제 학술지 ‘네이처 나노테크놀로지’에 게재됐다\n",
      "10 번 Topic 문장 :\n",
      "DNA의 염기서열 정보를 이용해 움직이는 초미세로봇 기술이 개발됐다\n",
      "박소정 이화여대 교수와 이대연·존 크로커 미국 펜실베이니아대 교수 연구진으로 구성된 한미 공동연구팀이 DNA의 염기서열 정보를 이용해 원하는 대로 구동하는 ‘연성재질 미세로봇’ 핵심 기술을 세계 처음으로 개발하는 데 성공했다고 7일 밝혔다\n",
      "박소정 교수는 “DNA의 염기서열 조작과 반응을 통해 다양한 방식으로 움직이는 나노 구조체를 최초로 구현했다”이라며 “정해진 자극에 따라 복잡한 움직임을 수행할 수 있는 나노로봇 제작 가능성을 열었다”고 설명했다\n",
      "이번 연구 논문의 제1저자인 심태섭(사진) 아주대 교수는 “0과 1의 2진수로 제어하는 컴퓨터와 달리 A와 T, G, C 등 4진수의 정보를 갖는 DNA 염기서열을 통해 보다 다양하고 복잡한 명령을 내릴 수 있는 나노로봇”이라며 “제어기술이 더욱 발전하면 약물 전달이나 혈관 확장 등 복잡하고 까다로운 환경에서도 정교한 구동이 가능한 미세로봇 제작이 가능할 것”이라고 말했다\n",
      "11 번 전문 : \n",
      "'나선형 신경망' 학습 기술\n",
      "카메라로 찍은 이미지에서 특정한 사물 찾는 기술 활용\n",
      "숲속에서 등산로 척척 찾아 드론이 산악구조대 역할도\n",
      "미국 국방부는 지난달 말 인공지능(AI)을 이용해 인간 도움 없이 적을 식별해 타격하는 드론(무인 항공기)을 시연했다\n",
      "이 드론은 카메라 화면에서 총으로 무장한 사람과 무기가 없는 사람을 구분할 수 있다\n",
      "표적으로 정한 사람을 찾아 그가 탄 자동차를 추적하는 기능도 있다\n",
      "조만간 원격 조종 없이도 전장에서 특수부대 군인들처럼 임무를 수행하는 드론이 등장할 전망이다\n",
      "이 드론이 사람 도움 없이 카메라 영상에서 목표물을 인식하고 추적할 수 있는 것은 바로 ‘머신러닝’ 덕분이다\n",
      "머신러닝은 AI의 한 분야로 컴퓨터가 인간처럼 스스로 학습할 수 있는 능력을 부여하는 작업을 말한다\n",
      "머신러닝의 원리는 인간을 포함한 영장류 두뇌의 정보 처리 구조인 ‘신경망’을 모사하는 방식이다\n",
      "바둑 대결에서 이세돌 9단을 이긴 구글의 ‘알파고’ 등 지금까지 소개된 AI 대부분은 심층신경망을 기반으로 한 머신러닝 알고리즘을 이용한다\n",
      "이미지에서 특정 사물을 찾는 기술은 인간이 아니라 고양이 뇌에서 유래했다\n",
      "고양이 뇌의 시신경에서 발견되는 ‘나선형 신경망’ 구조는 시각세포들이 보내오는 반응을 모아 여러 개의 층(層)으로 나눈다\n",
      "이를 3단계에 걸쳐 점차적으로 단순화하면서 물체의 색깔이나 모양을 파악한다\n",
      "이를 처음으로 연구한 데이비드 휴벨과 토어스텐 비젤은 1981년 노벨 생리의학상을 받았다\n",
      "AI 과학자들은 나선형 신경망에서 아이디어를 얻어 이미지에서 사물을 판별하는 알고리즘을 설계했다\n",
      "우선 이미지에서 큰 특징을 추출한 다음 점차 작고 복잡한 특징을 발견해 나가는 방식이다\n",
      "예컨대 사진 속에 자동차가 있다고 해 보자\n",
      "알고리즘은 우선 사물의 전체적인 윤곽을 먼저 확인한 뒤 기존에 입력된 사진 데이터와 비교해 ‘탈 것’으로 범위를 좁힌다\n",
      "이후 타이어나 제조사 엠블럼처럼 세부적인 특징을 파악하고 ‘사진 속에 있는 물체는 자동차’라는 결론을 내리게 된다\n",
      "제프 딘 구글 수석연구원은 “나선형 신경망은 다른 머신러닝 구조들과 비교할 때 영상, 음성 분야에서 좋은 성능을 보인다”며 “이를 이용하면 컴퓨터가 처음 본 사물도 무엇인지 파악할 수 있다”고 설명했다\n",
      "주변에서 볼 수 있는 영상촬영용 드론에도 이보다는 간단하지만 비슷한 기술이 이용된다\n",
      "세계 1위 드론업체인 중국 DJI의 ‘팬텀4’는 사람 눈처럼 두 개의 카메라 센서를 장착했다\n",
      "이를 통해 대상 물체를 확인하고 일정 거리를 유지하면서 따라다닌다\n",
      "이른바 ‘액티브 트랙’ 기능이다\n",
      "액티브 트랙 기능을 켜면 이용자가 지정한 사물이나 사람의 윤곽선을 인식하고 픽셀(이미지를 구성하는 가장 작은 단위인 네모 모양의 점) 단위로 인식한다\n",
      "그 픽셀을 계속적으로 같은 크기로 유지하기 위해 기체가 이동한다\n",
      "예컨대 주변에 있는 사람을 지정했을 때 픽셀 크기가 상하좌우 100×100 픽셀이었다고 해 보자\n",
      "그 사람이 앞으로 움직여서 80×80 픽셀 크기로 줄어들면 원래 수치인 100×100 픽셀을 되찾기 위해 드론도 따라서 앞으로 움직이는 방식이다\n",
      "과학자들은 나선형 신경망을 본뜬 머신러닝 기술을 응용해 인간 삶을 윤택하게 할 수 있는 기술을 개발하고 있다\n",
      "스위스 취리히대 연구팀은 드론을 이용해 알프스 산맥에서 조난자를 찾는 기술을 연구 중이다\n",
      "연구팀이 개발한 AI 드론은 카메라가 촬영한 이미지를 이용해 숲이 우거진 곳과 등산로를 구분한다\n",
      "이를 드론의 비행 제어기로 전달해 이동 방향을 결정한다\n",
      "올해 초 취리히대가 완료한 첫 실험에서는 ‘드론이 인간보다 등산로를 잘 찾는다’는 결과가 나왔다\n",
      "연구팀은 약 2만장의 알프스 산 등산로 사진을 바탕으로 3일간 드론에 탑재된 인공지능의 심층신경망을 학습시켰다\n",
      "이후 드론이 전혀 가보지 못한 등산로를 오르도록 했다\n",
      "실험 결과 사람 눈으로 새로운 등산로를 식별할 확률은 82%였으나 AI 드론은 85%의 성공률을 보여줬다\n",
      "취리히대 연구팀은 “AI 드론은 조만간 실전에 투입돼 산악구조대가 조난자를 찾는 일을 도울 수 있을 것”이라고 말했다\n",
      "신경망 학습 기술은 다양한 용도로 활용할 수 있다\n",
      "문태현 DJI코리아 대표는 “AI를 탑재한 드론은 송전선이나 송유관 등 산업시설물의 결함 발견, 산불 감지, 장애물이나 군사용 목표물 탐지 등 이용 가능 범위가 무궁무진하다”고 말했다\n",
      "11 번 Topic 문장 :\n",
      "미국 국방부는 지난달 말 인공지능(AI)을 이용해 인간 도움 없이 적을 식별해 타격하는 드론(무인 항공기)을 시연했다\n",
      "이 드론은 카메라 화면에서 총으로 무장한 사람과 무기가 없는 사람을 구분할 수 있다\n",
      "조만간 원격 조종 없이도 전장에서 특수부대 군인들처럼 임무를 수행하는 드론이 등장할 전망이다\n",
      "이 드론이 사람 도움 없이 카메라 영상에서 목표물을 인식하고 추적할 수 있는 것은 바로 ‘머신러닝’ 덕분이다\n",
      "머신러닝은 AI의 한 분야로 컴퓨터가 인간처럼 스스로 학습할 수 있는 능력을 부여하는 작업을 말한다\n",
      "머신러닝의 원리는 인간을 포함한 영장류 두뇌의 정보 처리 구조인 ‘신경망’을 모사하는 방식이다\n",
      "AI 과학자들은 나선형 신경망에서 아이디어를 얻어 이미지에서 사물을 판별하는 알고리즘을 설계했다\n",
      "제프 딘 구글 수석연구원은 “나선형 신경망은 다른 머신러닝 구조들과 비교할 때 영상, 음성 분야에서 좋은 성능을 보인다”며 “이를 이용하면 컴퓨터가 처음 본 사물도 무엇인지 파악할 수 있다”고 설명했다\n",
      "과학자들은 나선형 신경망을 본뜬 머신러닝 기술을 응용해 인간 삶을 윤택하게 할 수 있는 기술을 개발하고 있다\n",
      "연구팀이 개발한 AI 드론은 카메라가 촬영한 이미지를 이용해 숲이 우거진 곳과 등산로를 구분한다\n",
      "신경망 학습 기술은 다양한 용도로 활용할 수 있다\n",
      "12 번 전문 : \n",
      "영화 ‘반지의 제왕’을 보면 마법사 간달프는 호빗 마을에서 신기한 불꽃놀이를 보여준다\n",
      "폭죽으로 용을 밤하늘에 그렸는데, 이 용은 살아있는 것처럼 날아다닌다\n",
      "현실에서도 이런 불꽃놀이가 가능해졌다\n",
      "드론 덕분이다\n",
      "인텔은 4일(현지시간) ‘슈팅스타(Shooting Star)’라고 불리는 자사의 드론으로 ‘가짜 불꽃놀이’를 시연하는 데 성공했다고 밝혔다\n",
      "반도체 제조사인 인텔은 지난해부터 본격적으로 드론 시장에 뛰어 들었다\n",
      "이 드론은 무게가 280g으로 모터가 4개 달린 쿼드콥터(quadcopter)이다\n",
      "조립하는데 단 한 개의 나사도 쓰지 않았다고 한다\n",
      "500개의 슈팅스타가 불꽃놀이에 동원됐다\n",
      "이는 가장 많은 드론이 동시에 비행한 기록으로 기네스북에 등재됐다\n",
      "이들 드론은 자율 알고리즘이 내장돼 있기 때문에 하늘에 그릴 그림이나 글자를 지정해주면 개별 드론이 알아서 적절한 위치로 비행을 한다\n",
      "드론마다 따로 프로그래밍할 필요가 없다고 인텔은 설명했다\n",
      "12 번 Topic 문장 :\n",
      "인텔은 4일(현지시간) ‘슈팅스타(Shooting Star)’라고 불리는 자사의 드론으로 ‘가짜 불꽃놀이’를 시연하는 데 성공했다고 밝혔다\n",
      "이들 드론은 자율 알고리즘이 내장돼 있기 때문에 하늘에 그릴 그림이나 글자를 지정해주면 개별 드론이 알아서 적절한 위치로 비행을 한다\n",
      "13 번 전문 : \n",
      "수명이 길어지면서 사람들이 가장 두려워하는 질병으로 치매가 꼽힙니다\n",
      "지난해 기준 국내 치매 환자는 65만명에 달합니다\n",
      "65세 이상 노인 10명 중 1명은 치매를 앓고 있는 것으로 추정됩니다\n",
      "2030년 127만명, 2050년 271만명으로 국내 치매 환자 수가 계속 늘어날 것이란 전망도 나옵니다\n",
      "치매는 크게 ‘알츠하이머병’과 ‘혈관성 치매’로 나뉩니다\n",
      "전체 치매 환자의 50%는 알츠하이머병입니다\n",
      "약 30% 환자는 혈관성 치매를 앓고 있습니다\n",
      "알츠하이머병은 1907년 독일 정신과 의사 알로이스 알츠하이머에 의해 보고됐습니다\n",
      "처음에는 기억력이 약해지다가 언어능력 판단력 등이 서서히 떨어집니다\n",
      "환각 망상 우울증 등도 알츠하이머병의 특징입니다\n",
      "남이 자신을 위협한다든가 남의 물건을 훔치는 등 피해망상에 사로잡히거나 헛것을 보고 듣는 것도 알츠하이머병의 증상입니다\n",
      "원인은 아직 밝혀지지 않았습니다\n",
      "베타아밀로이드라는 단백질이 뇌에서 많이 생성돼 뇌세포에 영향을 주는 것으로 알려졌습니다\n",
      "혈관성 치매는 뇌경색 뇌출혈 뇌졸중 등 뇌혈관 질환으로 뇌가 손상돼 나타나는 병입니다\n",
      "알츠하이머병과 달리 갑작스럽게 나타나는 경우가 많다고 합니다\n",
      "혈관성 치매도 알츠하이머병처럼 기억력과 판단력 등 인지능력이 떨어집니다\n",
      "고혈압 흡연 당뇨 등 뇌혈관 질환을 유발하는 질병을 예방하면 상대적으로 혈관성 치매 발병률이 낮다고 합니다\n",
      "치매는 아직 치료제가 나오지 않았습니다\n",
      "기존 치매 치료에 사용되는 의약품은 인지기능을 개선하는 역할을 합니다\n",
      "증상을 늦춰주는 것입니다\n",
      "노바티스, 화이자, 로슈 등 글로벌 제약사가 치매 치료제 개발에 뛰어들었지만 성과를 내지 못하고 있습니다\n",
      "최근 미국 제약사 머크가 알츠하이머병 치매 치료제 ‘베루베세스타트’ 초기 임상에서 알츠하이머병 치매 원인 단백질인 베타아밀로이드를 최대 90%까지 감소시킨 것으로 알려졌습니다\n",
      "이 회사는 대규모 환자를 대상으로 임상시험 3상을 진행 중입니다\n",
      "이 치료제가 상용화되면 치매 환자와 그 가족에게는 희소식인데요\n",
      "치매 환자들의 고통을 줄이기 위해 하루빨리 개발에 성공했으면 하는 바람입니다\n",
      "13 번 Topic 문장 :\n",
      "남이 자신을 위협한다든가 남의 물건을 훔치는 등 피해망상에 사로잡히거나 헛것을 보고 듣는 것도 알츠하이머병의 증상입니다\n",
      "혈관성 치매는 뇌경색 뇌출혈 뇌졸중 등 뇌혈관 질환으로 뇌가 손상돼 나타나는 병입니다\n",
      "혈관성 치매도 알츠하이머병처럼 기억력과 판단력 등 인지능력이 떨어집니다\n",
      "최근 미국 제약사 머크가 알츠하이머병 치매 치료제 ‘베루베세스타트’ 초기 임상에서 알츠하이머병 치매 원인 단백질인 베타아밀로이드를 최대 90%까지 감소시킨 것으로 알려졌습니다\n",
      "14 번 전문 : \n",
      "인류의 소망담아\n",
      "우주로 나아간다\n",
      "진실을 찾아간다\n",
      "차세대 우주선 오리온(Orion)의 승무원 모듈에 대한 실험이 태평양에서 이뤄져 관심을 모으고 있다\n",
      "미국 항공우주국(NASA)은 지난달 27일 캘리포니아 해변에서 오리온의 승무원 모듈에 대한 실험을 진행했다\n",
      "이번 실험은 수중에 우주선이 착륙했을 때를 가정해 회복 과정과 매뉴얼, 하드웨어 등에 대한 점검이 이뤄졌다\n",
      "오리온에는 비상정지 능력, 우주비행사를 건강하게 지탱하는 시스템, 심우주에서 안전하게 재진입하는 구조 등 복잡한 시스템으로 구성돼 있다\n",
      "오리온은 지금까지의 우주선과 차원을 달리한다\n",
      "오리온을 '탐험 우주선'이라고 부른다\n",
      "이는 그동안 인류가 탐험하지 못한 곳까지 우주비행사를 보내겠다는 강한 의지를 담고 있다\n",
      "인류의 우주과학은 끝없이 발전하고 있다\n",
      "그럼에도 지금까지 인류가 지구 아닌 다른 천체에 땅을 디딘 곳은 지구 위성인 '달'이 고작이다\n",
      "오리온은 계획된 실험이 끝나면 차세대발사시스템인 SLS(Space Launch System)로켓에 실려 우주로 발사된다\n",
      "2018년 시험비행에 나서는데 이때는 무인으로 실험한다\n",
      "이어 소행성에 오리온을 보낼 예정이다\n",
      "이 같은 일련의 과정이 끝나면 2030년대 인류를 화성에 보내는 프로그램에 본격 진입한다\n",
      "14 번 Topic 문장 :\n",
      "차세대 우주선 오리온(Orion)의 승무원 모듈에 대한 실험이 태평양에서 이뤄져 관심을 모으고 있다\n",
      "미국 항공우주국(NASA)은 지난달 27일 캘리포니아 해변에서 오리온의 승무원 모듈에 대한 실험을 진행했다\n",
      "오리온은 계획된 실험이 끝나면 차세대발사시스템인 SLS(Space Launch System)로켓에 실려 우주로 발사된다\n",
      "15 번 전문 : \n",
      "대학과 산업계, 공공연구기관에서 일하는 기술경영 전문가 10명 중 7명은 박근혜 정부의 과학기술 정책이 실패했다고 평가하는 것으로 나타났다\n",
      "10명 중 8명은 과학기술 전담 부처의 필요성에 공감했다\n",
      "기술경영경제학회는 3일 이 같은 내용을 담은 ‘차기 정부 과학기술혁신 정책에 대한 설문 조사 결과’를 발표했다\n",
      "지난 10월17~23일 이뤄진 이 설문 조사에는 대학과 산업계, 공공연구기관에 종사하는 학회 소속 회원 160명이 참여했다\n",
      "응답자 중 69.4%가 정부 교체 때마다 바뀐 과학기술 정책이 모두 실패했다고 답했다\n",
      "과학기술처에서 과학기술부, 교육과학기술부를 거쳐 미래창조과학부로 전담 부처 이름을 바꾸고 정책 기조가 바뀌면서 일관성 있는 과학기술 정책을 추진하지 못했다는 것이다\n",
      "응답자의 66.9%는 창조경제를 내세운 현 정부의 과학기술 정책이 실패했다고 평가했다\n",
      "성공한 과학기술 정책을 편 정부를 꼽아달라는 질문에 응답자의 65%(104명)가 노무현 정부를, 22%(35명)는 김대중 정부를 선택했다\n",
      "과학기술 정책에서 가장 실패한 정부는 응답자 절반 이상인 56%(104명)가 박근혜 정부를, 36%(58명)가 이명박 정부를 꼽았다\n",
      "응답자의 78.8%는 차기 정부의 과학기술 전담 부처 설립 필요성에 공감했다\n",
      "15 번 Topic 문장 :\n",
      "대학과 산업계, 공공연구기관에서 일하는 기술경영 전문가 10명 중 7명은 박근혜 정부의 과학기술 정책이 실패했다고 평가하는 것으로 나타났다\n",
      "10명 중 8명은 과학기술 전담 부처의 필요성에 공감했다\n",
      "과학기술처에서 과학기술부, 교육과학기술부를 거쳐 미래창조과학부로 전담 부처 이름을 바꾸고 정책 기조가 바뀌면서 일관성 있는 과학기술 정책을 추진하지 못했다는 것이다\n",
      "16 번 전문 : \n",
      "UNIST(울산과학기술원)는 수소차에 쓰이는 수소 연료전지를 저렴하게 만들 수 있는 촉매 합성법을 개발했다고 3일 밝혔다\n",
      "주상훈 UNIST 교수\n",
      "에너지 및 화학공학부 교수팀이 개발한 촉매 합성법은 가격이 비싼 백금 대신 새로 만든 탄소 촉매를 이용한 것이 핵심이다\n",
      "수소 연료전지는 수소와 산소를 결합해 전기와 물을 만들어 내는데 지금까지 상용화된 연료전지에는 귀금속인 백금 촉매가 사용됐다\n",
      "하지만 백금 가격은 1g당 5만원이 넘기 때문에 수소차나 수소 연료전지 대중화에 걸림돌이 돼왔다\n",
      "백금을 대체할 물질로 탄소 촉매가 거론됐지만 700도 이상의 고온 열처리를 통해 합성되기 때문에 촉매 활성점이 파괴돼 촉매 효율이 떨어지는 문제가 있었다\n",
      "주 교수팀은 촉매 활성점이 파괴되는 것을 막기 위한 '실리카 보호층'을 도입해 이런 문제를 해결했다\n",
      "이 방법으로 개발한 탄소 촉매는 백금 촉매보다 훨씬 저렴하면서도, 산소 환원 반응 효율은 상용 백금 촉매와 유사한 수준을 보였다고 대학 측은 설명했다\n",
      "주 교수는 \"연료전지 상용화에 한 단계 접근할 수 있을 것으로 기대된다\"며 \"이번 연구에서 개발한 합성법은 연료전지 외에도 다양한 에너지 변환 및 저장 장치에 적용될 수 있을 것이다\"고 강조했다\n",
      "16 번 Topic 문장 :\n",
      "UNIST(울산과학기술원)는 수소차에 쓰이는 수소 연료전지를 저렴하게 만들 수 있는 촉매 합성법을 개발했다고 3일 밝혔다\n",
      "백금을 대체할 물질로 탄소 촉매가 거론됐지만 700도 이상의 고온 열처리를 통해 합성되기 때문에 촉매 활성점이 파괴돼 촉매 효율이 떨어지는 문제가 있었다\n",
      "주 교수팀은 촉매 활성점이 파괴되는 것을 막기 위한 '실리카 보호층'을 도입해 이런 문제를 해결했다\n",
      "주 교수는 \"연료전지 상용화에 한 단계 접근할 수 있을 것으로 기대된다\"며 \"이번 연구에서 개발한 합성법은 연료전지 외에도 다양한 에너지 변환 및 저장 장치에 적용될 수 있을 것이다\"고 강조했다\n",
      "17 번 전문 : \n",
      "21세기 컴퓨팅 콘퍼런스 서울 개최\n",
      "\"기계-인간 합쳐 '슈퍼맨' 될 수 있어\"\n",
      "\"우리는 인공지능(AI)이 갖는 잠재력과 힘, 영향력을 모든 사람이 쉽게 사용하고 접근할 수 있도록 민주화하길 바랍니다\"\n",
      "피터 리(Peter Lee) 마이크로소프트연구소 총괄 부사장은 2일 서울 서대문구 연세대에서 열린 '21세기 컴퓨팅 콘퍼런스 2016'에서 AI를 향한 미래 비전을 이같이 강조했다\n",
      "이 행사는 올해로 18번째로, '인간과 AI가 공존하는 시대'라는 주제로 열렸다\n",
      "한국에서 이 행사가 개최된 것은 2007년 이후 9년 만이다\n",
      "컨퍼런스 기조연설하는 피터 리 부사장 (서울=연합뉴스) 윤동진 기자 = 3일 오전 서울 연세대학교 대강당에서 '인간과 AI가 공존하는 시대'를 주제로 열린 21세기 컴퓨팅 컨퍼런스 2016에서 피터 리 마이크로소프트연구소 총괄 부사장이 4차 산업혁명에서 AI가 가져올 변화에 관해 기조연설을 하고 있다\n",
      "2016.11.3 mon@yna.co.kr\n",
      "기조연설자로 나선 리 부사장은 세계적 기업이 연구에 투자하는 목표로 \"세렌디피티(Serendipity)\"라는 단어를 제시하며 연구개발을 꾸준히 해야 한다고 강조했다\n",
      "이는 '우연히 생긴 운 좋은 일', '뜻밖의 일'이란 뜻을 담고 있다\n",
      "지속적인 연구를 통해 많은 이들에게 생각지도 못했던 방법으로 긍정적 혜택을 줄 수 있다는 것이다\n",
      "어느 때보다 빠른 속도로 발전하는 AI, 머신러닝 등의 기술이 큰 변화를 가져올 것이란 관측도 내놓았다\n",
      "피터 리 부사장은 \"컴퓨팅 기술의 발전은 구텐베르크(1452년 독일에서 활판 인쇄술로 성서를 제작해 유럽에서 인쇄업을 대중화한 인물) 시대만큼 큰 변화를 가져올 것\"이라며 \"많은 이가 접근하도록 민주화가 이뤄지길 바란다\"고 말했다\n",
      "기조연설하는 피터 리 부사장 (서울=연합뉴스) 윤동진 기자 = 3일 오전 서울 연세대학교 대강당에서 '인간과 AI가 공존하는 시대'를 주제로 열린 21세기 컴퓨팅 컨퍼런스 2016에서 피터 리 마이크로소프트연구소 총괄 부사장이 4차 산업혁명에서 AI가 가져올 변화에 관해 기조연설을 하고 있다\n",
      "2016.11.3 mon@yna.co.kr\n",
      "그는 AI에 대해 \"기술에 대한 아이디어는 인간과 함께 일하는 것에서 시작된다\"며 \"인류가 더 똑똑해지게, 생산을 높이도록, 행복하게 살 수 있도록 바란다\"고 역설했다\n",
      "도덕이나 일자리 등 일각에서 제기되는 문제점에 대해서는 \"구글, IBM 등 업계가 함께 참여하는 인공지능에 관한 파트너십(Partnership on AI)을 통해 고민하겠다고 강조했다\n",
      "이날 콘퍼런스에 참석한 샤오우엔 혼 마이크로소프트 부사장 역시 \"개인이 일할 때나 생활에서 AI를 쉽게 사용할 수 있도록 민주화를 목표로 하고 있다\"며 힘을 보탰다\n",
      "마이크로소프트 아태지역 연구개발 그룹을 이끌며 연구소 아시아 소장을 맡고 있는 그는 \"AI는 자동차, 비행기처럼 인류를 더 좋게 만들 수 있는 하나의 도구\"라고 말했다\n",
      "샤오우엔 혼 마이크로소프트 부사장샤오우엔 혼 부사장(마이크로소프트연구소 아시아 소장)이 3일 연세대학교 신촌캠퍼스에서 열린 '21세기 컴퓨팅 컨퍼런스 2016’에서 발표를 하고 있다\n",
      "[마이크로소프트코리아 제공=연합뉴스]\n",
      "샤오우엔 혼 부사장은 \"많은 이들이 AI가 인간 지능을 앞설까 걱정하지만 그런 걱정은 필요없다\"면서 \"AI 자체는 프로그래밍할 수 없고 인간이 필요하다\"고 강조했다\n",
      "그는 \"AI의 A는 '인공'(Artificial)이 아니라 '증강'(Augment)으로, 사람과 기계가 합쳐져 슈퍼맨이 될 수 있다\"면서 \"AI와 인간이 함께 발전하는 공진화\"라고 덧붙였다\n",
      "마이크로소프트연구소는 사람의 음성을 인식하는 AI 비서 '코타나'의 국내 출시 가능성도 내비쳤다\n",
      "코타나는 스마트폰과 게임기 '엑스박스 원'에서 쓸 수 있다\n",
      "피터 리 부사장은 한국어 지원 여부에 관한 질문에 대해 \"정확한 날짜는 밝힐 수 없지만, 곧 가능하다\"면서 \"한·중·일 시장은 음성 인식과 관련해 중요한 시장\"이라고 말했다\n",
      "마이크로소프트연구소는 콘퍼런스를 시작으로 4일부터 이틀간 '아시아 연례 교수 회의 2016'을 연다\n",
      "중국과학기술원, 도쿄대, 멜버른대 등의 전문가 250여 명이 참석한다\n",
      "연구소가 해 온 최신 연구 프로젝트 11건과 산학연 협력을 통해 개발 중인 연구 결과 등이 기술 쇼케이스에서 공개될 예정이다\n",
      "17 번 Topic 문장 :\n",
      "\"우리는 인공지능(AI)이 갖는 잠재력과 힘, 영향력을 모든 사람이 쉽게 사용하고 접근할 수 있도록 민주화하길 바랍니다\"\n",
      "피터 리(Peter Lee) 마이크로소프트연구소 총괄 부사장은 2일 서울 서대문구 연세대에서 열린 '21세기 컴퓨팅 콘퍼런스 2016'에서 AI를 향한 미래 비전을 이같이 강조했다\n",
      "이 행사는 올해로 18번째로, '인간과 AI가 공존하는 시대'라는 주제로 열렸다\n",
      "컨퍼런스 기조연설하는 피터 리 부사장 (서울=연합뉴스) 윤동진 기자 = 3일 오전 서울 연세대학교 대강당에서 '인간과 AI가 공존하는 시대'를 주제로 열린 21세기 컴퓨팅 컨퍼런스 2016에서 피터 리 마이크로소프트연구소 총괄 부사장이 4차 산업혁명에서 AI가 가져올 변화에 관해 기조연설을 하고 있다\n",
      "기조연설하는 피터 리 부사장 (서울=연합뉴스) 윤동진 기자 = 3일 오전 서울 연세대학교 대강당에서 '인간과 AI가 공존하는 시대'를 주제로 열린 21세기 컴퓨팅 컨퍼런스 2016에서 피터 리 마이크로소프트연구소 총괄 부사장이 4차 산업혁명에서 AI가 가져올 변화에 관해 기조연설을 하고 있다\n",
      "샤오우엔 혼 마이크로소프트 부사장샤오우엔 혼 부사장(마이크로소프트연구소 아시아 소장)이 3일 연세대학교 신촌캠퍼스에서 열린 '21세기 컴퓨팅 컨퍼런스 2016’에서 발표를 하고 있다\n",
      "18 번 전문 : \n",
      "우리나라 기초연구의 문제가 국가혁신시스템에서 기초연구 전략이 부족하다는 지적이 나왔다\n",
      "과학기술정책연구원(STEPI)이 3일 한국과학기술회관에서 열린 `기초연구 경쟁력, 질적 혁명에서부터`라는 주제 정책포럼에서 이민형 STEPI 선임연구위원은 “정부가 풀뿌리 지원만 강조하는데 `왜 기초연구를 하는가`에 대한 근본적 질문이 없다”고 비판했다\n",
      "기초과학이 국가 성장동력 핵심으로 강조되면서 세계 각 국은 기초연구 투자를 확대하고 있다\n",
      "하지만 우리나라 기초연구 경쟁력은 영향을 미치는 성과가 부족해 과학적 진보, 인류복지 기여 등 국내 경제사회적 문제해결 등 목적을 명시할 필요가 있다는 지적이다\n",
      "이 위원은 “기초연구 시스템의 미성숙으로 기초연구 축적이 부족하다”면서 “기초연구는 눈에 보이지 않는 문화와 자율이 중요한데 정부가 투자 목표 중심의 정책을 펼치고 있다”고 말했다\n",
      "그는 세계적 학술지에 내기 위한 연구만 계속 한다는 것은 방향이 잘못됐다고 덧붙였다\n",
      "연구비 지원 방식도 개편이 필요하다고 주장했다\n",
      "이 위원은 “대학 교수 개인 지원을 하다 보니 개인주의를 촉발하고 폐쇄성으로 나타난다”며 “지원방식을 개선하지 않고 연구장비 공동화를 아무리 외쳐봐야 소용이 없다\n",
      "같이 논의할 수 있는 장이 되도록 연구비 지원을 어떤 방식으로 하는지가 변화에 중요한 영향을 미친다”고 말했다\n",
      "또 인프라를 질적으로 향상시켜야 한다고 강조했다\n",
      "이 위원은 “연구를 하려면 장비 인프라를 다루는 전문적 엔지니어가 있어서 연구자와 함께 협업을 해야 하는데 이 부분은 지원이 안 된다”면서 “지금은 논문 낸 사람만 칭찬 받는데, 논문 결과는 `부분적`이고 한 나라의 과학 활동의 토대를 닦는 것은 인프라로, 이게 갖춰지지 않으면 노벨상은 기대하기 어렵다”고 전했다\n",
      "이날 주제 발표 후에는 정광화 전 기초과학지원연구원 원장을 좌장으로 각 분야 전문가 토론이 이어졌다\n",
      "18 번 Topic 문장 :\n",
      "우리나라 기초연구의 문제가 국가혁신시스템에서 기초연구 전략이 부족하다는 지적이 나왔다\n",
      "과학기술정책연구원(STEPI)이 3일 한국과학기술회관에서 열린 `기초연구 경쟁력, 질적 혁명에서부터`라는 주제 정책포럼에서 이민형 STEPI 선임연구위원은 “정부가 풀뿌리 지원만 강조하는데 `왜 기초연구를 하는가`에 대한 근본적 질문이 없다”고 비판했다\n",
      "기초과학이 국가 성장동력 핵심으로 강조되면서 세계 각 국은 기초연구 투자를 확대하고 있다\n",
      "이 위원은 “연구를 하려면 장비 인프라를 다루는 전문적 엔지니어가 있어서 연구자와 함께 협업을 해야 하는데 이 부분은 지원이 안 된다”면서 “지금은 논문 낸 사람만 칭찬 받는데, 논문 결과는 `부분적`이고 한 나라의 과학 활동의 토대를 닦는 것은 인프라로, 이게 갖춰지지 않으면 노벨상은 기대하기 어렵다”고 전했다\n",
      "19 번 전문 : \n",
      "만성 폐쇄성 폐질환 연구 목적\n",
      "흡연이 폐에 어떤 영향을 미치는 지 정확히 연구할 수 있는 흡연로봇이 개발돼 주목을 받고 있다\n",
      "미국 하버드 대학 위스 응용 생물학 공학 연구소(Wyss Institute for Biologically Inspired Engineering)가 개발한 흡연로봇은 흡입된 연기가 인간의 기관을 모방한 마이크로칩을 통과하기 때문에 흡연이 폐에 어떻게 영향을 미치는지 정확하게 연구할 수 있다\n",
      "이를 통해 연구진은 만성 폐쇄성 폐질환(COPD)과 전자담배에 대한 이해가 깊어질 수 있다는 판단이다\n",
      "흡연이 사람들에게 어떤 영향을 미치는지에 대해 연구해온 와이즈 응용 생물학 공학 연구소의 연구팀은 기존 방식보다 정확한 테스트를 위해 흡연로봇을 개발했다\n",
      "사진에 나온 개틀링 건 또는 회전식 탄창과 같은 부분에는 담배를 최대 12개 꽂을 수 있으며, 로봇이 담배를 피우는 빈도나 빨아들이는 강도, 간격 등의 조건을 설정할 수 있다\n",
      "로봇이 피운 담배 연기는 ‘에어웨이 온 어 칩’(airway on a chip)이라고 불리는 미세한 마이크로 채널을 가진 인공 폐 마이크로 칩에 보내진다\n",
      "마이크로 채널은 건강한 사람 또는 만성 폐쇄성 폐 질환 환자에서 채취된 폐의 세기관지 피막 조직이 붙어 있어 담배 연기가 폐에 어떤 영향을 미치는지 정확히 분석할 수 있다\n",
      "만성 폐쇄성 폐 질환은 일단 발병하면 원래대로 돌아갈 수 없는 질환으로 알려져 있지만, 흡연이 얼마나 만성 폐쇄성 폐 질환을 악화시킬 것인가에 대한 정확한 연구는 적다\n",
      "만성 폐쇄성 폐 질환에 대한 연구가 오랫동안 정체돼 있었기 때문이다\n",
      "이에 생리적 호흡과 인공 폐를 결합한 흡연로봇이 개발된 것으로, 환자의 병세가 유전자에 의한 것인지, 가정환경이나 작업환경에 관련된 것인지 등 개별 흡연자의 조건 비교가 가능해 만성 폐쇄성 폐질환이 악화되는 원인을 밝히는 데 도움이 될 것으로 연구진은 기대하고 있다\n",
      "19 번 Topic 문장 :\n",
      "흡연이 폐에 어떤 영향을 미치는 지 정확히 연구할 수 있는 흡연로봇이 개발돼 주목을 받고 있다\n",
      "미국 하버드 대학 위스 응용 생물학 공학 연구소(Wyss Institute for Biologically Inspired Engineering)가 개발한 흡연로봇은 흡입된 연기가 인간의 기관을 모방한 마이크로칩을 통과하기 때문에 흡연이 폐에 어떻게 영향을 미치는지 정확하게 연구할 수 있다\n",
      "흡연이 사람들에게 어떤 영향을 미치는지에 대해 연구해온 와이즈 응용 생물학 공학 연구소의 연구팀은 기존 방식보다 정확한 테스트를 위해 흡연로봇을 개발했다\n",
      "이에 생리적 호흡과 인공 폐를 결합한 흡연로봇이 개발된 것으로, 환자의 병세가 유전자에 의한 것인지, 가정환경이나 작업환경에 관련된 것인지 등 개별 흡연자의 조건 비교가 가능해 만성 폐쇄성 폐질환이 악화되는 원인을 밝히는 데 도움이 될 것으로 연구진은 기대하고 있다\n",
      "20 번 전문 : \n",
      "애플 '시리'·SKT '누구' 등\n",
      "음성인식 기술 활용 잇따라\n",
      "소음속 음성인식 등은 과제\n",
      "아이폰에서 시리(Siri)를 작동시킨 화면\n",
      "SK텔레콤의 음성인식 기반 인공지능 서비스 기기 ‘누구(NUGU)’\n",
      "“다른 누구도 당신처럼 사랑한 적은 없어요.” “저도요\n",
      "이제 우리는 사랑하는 법을 아는 거겠죠.”\n",
      "영화 ‘허(Her·2014)’에서 주인공 ‘테어도르’와 음성인식 운영체제(OS) ‘사만다’가 나누는 대화다\n",
      "영화에서 그리는 기술은 단순히 음성을 인식하는 차원을 넘어 문맥 속에서 감정과 의도를 읽고 교감까지 한다\n",
      "기계가 인간에 가깝게 진화하는 것으로 음성인식 기술의 궁극적 발전 단계에 속한다\n",
      "애플 ‘시리(Siri)’, SK텔레콤 ‘누구(NUGU)’ 등이 완벽하지는 않지만 현실 속의 사만다라 할 수 있다\n",
      "일정을 챙기는 비서 역할을 비롯해 자동차 내비게이션·채팅봇 등으로 음성인식 기술이 활용되고 있다\n",
      "삼성전자는 지난달 시리를 만든 비브랩스(VIV Labs)를 인수하고 새로운 서비스 출시를 예고하며 음성인식 기술에 대한 관심을 고조시켰다\n",
      "그렇다면 음성인식은 어떻게 작동할까\n",
      "음성인식은 사람 입에서 나온 음성신호를 자동으로 인식해 문자열로 변환해주는 과정 혹은 기술이다\n",
      "사람이 의사소통하듯 듣기와 인지의 과정을 거친다\n",
      "박범근 연구성과실용화진흥원 매니저는 “음성인식은 음성으로부터 추출한 독특한 특성을 이용하는 인식기술”이라며 “비강과 구강·구강 모양 등에 의한 음성학적 특성을 이용한다”고 설명했다\n",
      "음성인식 단계는 크게 음성인식(전처리)→자연어(일상 언어) 이해→자연어 응답→음성합성으로 이어진다\n",
      "생활 속 듣기에 해당하는 전처리에서는 이용자가 “오늘 날씨 어때”라고 물으면 기계가 ‘O’‘ㅗ’ 등 음운마다 다른 주파수를 통해 질문이 날씨라는 것을 인지한다\n",
      "자연어 이해에서는 질문의 의도를 알고 기상청 등을 통해 현재 날씨·기온 등을 파악한다\n",
      "자연어 응답에서는 음운을 조합해 문장으로 변환하고 음성합성에서는 문장을 읽어준다\n",
      "전처리시 주파수 등 주기적으로 반복되는 패턴을 추출하고 이를 미리 수집된 음성 모델 데이터베이스(DB)와 비교해 얼마나 유사한지 파악한다\n",
      "이를테면 사람이 ‘신문을 읽다’라고 말하면 기계는 이를 ‘신무늘 익따’로 듣는다\n",
      "이 과정에서 음성인식 기술은 저장된 DB에서 ‘을’과 ‘늘’이라는 두 개의 후보단어를 만든다\n",
      "목적어·조사·서술어 등 문장구조를 분석하면서 ‘늘’이라는 조사는 존재하지 않는다는 점을 파악해 ‘을’을 선택한다\n",
      "가장 적합한 어휘·문장구조 분석을 통해 ‘신문을 읽다’라는 문장을 인식하게 되는 셈이다\n",
      "문장을 정확하게 인식하기 위해 전문기관에서는 일정량 이상의 음성 DB를 수집하는 데 주력한다\n",
      "많은 사람을 모아 특정한 문장을 주고 읽게 한 뒤 녹음해 자료를 축적하는 방식이다\n",
      "이런 방식으로 일정량을 모아 일종의 표본이 되는 원형(프로토타입)을 만든다\n",
      "이후에는 서비스하면서 입력되는 각종 로그데이터(오류·장애로부터의 복원에 필요한 정보)를 이용해 계속 성능을 높여간다\n",
      "국내에서는 한국전자통신연구원(ETRI)이 수집한 2,000여개의 목소리를 활용해 한글과컴퓨터·제타뱅크 등이 관련 서비스를 선보였다\n",
      "DB에 기반을 둔 음성인식은 대부분 확률통계 방식으로 이뤄진다\n",
      "명령이 떨어졌을 때 경험상 가장 어울리는 반응을 내놓는다\n",
      "하지만 DB에 모든 경우가 포함될 수 없고 수집되지 않은 정보가 많을수록 오답률은 높아진다\n",
      "인간 뇌에 해당하는 인공지능(AI)이 중요한 이유다\n",
      "올해 오답률을 줄여줄 수 있는 획기적인 AI가 등장했는데 바로 ‘알파고’다\n",
      "알파고는 기존과 달리 딥러닝의 일종인 ‘DNN(Deep Neural Network)’이라는 통계방식을 활용했다\n",
      "외부적으로 입력된 데이터뿐 아니라 기계 스스로 학습해 방대한 데이터를 축적하고 통계의 신뢰도와 정확성을 높였다\n",
      "음성인식 기기를 AI와 마이크·스피커로 나눴을 때 AI는 상당한 진전을 이룬 반면 마이크·스피커는 아직 마이크 입력 문제에서 자유롭지 못하다\n",
      "거리가 멀거나 잡음이 발생했을 때 제대로 작동하지 않는 것이다\n",
      "SK텔레콤 종합기술원 관계자는 “발화자와 기기 간 거리가 3m만 돼도 마이크에 들어오는 신호가 거의 잡히지 않아 인식이 어렵다”며 “사람 귀처럼 2개 이상의 마이크를 사용해 거리 제약을 극복하는 방법 등이 해결책으로 떠오르는 상황”이라고 설명했다\n",
      "20 번 Topic 문장 :\n",
      "기계가 인간에 가깝게 진화하는 것으로 음성인식 기술의 궁극적 발전 단계에 속한다\n",
      "삼성전자는 지난달 시리를 만든 비브랩스(VIV Labs)를 인수하고 새로운 서비스 출시를 예고하며 음성인식 기술에 대한 관심을 고조시켰다\n",
      "박범근 연구성과실용화진흥원 매니저는 “음성인식은 음성으로부터 추출한 독특한 특성을 이용하는 인식기술”이라며 “비강과 구강·구강 모양 등에 의한 음성학적 특성을 이용한다”고 설명했다\n",
      "21 번 전문 : \n",
      "임지선 박사 \"자기계발 여가부터 보장돼야 변화 대처 가능\"\n",
      "인간의 일자리를 위협하는 인공지능 기술\n",
      "인공지능(AI)이 인간의 일자리를 대거 대체하는 '4차 산업혁명'으로 발생할 수 있는 대규모 실업 문제를 해결하려면 현행 노동시간부터 줄여야 한다는 전문가 진단이 나왔다\n",
      "복잡한 정신노동까지 인간 대신 기계가 하게 되는 이런 시기에 노동자들이 자생력을 키우려면 충분한 여가를 보장해줘야 한다는 얘기다\n",
      "연세대 바른ICT연구소의 임지선 박사는 2일 연세대 신촌 캠퍼스에서 열리는 '바른 ICT 리서치 컨퍼런스 2016'의 발표 자료에서 \"4차 산업혁명 시대에서는 수동적 노동자가 능동적 생산자로 바뀔 수 있는 재교육 기회가 매우 중요하다\"며 이처럼 주장했다\n",
      "경제학을 전공한 임 박사는 \"4차 산업혁명은 AI·로봇·사물 인터넷 등의 영향 때문에 고용 창출보다 대체 효과가 더 클 것으로 관측된다\"며 \"이로 인한 일자리 양극화와 소득 불평등 문제를 해결하려면 노동시간을 줄여 인적자원개발의 여건을 개선해야 한다\"고 설명했다\n",
      "그는 현재 한국에서는 노동시간이 너무 길어 자기계발을 할 상황 자체가 안되는 경우가 많다고 지적하고, 일하는 시간이 줄면 이직·업무 전환을 준비할 여력이 늘어나 노동시장의 유연성도 개선될 수 있다고 내다봤다\n",
      "임 박사는 평생 교육의 중요성도 강조했다\n",
      "빠른 산업 변화로 대다수 노동자가 계속 새 지식을 배워야 하지만, 경직된 학교 교육으로는 이런 수요를 맞출 수 없다는 것이다\n",
      "특히 정보기술의 발달로 교육에 대한 진입장벽과 비용이 떨어지는 만큼, 각 노동자의 지적 필요에 맞게 부담 없이 재교육·직업교육을 받을 수 있는 환경을 마련해야 한다고 임 박사는 당부했다\n",
      "그는 \"또 정부는 급격하게 발전하는 정보기술을 토대로 전자정부를 고도화해 자원배분을 효율화하고, 노동자들이 공공 데이터를 자유롭게 활용해 경쟁력을 높일 수 있도록 할 필요가 있다\"고 덧붙였다\n",
      "21 번 Topic 문장 :\n",
      "인공지능(AI)이 인간의 일자리를 대거 대체하는 '4차 산업혁명'으로 발생할 수 있는 대규모 실업 문제를 해결하려면 현행 노동시간부터 줄여야 한다는 전문가 진단이 나왔다\n",
      "연세대 바른ICT연구소의 임지선 박사는 2일 연세대 신촌 캠퍼스에서 열리는 '바른 ICT 리서치 컨퍼런스 2016'의 발표 자료에서 \"4차 산업혁명 시대에서는 수동적 노동자가 능동적 생산자로 바뀔 수 있는 재교육 기회가 매우 중요하다\"며 이처럼 주장했다\n",
      "특히 정보기술의 발달로 교육에 대한 진입장벽과 비용이 떨어지는 만큼, 각 노동자의 지적 필요에 맞게 부담 없이 재교육·직업교육을 받을 수 있는 환경을 마련해야 한다고 임 박사는 당부했다\n",
      "22 번 전문 : \n",
      "미래창조과학부는 박재형 성균관대 교수 연구팀이 나노로봇(10억분의 1ｍ 크기의 초미세 로봇)을 이용해 외과 수술 없이 종양을 치료하는 기술을 개발했다고 1일 발표했다\n",
      "이번에 개발된 금·티타늄 재질의 나노로봇은 체내에 주입되면 종양을 추적해 달라붙는다\n",
      "이후 환부에 초음파를 쏘면 이에 반응한 로봇이 ‘활성산소종’이란 분자를 다량 방출해 암세포를 공격한다\n",
      "연구팀은 생쥐 실험에서 종양 성장을 억제하는 효과를 입증했다고 설명했다\n",
      "박 교수는 “나노로봇은 정확하게 암을 선별해 공격할 수 있다”며 “정상 세포를 해칠 수 있는 방사선 치료 등에 비해 부작용이 훨씬 줄어들 것으로 보인다”고 말했다\n",
      "이어 “체내 독성연구 등을 마치면 임상실험에 들어갈 수 있을 것”이라고 덧붙였다\n",
      "이번 연구 결과는 국제 학술지 나노레터 지난달 12일자에 게재됐다\n",
      "22 번 Topic 문장 :\n",
      "미래창조과학부는 박재형 성균관대 교수 연구팀이 나노로봇(10억분의 1ｍ 크기의 초미세 로봇)을 이용해 외과 수술 없이 종양을 치료하는 기술을 개발했다고 1일 발표했다\n",
      "이번에 개발된 금·티타늄 재질의 나노로봇은 체내에 주입되면 종양을 추적해 달라붙는다\n",
      "박 교수는 “나노로봇은 정확하게 암을 선별해 공격할 수 있다”며 “정상 세포를 해칠 수 있는 방사선 치료 등에 비해 부작용이 훨씬 줄어들 것으로 보인다”고 말했다\n",
      "23 번 전문 : \n",
      "서울대 연구팀 \"뿌리가 햇빛 분석해 잎과 줄기 생장에 영향 끼쳐\"\n",
      "식물 뿌리가 햇빛을 모니터링해 최적의 생장 환경을 만드는 것으로 파악됐다.잎이 흡수한 햇빛은 줄기와 뿌리의 관다발을 통해 지하의 뿌리까지 전달된다\n",
      "뿌리에 존재하는 피토크롬B(phyB) 광수용체는 뿌리로 전달된 빛을 인식해 HY5 전사인자를 활성화 한다\n",
      "식물에서 뿌리는 사람으로 치자면 '뇌'의 기능을 담당하는 것으로 드러났습니다\n",
      "뿌리는 땅에 묻혀 눈으로 확인하기 쉽지 않습니다\n",
      "국내 연구팀이 식물 뿌리가 햇빛을 모니터링하면서 잎과 줄기 생장에 큰 영향을 끼친다는 사실을 밝혀냈습니다\n",
      "잎과 줄기의 신호를 뿌리가 받아들이고 이를 다시 잎과 줄기 생장에 영향을 끼친다는 것을 보여주고 있습니다\n",
      "식물 뿌리는 식물체를 지지하고 식물 생존에 필요한 모든 물과 양분을 흡수합니다\n",
      "토양 환경을 모니터링 하는 필수적 식물 기관입니다\n",
      "빛에너지를 이용해 공기 중의 이산화탄소를 고정함으로써 지구상의 모든 생물이 필요로 하는 에너지를 공급하는 광합성은 잎에서 일어납니다\n",
      "흙속에 존재하는 뿌리는 햇빛을 직접 인지하지 않고 잎이 받는 빛신호에 의해 수동적으로 영향을 받을 것으로 알려져 있었습니다\n",
      "연구팀은 최근 광화학적 분자생물학적 연구 기술을 융합해 잎에서 흡수된 빛이 광섬유와 비슷한 물리적 구조를 가지는 관다발을 통해 직접 지하의 뿌리까지 전달된다는 사실을 처음으로 증명했습니다\n",
      "뿌리로 전달된 빛은 광수용체 단백질을 활성화시켜 뿌리의 생장과 발달을 촉진하고 나아가 지상부의 잎과 줄기 생장에도 영향을 주고 있다는 내용입니다\n",
      "식물 뿌리가 기존에 알려진 것보다 훨씬 다양한 기능을 한다는 사실을 보여주고 있습니다\n",
      "진화론을 창시한 찰스 다윈은 식물도 두뇌 활동을 하며 동물의 뇌와 유사한 기능을 하는 구조가 뿌리에 존재한다는 '루트-브레인(root-brain)' 가설을 제시했습니다\n",
      "최근 다양한 연구들을 통해 식물 두뇌 활동이 증명되고 있습니다\n",
      "이번 연구 결과는 식물 뿌리가 빛을 포함한 다양한 외부 환경 정보를 수집하고 적절하게 반응한다는 사실을 밝혀냄으로써 앞으로 'root-brain' 가설의 타당성 검증에 크게 기여할 것으로 기대됩니다\n",
      "전달된 빛은 뿌리에 존재하는 피토크롬 광수용체를 통해 인식됨으로써 HY5 전사인자를 활성화 했다\n",
      "빛 신호에 의해 활성화된 HY5 전사인자는 다양한 유전자들의 발현을 촉진해 뿌리의 형태와 생장을 조절하는 기능을 담당한다\n",
      "식물 뿌리는 모든 토양 환경신호를 받아들여 병균, 가뭄, 염분 등의 환경스트레스에 대한 저항력을 증진하고 나아가 식물의 생존을 보장합니다\n",
      "연구팀은 이번 연구를 통해 광수용체 단백질과 신호전달 단백질들을 분리 동정했습니다\n",
      "이들 단백질 유전자들을 이용한 유전자조작을 통해 식물 뿌리의 빛 인지 능력을 높일 수 있습니다\n",
      "뿌리의 형태적 구조를 보강함으로써 토양환경스트레스에 대한 저항력을 높이고 나아가 생산성과 상품성이 향상된 농작물 신품종 개발 연구에 응용 가능하다고 연구팀은 전했습니다\n",
      "이번 연구는 박충모 서울대 화학부 교수가 수행했습니다\n",
      "연구 결과는 국제 학술지 사이언스 시그널링(Science Signaling) 11월2일자(우리나라 시간, 논문명: Stem-piped light activates phytochrome B to trigger light responses in Arabidopsis roots)에 실렸습니다\n",
      "박충모 교수는 \"찰스 다윈은 자신의 연구를 종합했을 때 식물도 지능행동을 하고 그 중심에는 뿌리가 있을 것이란 가설을 세웠다\"며 \"이번 연구결과를 통해 외부 신호를 받아 프로세싱하고 분석하고 명령을 내리는 기능을 뿌리가 하고 있다는 것을 확인했다\"고 말했습니다\n",
      "박 교수는\"뿌리가 이른바 '컨트롤 허브(조절 중심)' 기능을 하고 있다\"고 설명했습니다\n",
      "23 번 Topic 문장 :\n",
      "서울대 연구팀 \"뿌리가 햇빛 분석해 잎과 줄기 생장에 영향 끼쳐\"\n",
      "식물 뿌리가 햇빛을 모니터링해 최적의 생장 환경을 만드는 것으로 파악됐다.잎이 흡수한 햇빛은 줄기와 뿌리의 관다발을 통해 지하의 뿌리까지 전달된다\n",
      "국내 연구팀이 식물 뿌리가 햇빛을 모니터링하면서 잎과 줄기 생장에 큰 영향을 끼친다는 사실을 밝혀냈습니다\n",
      "연구팀은 최근 광화학적 분자생물학적 연구 기술을 융합해 잎에서 흡수된 빛이 광섬유와 비슷한 물리적 구조를 가지는 관다발을 통해 직접 지하의 뿌리까지 전달된다는 사실을 처음으로 증명했습니다\n",
      "이번 연구 결과는 식물 뿌리가 빛을 포함한 다양한 외부 환경 정보를 수집하고 적절하게 반응한다는 사실을 밝혀냄으로써 앞으로 'root-brain' 가설의 타당성 검증에 크게 기여할 것으로 기대됩니다\n",
      "박충모 교수는 \"찰스 다윈은 자신의 연구를 종합했을 때 식물도 지능행동을 하고 그 중심에는 뿌리가 있을 것이란 가설을 세웠다\"며 \"이번 연구결과를 통해 외부 신호를 받아 프로세싱하고 분석하고 명령을 내리는 기능을 뿌리가 하고 있다는 것을 확인했다\"고 말했습니다\n",
      "24 번 전문 : \n",
      "연못이나 논에 사는 연잎은 물에 젖지 않고 진흙탕에서도 잘 더러워지지 않는다\n",
      "연잎 표면이 미세한 돌기로 덮여있어 물이 스며들지 않고 물방울이 동그랗게 맺혀 그대로 미끄러진다\n",
      "이런 ‘연잎 효과’를 흔히 과학용어로 ‘초소수성’이라고 한다\n",
      "이런 특성을 이용하면 음료를 쏟아도 묻지 않는 옷감이나 비가 오면 스스로 먼지를 청소하는 외벽 자재를 만들 수 있어 과학자들은 관련 연구를 활발히 하고 있다\n",
      "하지만 지금까지 개발된 초소수성 물질을 만드는 방법은 제조공정이 복잡하고 독성이 강한 물질을 써야 하는 단점이 있다\n",
      "국내 대학에 다니는 학부 학생이 이런 한계를 극복한 방법을 알아내 최근 화제가 되고 있다\n",
      "포스텍은 기계공학과 4학년에 다니는 유재원씨(가운데)가 같은 과 김동성 교수(왼쪽)와 최동휘 연구교수(오른쪽)의 지도를 받아 소금을 이용해 물을 흡수하지 않고 튕겨내는 초소수성 표면을 간단히 제작하는 방법을 개발했다고 1일 발표했다\n",
      "기존 방식은 값비싼 장비를 이용해야 하고 독한 화학약품 처리 과정을 거쳤다\n",
      "물을 튕겨내도록 물질 표면에 연잎처럼 수 마이크로미터(㎛)와 수 나노미터(1㎚=10억분의 1m) 크기 돌기를 번갈아 만들어 울퉁불퉁한 구조를 만들어야 했기 때문이다\n",
      "반면 유씨가 개발한 방법은 흔히 주변에서 손쉽게 구할 수 있는 소금과 물만을 이용한다\n",
      "그만큼 환경 친화적이고 비싼 장비나 복잡한 공정도 필요없다\n",
      "연구진은 염용해식각법이란 방법을 이용했다\n",
      "액상 실리콘과 폴리디메틸실록산(PDMS)으로 만든 표면에 소금을 뿌려 건조시킨 뒤 물에 녹이면 소금 입자가 있던 자리에 마치 돌기처럼 다양한 크기 미세 구조물이 생긴다\n",
      "김 교수는 “이런 방법을 이용하면 넓은 면적이나 입체 곡면 기판 위에도 원하는 형상의 초소수성 표면을 구현할 수 있다”고 했다\n",
      "초소수성 물질은 활용범위가 넓어지고 있다\n",
      "자기 세정 작용뿐 아니라 산화 방지 능력이 뛰어나 차량 소재, 옷감, 건물 외장재 등 다양한 분야에서 쓸 수 있다\n",
      "눈이나 서리맺힘도 막을 수 있다\n",
      "이번 연구는 유씨가 참여한 학교 학부생 연구참여 프로그램 중 하나로 진행됐다\n",
      "연구 성과는 국제학술지 ‘어플라이드 서피스 사이언스’ 최신호에도 실렸다\n",
      "유씨는 학부생 중 이례적으로 최 연구교수와 함께 논문 제1 저자로 이름을 올렸다\n",
      "24 번 Topic 문장 :\n",
      "포스텍은 기계공학과 4학년에 다니는 유재원씨(가운데)가 같은 과 김동성 교수(왼쪽)와 최동휘 연구교수(오른쪽)의 지도를 받아 소금을 이용해 물을 흡수하지 않고 튕겨내는 초소수성 표면을 간단히 제작하는 방법을 개발했다고 1일 발표했다\n",
      "반면 유씨가 개발한 방법은 흔히 주변에서 손쉽게 구할 수 있는 소금과 물만을 이용한다\n",
      "액상 실리콘과 폴리디메틸실록산(PDMS)으로 만든 표면에 소금을 뿌려 건조시킨 뒤 물에 녹이면 소금 입자가 있던 자리에 마치 돌기처럼 다양한 크기 미세 구조물이 생긴다\n",
      "25 번 전문 : \n",
      "슈퍼컴퓨터 전문가인 김문주 박사가 한국의 슈퍼컴퓨터 정책에 쓴소리를 했다\n",
      "그는 IBM에서 30년간 몸담고 일하며 슈퍼컴퓨터 개발에 핵심 역할을 했다\n",
      "슈퍼컴퓨터와 관련한 수백건 발명과 특허 등을 개발한 인물이다\n",
      "2009년 IBM 퇴임 당시에는 `수석발명가`라는 호칭을 받았다\n",
      "수석발명가는 IBM에서 최고 개발자에게 붙여준다\n",
      "김 박사가 두 번째로 얻었다\n",
      "김 박사는 “한국에 알파고 이후 인공지능(AI) 열풍이 불고 있는데, 이미 미국에서는 AI가 체스를 이겨 충격을 받은 지 오래”라며 “AI는 슈퍼컴퓨터 없이는 구현할 수가 없는데, 한국이 개발하겠다는 AI 소프트웨어만 갖고는 할 수 있는 게 없다”고 지적했다\n",
      "구글이 개발에 몰두하고 있는 것은 `슈퍼컴퓨터`란 뜻이다\n",
      "실제로 구글은 지난해 AI로 쓰기 위해 여러 CPU를 하나의 칩에다 패키징한 `텐서프로세싱유닛(TPU)` 칩세트를 공개했다\n",
      "구글은 CPU, GPU, FPGA를 하나의 칩에다 넣고 멀티 패키징을 했다\n",
      "구글은 `스트리트뷰`라는 슈퍼컴퓨터도 자체적으로 만들었다\n",
      "김 박사는 “AI를 구현하려면 하드웨어는 당연히 같이 개발돼야 한다”며 “한국 프로젝트는 한국적인 슈퍼컴퓨터 플랫폼을 만들어 핵심(Core) 기술을 개발하려는 것이 아니라 외국 컴퓨터를 몇 대 사오려고 하는 것 같다”고 말했다\n",
      "그는 중국과 IBM의 슈퍼컴퓨터 개발 프로젝트(2006~2008년, 863프로그램)에 핵심 멤버로 참여했다\n",
      "그러다 미국 정부가 핵심 기술을 유출해선 안 된다고 막았고, IBM은 프로젝트를 중단했다\n",
      "중국은 단 10년 만에 93PF(페타플롭)의 선웨이 타이후라이트(Sunway TaihuLight)를 개발해 IBM을 뛰어넘었다\n",
      "중국은 멀티코어 CPU도 자체 개발해서 인텔 기술을 뛰어 넘으려 하고 있다\n",
      "슈퍼컴퓨터는 실생활에 혁신을 가져올 수 있다\n",
      "일례로 `의료 혁신`이다\n",
      "그는 “현재 위, 담낭 등의 사이즈를 엑스레이로 정확히 측정하기 어렵고 슈퍼컴퓨터로 구현하려면 10~11시간을 기다려야 하는데, 이를 1분 안에 할 수 있으면 개인 맞춤형 의료가 가능해진다”고 말했다\n",
      "우리나라 슈퍼컴퓨터 개발 기술 수준은 0.1PF으로 매운 낮은 수준이다\n",
      "미래부는 10년간 1000억원을 들여 슈퍼컴퓨터를 개발한다고 지난 4월 밝혔다\n",
      "김 박사는 “슈퍼컴퓨터 공통 플랫폼(Common Platform)을 먼저 만들어야 한다”면서 “집을 지을 때 상세한 청사진이 있는 것처럼 한국적인 플랫폼을 우선 만들고 필요한 부가 기능은 API로 연결하면 자연적으로 기술 산업화가 이뤄질 수 있다”고 말했다\n",
      "그는 디지털 시스템을 뛰어넘어 빅데이터, AI에서 쓸 수 있는 슈퍼컴퓨터 특허를 갖고 있다\n",
      "필요시 조국인 한국에 기부하겠다는 의사도 밝혔다\n",
      "김 박사는 “이 플랫폼을 만드는 핵심기술인 인 하이브리드 멀티코어(hybrid multicore), 반뉴먼 아키텍처(Van Neuman Architecture) 개선, 여러 IO와 네트워크 방법 특허를 갖고 있으니 한국에 기증할 수 있다”고 말했다\n",
      "김 박사는 IBM에서 CPU, 메모리, 스토리지를 각 5년씩 배웠고 슈퍼컴퓨터를 개발하는 데 꼬박 17년이 걸렸다\n",
      "한국 정부가 정책 방향의 갈피를 잡지 못하고 인재를 놓치고 있는 사이 2020년에 세계 최대 슈퍼컴퓨터를 개발하겠다고 밝힌 중국에서는 그에게 끊임없이 러브콜을 보내고 있다\n",
      "25 번 Topic 문장 :\n",
      "김 박사는 “한국에 알파고 이후 인공지능(AI) 열풍이 불고 있는데, 이미 미국에서는 AI가 체스를 이겨 충격을 받은 지 오래”라며 “AI는 슈퍼컴퓨터 없이는 구현할 수가 없는데, 한국이 개발하겠다는 AI 소프트웨어만 갖고는 할 수 있는 게 없다”고 지적했다\n",
      "김 박사는 “AI를 구현하려면 하드웨어는 당연히 같이 개발돼야 한다”며 “한국 프로젝트는 한국적인 슈퍼컴퓨터 플랫폼을 만들어 핵심(Core) 기술을 개발하려는 것이 아니라 외국 컴퓨터를 몇 대 사오려고 하는 것 같다”고 말했다\n",
      "그는 “현재 위, 담낭 등의 사이즈를 엑스레이로 정확히 측정하기 어렵고 슈퍼컴퓨터로 구현하려면 10~11시간을 기다려야 하는데, 이를 1분 안에 할 수 있으면 개인 맞춤형 의료가 가능해진다”고 말했다\n",
      "김 박사는 “슈퍼컴퓨터 공통 플랫폼(Common Platform)을 먼저 만들어야 한다”면서 “집을 지을 때 상세한 청사진이 있는 것처럼 한국적인 플랫폼을 우선 만들고 필요한 부가 기능은 API로 연결하면 자연적으로 기술 산업화가 이뤄질 수 있다”고 말했다\n",
      "26 번 전문 : \n",
      "12년 전 영국서 찾은 화석 분석… 초식공룡 이구아노돈 뇌조직 판명\n",
      "공룡의 뇌 화석(사진)이 세계 최초로 확인됐다\n",
      "데이비드 노먼 영국 케임브리지대 지구과학부 교수팀은 2004년 영국 서식스 주에서 발견된 화석을 분석한 결과 1억3300만 년 전에 살았던 것으로 추정되는 공룡의 뇌 조직인 것으로 밝혀졌다고 27일(현지 시간) 발표했다\n",
      "　그동안 공룡의 뼈는 화석으로 많이 발견됐지만 뇌 부위는 부드럽고 부패가 빨리 진행돼 화석으로 남아 있는 경우가 없었다\n",
      "다른 화석으로 추정할 수밖에 없었던 공룡의 뇌 구조를 화석으로 직접 확인했다는 점에서 이번 발견은 의미를 가진다\n",
      "노먼 교수팀의 공룡 뇌가 화석으로 남아 있을 수 있었던 까닭은 공룡이 사망 직후 산소가 거의 없고 산성도가 높은 물에 머리가 잠겼기 때문이다\n",
      "일종의 ‘자연적 방부 처리’가 된 셈이다\n",
      "　노먼 교수팀은 뇌 화석의 주인이 공룡 중에서도 ‘이구아노돈’일 것이라고 추정했다\n",
      "이구아노돈은 약 1억3300만 년 전, 중생대 백악기에 살았던 육상 공룡으로 몸길이 9m, 몸무게 3t 정도인 초식 공룡이다\n",
      "26 번 Topic 문장 :\n",
      "공룡의 뇌 화석(사진)이 세계 최초로 확인됐다\n",
      "데이비드 노먼 영국 케임브리지대 지구과학부 교수팀은 2004년 영국 서식스 주에서 발견된 화석을 분석한 결과 1억3300만 년 전에 살았던 것으로 추정되는 공룡의 뇌 조직인 것으로 밝혀졌다고 27일(현지 시간) 발표했다\n",
      "노먼 교수팀의 공룡 뇌가 화석으로 남아 있을 수 있었던 까닭은 공룡이 사망 직후 산소가 거의 없고 산성도가 높은 물에 머리가 잠겼기 때문이다\n",
      "27 번 전문 : \n",
      "\"아름다움과 복잡성 깜짝 놀랄만 해\"\n",
      "뉴호라이즌호가 작년 7월부터 수집한 명왕성의 데이터를 모두 지구로 전송하는데 성공했다\n",
      "스페이스닷컴 등 외신은 나사 우주선 뉴호라이즌호가 명왕성을 저공비행하며 촬영한 데이터의 마지막 조각까지 전송했다고 28일 보도했다\n",
      "뉴호라이즌호는 지난 2006년 1월 지구에서 출발해 약 10년에 달하는 비행 끝에 작년 7월 명왕성 1만2500km미터까지 접근하는데 성공했다\n",
      "뉴호라이즌 호의 모습\n",
      "접근에 성공한 우주선은 저공 비행을 통해 약 50 기가바이트의 데이터를 수집했다\n",
      "수집된 데이터는 가장 중요도가 높은 순서대로 15개월에 걸쳐 지구로 전송됐다\n",
      "나사의 앨런 스턴 뉴호라이즌 연구 책임자는 \"수집한 데이터를 통해 확인한 명왕성과 주변 위성의 아름다움과 복잡성은 우리를 깜짝 놀라게했다\"며 \"이제 지구로 보내진 데이터를 과학적인 관찰을 통해 이해하는 큰 작업이 남아있다\"고 말했다\n",
      "나사는 명왕성 저공비행 데이터의 품질을 확인 한 후 결과물이 만족스러울 경우 뉴호라이즌호를 1억 6천km 떨어진 카이퍼 벨트트 소속의 천체 2014 MU69로 향하는 추가 임무를 진행할 예정이다\n",
      "27 번 Topic 문장 :\n",
      "뉴호라이즌호가 작년 7월부터 수집한 명왕성의 데이터를 모두 지구로 전송하는데 성공했다\n",
      "스페이스닷컴 등 외신은 나사 우주선 뉴호라이즌호가 명왕성을 저공비행하며 촬영한 데이터의 마지막 조각까지 전송했다고 28일 보도했다\n",
      "나사의 앨런 스턴 뉴호라이즌 연구 책임자는 \"수집한 데이터를 통해 확인한 명왕성과 주변 위성의 아름다움과 복잡성은 우리를 깜짝 놀라게했다\"며 \"이제 지구로 보내진 데이터를 과학적인 관찰을 통해 이해하는 큰 작업이 남아있다\"고 말했다\n",
      "28 번 전문 : \n",
      "다른 파장 영역에서 더 상세한 관찰 가능해\n",
      "서로 다른 파장 영역에서 태양의 색깔이 달리 보인다\n",
      "서로다른 두 태양\n",
      "광화문의 태양은\n",
      "다르게 떠오른다\n",
      "태양은 우리 눈에 똑같이 보인다\n",
      "맨눈으로 쳐다볼 수 없을 정도로 강하다\n",
      "파장이 다른 영역에서 태양은 색깔을 달리한다\n",
      "자외선 영역의 파장에서는 태양의 '코로나 홀'을 더 쉽게 관찰할 수 있다\n",
      "구리 빛으로 물든 'AIA 171' 이미지를 말한다\n",
      "반면 붉은 빛의 왼쪽 이미지에서는 '코로나 홀'을 상대적으로 보기 어렵다\n",
      "미국 항공우주국(NASA)의 태양활동관측위성(SDO)이 최근 태양의 비교되는 이미지를 촬영해 28일(현지 시간) 홈페이지에 공개했다\n",
      "서로 다른 색으로 나타나는 태양 이미지는 지난 27일 같은 시간에 촬영된 것이다\n",
      "'코로나 홀'은 우주로 강력한 태양풍을 실어 나르는 자기장 영역이다\n",
      "'코로나 홀'은 지구의 지자기적 영역에 많은 영향을 끼친다\n",
      "태양에 대해 다양한 파장 영역으로 관찰하면 상세한 데이터를 얻을 수 있다\n",
      "28 번 Topic 문장 :\n",
      "자외선 영역의 파장에서는 태양의 '코로나 홀'을 더 쉽게 관찰할 수 있다\n",
      "미국 항공우주국(NASA)의 태양활동관측위성(SDO)이 최근 태양의 비교되는 이미지를 촬영해 28일(현지 시간) 홈페이지에 공개했다\n",
      "태양에 대해 다양한 파장 영역으로 관찰하면 상세한 데이터를 얻을 수 있다\n",
      "29 번 전문 : \n",
      "카이스트 연구팀 개발, 차세대 저장매체에 응용가능\n",
      "전기장 인가를 통한 자성 방향의 변화를 나타낸 개념도\n",
      "자석 아닌 물질에 자성(磁性)을 갖게 하는 기술이 개발됐다\n",
      "카이스트(KAIST) 물리학과 양찬호 교수 연구팀이 전기장을 통해 자석이 아닌 물질이 자성을 갖게 하거나 그 반대로 자석 내의 자성을 없앨 수 있는 기술을 내놓아 눈길을 끈다\n",
      "이번 연구를 응용하면 자성 물질 기반의 저장 매체를 개발해 대용량의 정보를 빠른 속도로 이용할 수 있을 것으로 기대된다\n",
      "물질의 내부에는 아주 작은 자석들이 존재한다\n",
      "그 작은 자석들이 무질서하게 여러 방향으로 향하고 있으면 비 자성 상태이고 일정한 방향으로 정렬이 이뤄지면 우리가 흔히 볼 수 있는 자석이 된다\n",
      "정보를 자성 상태로 기록하면 속도가 빠르고 피로 누적 현상을 없앨 수 있기 때문에 저장 매체의 최소 저장 공간인 셀(Cell)을 자성 물질로 구성하려는 시도가 많았다\n",
      "주로 전류의 흐름을 통해 유도된 자기장을 이용하는 방식이다\n",
      "자기장은 자폐가 매우 어려워 넓은 범위에 영향을 끼치기 때문에 인접한 셀의 자성도 변화시킨다\n",
      "셀 하나하나를 조절할 수 없기 때문에 일정한 방향으로 정렬시킬 수 없어 자성의 상태를 바꾸기가 어려웠다\n",
      "연구팀은 문제 해결을 위해 자기전기 상호작용을 통해 자성 상태를 조절했다\n",
      "자기전기 상호작용은 자기장이 아닌 전기장을 이용해 전류의 흐름 없이 자성 상태를 조절하는 방식으로 에너지 소모가 적다는 장점을 갖는다\n",
      "연구팀은 실험을 통해 전기장 인가만으로 무질서하게 임의의 방향을 향하고 있는 셀들이 일정한 방향을 향하고 있음을 확인했다\n",
      "또 반대로 일정한 방향에서 다시 무질서한 상태로도 변화가 가능함을 증명했다\n",
      "기존에 보고된 자기전기 현상은 통상적으로 극저온이나 고온에서 발현이 가능했다\n",
      "이번 기술은 화학적 도핑을 통해 상온에서도 작동이 가능하고, 변환이 가역적이며 비휘발성을 갖기 때문에 차세대 정보 저장 소자 개발의 발판이 될 것으로 기대된다\n",
      "양 교수는 \"이번 전기적 자성상태의 변화는 엔트로피 변화를 동반하고 있을 것으로 예상한다\"며 \"자기전기 소자 응용뿐 아니라 열전 현상의 새로운 가능성을 열 것으로 기대된다\"고 말했다\n",
      "29 번 Topic 문장 :\n",
      "자석 아닌 물질에 자성(磁性)을 갖게 하는 기술이 개발됐다\n",
      "카이스트(KAIST) 물리학과 양찬호 교수 연구팀이 전기장을 통해 자석이 아닌 물질이 자성을 갖게 하거나 그 반대로 자석 내의 자성을 없앨 수 있는 기술을 내놓아 눈길을 끈다\n",
      "이번 연구를 응용하면 자성 물질 기반의 저장 매체를 개발해 대용량의 정보를 빠른 속도로 이용할 수 있을 것으로 기대된다\n",
      "자기전기 상호작용은 자기장이 아닌 전기장을 이용해 전류의 흐름 없이 자성 상태를 조절하는 방식으로 에너지 소모가 적다는 장점을 갖는다\n",
      "이번 기술은 화학적 도핑을 통해 상온에서도 작동이 가능하고, 변환이 가역적이며 비휘발성을 갖기 때문에 차세대 정보 저장 소자 개발의 발판이 될 것으로 기대된다\n",
      "30 번 전문 : \n",
      "화성 유인탐사 경쟁 후끈\n",
      "　1969년 인류가 달에 첫발을 내디딘 후, 사람들은 다음 목표로 화성을 주목해 왔다\n",
      "47년이 흐른 지금, 40대 이상의 무인 우주선이 화성으로 떠났지만 아직 인류의 발자국을 남기지는 못했다\n",
      "인류는 언제쯤 화성에 도착할 수 있을까\n",
      "　현시점에서 가장 빨리 화성에 도달할 나라는 미국이다\n",
      "먼저 미국 정부, 즉 미국항공우주국(NASA)이 꼽힌다\n",
      "여기에 질세라 민간 우주기업 스페이스X도 화성 유인 탐사를 준비하고 있어 둘 중 누가 먼저 화성에 도착하게 될지 관심이 모아지고 있다\n",
      "○ 검증된 기술 통해 확실하게 도전\n",
      "　NASA는 ‘다소 늦더라도 안전한’ 방법을 선택했다\n",
      "검증된 기술 위주로 강력한 로켓을 만들어 실패 없이 한 번에 화성까지 도달할 계획이다\n",
      "목표는 2030년이다\n",
      "　NASA는 화성 탐사를 위해 신형 2단 로켓 ‘우주발사시스템(SLS)’ 로켓을 개발 중이다\n",
      "SLS는 그동안 NASA가 개발했던 어떤 로켓보다 거대하고 추진력도 강하다\n",
      "2단으로 구성돼 있고 지구를 탈출할 힘을 얻는 1단 추진체는 여러 대의 로켓을 하나로 묶는 ‘클러스터링’ 기법으로 만든다\n",
      "우주왕복선에 사용했던 ‘RS-25’ 로켓 4개를 이용할 예정이다\n",
      "이렇게 만든 1단 로켓은 1969년 달 유인 탐사선을 실었던 ‘새턴 5’보다 추력은 20% 커졌다\n",
      "새턴5가 캐로신(등유의 일종)을 연료로 사용하는 데 비해 가벼운 수소를 연료로 이용한 덕분에 전체적인 효율은 약 38% 늘어났다\n",
      "　안전 시스템에도 최선을 다할 계획이다\n",
      "화성 탐사 유인 우주선 ‘오리온’이 포함된 2단 로켓에는 발사에 문제가 생길 경우 승무원을 안전한 거리까지 이동시킬 발사 중단 시스템(LAS)이 포함돼 있다\n",
      "승무원들의 생존에 필요한 산소, 질소, 물 등을 저장하는 공간도 따로 마련돼 있다\n",
      "　NASA는 지구 귀환에 쓸 수소연료를 무인 우주선에 실어 미리 화성에 보내 놓을 계획이다\n",
      "지구에서 우주선이 출발할 때 무게를 줄일 수 있기 때문이다\n",
      "화성 표면에 내려앉은 오리온은 수소연료를 충전한 후, 지구 궤도로 다시 돌아오게 된다\n",
      "○ 신기술 총동원, “가장 빨리 화성 도달하겠다”\n",
      "　현실적인 기술로 화성에 도전하는 NASA와 달리 스페이스X는 기술 혁신을 통한 비용 절감을 최대 기치로 내걸고 있다\n",
      "스페이스X가 개발 중인 ‘행성 간 이동 시스템(ITS)’ 로켓의 핵심은 최근 신기술로 각광받고 있는 ‘로켓 재사용’ 기술이다\n",
      "　ITS 로켓은 지구 궤도에서 1단 로켓과 2단 로켓이 분리된 뒤 1단 로켓만 지구로 되돌아오고 2단 로켓은 우주에서 대기한다\n",
      "여기까지는 지난해 12월 로켓 재사용 실험에 성공한 ‘팰컨 9’로켓과 같다\n",
      "그다음 지구로 돌아온 1단 로켓에 2단 로켓과 동일한 크기의 연료 운반선을 결합한 뒤 다시 발사한다\n",
      "두 번째로 발사한 연료 운반선은 우주에서 2단 로켓과 결합해 연료를 공급하고, 연료가 충전된 2단 로켓은 화성으로 향한다\n",
      "마지막엔 연료 운반선마저 지구로 귀환한다\n",
      "ITS는 이렇게 발사체의 거의 모든 부분을 재사용하기 때문에 발사 비용을 6200만 달러(약 704억 원)까지 낮출 수 있다\n",
      "이는 NASA의 SLS 로켓 발사 비용의 10분의 1 수준이다\n",
      "　ITS는 연료로 메탄을 사용한다\n",
      "지구로 돌아올 때는 화성에서 직접 메탄을 만들어 연료로 쓸 계획이다\n",
      "화성의 대기는 95%가 이산화탄소인데, 지구에서 준비해 간 수소와 결합하면 손쉽게 메탄을 만들 수 있다\n",
      "ITS의 1단 로켓에는 메탄을 연료로 쓰는 ‘랩터’ 엔진 42개가 들어간다\n",
      "개발에 성공한다면 로켓에 사용되는 최초의 메탄 엔진이 된다\n",
      "　옥호남 한국항공우주연구원 발사체기술개발단장은 “NASA와 스페이스X는 서로 간의 경쟁을 통해 유인 화성 탐사를 앞당기고 있다”라며 “지금으로선 NASA의 계획이 좀 더 현실성이 있지만 스페이스X의 계획도 아주 허황되지는 않다”라고 말했다\n",
      "화성에 도전하는 첨단과학기술은 월간 과학동아 11월호에서 자세히 볼 수 있다\n",
      "30 번 Topic 문장 :\n",
      "　1969년 인류가 달에 첫발을 내디딘 후, 사람들은 다음 목표로 화성을 주목해 왔다\n",
      "47년이 흐른 지금, 40대 이상의 무인 우주선이 화성으로 떠났지만 아직 인류의 발자국을 남기지는 못했다\n",
      "　현시점에서 가장 빨리 화성에 도달할 나라는 미국이다\n",
      "여기에 질세라 민간 우주기업 스페이스X도 화성 유인 탐사를 준비하고 있어 둘 중 누가 먼저 화성에 도착하게 될지 관심이 모아지고 있다\n",
      "　NASA는 화성 탐사를 위해 신형 2단 로켓 ‘우주발사시스템(SLS)’ 로켓을 개발 중이다\n",
      "2단으로 구성돼 있고 지구를 탈출할 힘을 얻는 1단 추진체는 여러 대의 로켓을 하나로 묶는 ‘클러스터링’ 기법으로 만든다\n",
      "화성 탐사 유인 우주선 ‘오리온’이 포함된 2단 로켓에는 발사에 문제가 생길 경우 승무원을 안전한 거리까지 이동시킬 발사 중단 시스템(LAS)이 포함돼 있다\n",
      "　현실적인 기술로 화성에 도전하는 NASA와 달리 스페이스X는 기술 혁신을 통한 비용 절감을 최대 기치로 내걸고 있다\n",
      "스페이스X가 개발 중인 ‘행성 간 이동 시스템(ITS)’ 로켓의 핵심은 최근 신기술로 각광받고 있는 ‘로켓 재사용’ 기술이다\n",
      "　옥호남 한국항공우주연구원 발사체기술개발단장은 “NASA와 스페이스X는 서로 간의 경쟁을 통해 유인 화성 탐사를 앞당기고 있다”라며 “지금으로선 NASA의 계획이 좀 더 현실성이 있지만 스페이스X의 계획도 아주 허황되지는 않다”라고 말했다\n",
      "31 번 전문 : \n",
      "- 기어 조작은 베트남 전쟁 당시 기관총 조작에 쓰였던 조종간이다\n",
      "- 배기량 3리터, 출력 210 마력의 엔진은 부서진 2002년형 아우디 V6 엔진에서 가져왔다\n",
      "엔진 가격은 450달러\n",
      "- 폰툰은 1988년형 선 트래커 보트에서 가져왔고, 강철로 보강했다\n",
      "지난해, 여기저기 부서진 1969년산 벨 OH-58 카이오와 헬리콥터의 동체가 경매에서 3,101달러에 팔렸다\n",
      "이 헬리콥터는 베트남 전쟁에도 참전했고, 연방 마약 수사 기동대에서도 사용되었으며, 이후 퇴역해 테네시 주 내시빌에서 해체되어 부품 조달용으로 사용되다가 홍수에 떠내려갔다\n",
      "하지만 이 헬리콥터는 폐기처분을 면하고 수륙양용 자동차로 제2의 삶을 살게 되었다\n",
      "그것은 이 헬리콥터의 새 주인인 제프 블로크의 공로였다\n",
      "그는 자동차 제작자이며 D.C.의 경찰관이기도 하다\n",
      "그는 몇 년 전부터 헬리콥터를 개조한 경주용차를 만들고 싶어 했다\n",
      "그는 이 헬리콥터를 기증받자 친구와 가족 등 16명의 도움으로 폐기 처분된 헬리콥터를 주행가능한 자동차로 개조했다\n",
      "동체를 1980년대 중반에 출시된 토요타 밴 웨건의 차대에 얹고, 마츠다 미아타 차량의 가벼운 후륜 서스펜션을 장착했다\n",
      "그러나 블로크는 이 차량을 이리저리 짜맞춘 부품들로 이루어진 이상한 덩어리가 아닌, 주행 가능한 헬리콥터처럼 보이게 하고 싶었다\n",
      "그래서 그는 헬리콥터와 차대 사이에 폰툰을 설치해, 안 어울리는 부분을 가렸다\n",
      "그는 이 폰툰(바닥이 평평한 배)이 경기에서 범퍼 역할을 해 줄 수 있음을 알았다\n",
      "또한 차량에 수륙양용 기능을 부여해 줄 수 있음도 알았다\n",
      "“차대를 가리기 위해 설치한 폰툰이 차량을 물 위로 띄워주더군요.”\n",
      "이제 이 차량은 하늘을 제외하면 어디라도 갈 수 있다.지난 5월, 블로크가 만든 이 <레이스콥터>는 뉴 저지 주 밀빌에서 열린 24시간 레몬스 레이스 대회에서 주최자 상을 탔다\n",
      "경기장을 두 바퀴 돌고 나서 아우디 엔진의 밸브가 떨어져 나갔는데도 말이다\n",
      "이 엔진은 패러세일링 보트에서 떼어낸 4엽 프로펠러를 분당 회전수 7,000회로 돌렸다\n",
      "물론 제임스 본드가 타고 다니는 잠수 가능한 로터스 차량이 이거보다는 더 멋지다\n",
      "그러나 이 레이스콥터는 100% 수작업으로 만들어졌으며, 실전 경험도 있다\n",
      "128km(80)\n",
      "레이스콥터가 땅위에서 낼 수 있는속도\n",
      "31 번 Topic 문장 :\n",
      "하지만 이 헬리콥터는 폐기처분을 면하고 수륙양용 자동차로 제2의 삶을 살게 되었다\n",
      "그는 이 헬리콥터를 기증받자 친구와 가족 등 16명의 도움으로 폐기 처분된 헬리콥터를 주행가능한 자동차로 개조했다\n",
      "이제 이 차량은 하늘을 제외하면 어디라도 갈 수 있다.지난 5월, 블로크가 만든 이 <레이스콥터>는 뉴 저지 주 밀빌에서 열린 24시간 레몬스 레이스 대회에서 주최자 상을 탔다\n",
      "32 번 전문 : \n",
      "국내 연구팀, 특정 단백질 증가 현상 찾아내…폐암 조기 진단 키트·신약 개발 기대\n",
      "정상폐와 폐암에서의 USE1의 조절 메커니즘\n",
      "[아시아경제 정종오 기자] 폐암을 조기에 진단할 수 있는 생화학 마커를 국내 연구팀이 발견했습니다\n",
      "폐암환자의 92.5%에서 'USE1' 단백질이 증가돼 있고 이중 13%에서는 USE1 유전자에 돌연변이가 발생해 폐암이 발생한다는 사실을 발견했습니다\n",
      "폐암을 조기에 진단할 수 있는 새로운 생화학적 지표를 확보했습니다\n",
      "'USE1'은 생체 내 단백질의 항상성을 조절하는 유비퀴틴 프로테아좀 시스템을 구성하는 효소 중 하나입니다\n",
      "이번 연구 결과는 폐암에 대한 바이오마커(단백질이나 DNA, RNA, 대사 물질 등을 이용해 몸 안의 변화를 알아낼 수 있는 지표)로 가능해 관심을 모으고 있습니다\n",
      "폐암은 국제적으로 연간 100만 명이 사망하는 치명적 암입니다\n",
      "수십 년 동안 진단과 치료 기술이 개발됐는데 특별한 자각증상이 없고 대부분 진행 암 또는 다른 부위에까지도 전이된 상태에서 발견돼 폐암 환자의 완치율은 30% 이하로 낮습니다\n",
      "폐암을 일찍 발견할 수 있다면 완치율도 높아집니다\n",
      "조기 진단이 되면 생존율을 80% 이상 획기적으로 늘어납니다\n",
      "현재 폐암 진단을 위해서는 이미징 방법(X-ray, CT, MRI 등)에 의존도가 높은 편으로 생화학적 지표로 사용될 수 있는 물질은 발견된 예가 적습니다\n",
      "폐암 진단을 위해 바이오 마커라는 이름으로 제시된 물질들이 존재하는데 여전히 충분한 특이성(specificity)과 민감성(sensitivity)을 나타내지 못하고 있습니다\n",
      "연구팀은 106명의 폐암환자의 폐암 조직과 정상조직의 단백질의 발현 양을 비교 분석한 결과 폐암조직의 92.5%에서 USE1의 발현양이 증가돼 있음을 확인했습니다\n",
      "세포와 동물을 사용해 USE1의 발현양이 증가했을 때 폐암을 증식시킴을 확인했습니다\n",
      "반대로 USE1의 단백질의 발현양이 감소되면 폐암을 감소시킴을 밝혀냈습니다\n",
      "106명의 폐암 환자의 DNA를 분석한 결과 13명의 폐암환자로부터 5종의 USE1 돌연변이를 발견했습니다\n",
      "이들 돌연변이들에 의해 실제로 USE1의 단백질의 발현양이 증가돼 폐암을 유발함을 알아냈습니다\n",
      "초고속 질량 분석기를 이용해 USE1의 결합 단백질을 확인한 결과 세포주기 조절에 중요한 역할을 하는 'APC/C'에 의해 USE1의 발현양이 조절됨을 규명했습니다\n",
      "APC/C는 유비퀴틴 시스템에 관여하는 효소 중 하나입니다\n",
      "이번 연구는 이창환 울산의대 서울아산병원 교수 연구팀이 수행했습니다\n",
      "연구 결과는 국제학술지인 국립암학회지(JNCI) 10월18일자(논문명 : Association of Uba6-specific-E2(USE1) with lung tumorigenesis)에 실렸습니다\n",
      "이창환 교수는 \"이번 연구 성과는 폐암의 발병과 관련된 중요한 핵심 단백질을 발견한 것\"이라며 \"폐암을 진단할 수 있는 특이적 바이오 마커로서 사용할 수 있어 폐암에 관한 이해를 높이고 폐암의 조기 진단 키트와 신약개발 등이 가능하다\"고 말했습니다\n",
      "32 번 Topic 문장 :\n",
      "국내 연구팀, 특정 단백질 증가 현상 찾아내…폐암 조기 진단 키트·신약 개발 기대\n",
      "[아시아경제 정종오 기자] 폐암을 조기에 진단할 수 있는 생화학 마커를 국내 연구팀이 발견했습니다\n",
      "폐암환자의 92.5%에서 'USE1' 단백질이 증가돼 있고 이중 13%에서는 USE1 유전자에 돌연변이가 발생해 폐암이 발생한다는 사실을 발견했습니다\n",
      "수십 년 동안 진단과 치료 기술이 개발됐는데 특별한 자각증상이 없고 대부분 진행 암 또는 다른 부위에까지도 전이된 상태에서 발견돼 폐암 환자의 완치율은 30% 이하로 낮습니다\n",
      "폐암 진단을 위해 바이오 마커라는 이름으로 제시된 물질들이 존재하는데 여전히 충분한 특이성(specificity)과 민감성(sensitivity)을 나타내지 못하고 있습니다\n",
      "연구팀은 106명의 폐암환자의 폐암 조직과 정상조직의 단백질의 발현 양을 비교 분석한 결과 폐암조직의 92.5%에서 USE1의 발현양이 증가돼 있음을 확인했습니다\n",
      "초고속 질량 분석기를 이용해 USE1의 결합 단백질을 확인한 결과 세포주기 조절에 중요한 역할을 하는 'APC/C'에 의해 USE1의 발현양이 조절됨을 규명했습니다\n",
      "이창환 교수는 \"이번 연구 성과는 폐암의 발병과 관련된 중요한 핵심 단백질을 발견한 것\"이라며 \"폐암을 진단할 수 있는 특이적 바이오 마커로서 사용할 수 있어 폐암에 관한 이해를 높이고 폐암의 조기 진단 키트와 신약개발 등이 가능하다\"고 말했습니다\n",
      "33 번 전문 : \n",
      "‘내장형 심장감시장치 장착 테이저’\n",
      "테이저 때문에 죽는 사람은 의외로 많다\n",
      "‘워싱턴 포스트’ 지의 2015년 보도에 따르면, 경찰에게 테이저로 사격을 당한 후 구속 중 사망하는 사람이 1주에 1명 꼴로 발생한다고 한다\n",
      "전도성 전기 병기인 테이저로 인한 중상자 대부분은 근육 마비에 의한 낙상으로 인해 생긴다\n",
      "그러나 증거에 따르면 테이저가 심장 마비를 일으킬 수 있는 것으로 나타났다\n",
      "현재 여러 연구자들은 테이저에 EKG(심전도) 기기를 추가하면 피의자의 심부담을 측정함으로서 피의자의 심장 위험을 막을 수 있다고 생각한다\n",
      "웨이크 포리스트 뱁티스트 메디컬 센터의 응급 의학교수인 윌리엄 보즈먼은 지난 2009년 동료들과 함께, 테이저의 안전성을 철저히 검증했다\n",
      "그들은 테이저에 명중된 사람은 99.75%가 아무 부상이 없거나 경상 이하만을 입는다고 결론지었다\n",
      "보즈먼 교수는 “테이저는 놀랄 만큼 효율적이고 또한 안전합니다\n",
      "경찰관들이 휴대하는 총기나 가스 분사기, 경봉, 맨손 제압 등 다른 체포 수단과 비교해 볼 때 그 어떤 것보다도 안전합니다\n",
      "그러나 세상에 100%는 없습니다\n",
      "구류 중 돌연사가 꾸준히 일어나는 게 그 증거입니다.”라고 말한다\n",
      "테이저에 피격된 사람 250만 명 중 1명은 심장에 무리가 가고, 이 중 일부는 결국 그로 인해 죽게 된다\n",
      "“테이저에 피격된 사람이 의학적으로 문제가 있음을 알게 된다면, 신속하게 응급조치를 취해 그 사람의 생명을 구할 수 있습니다.”\n",
      "1년에 테이저 때문에 죽는 사람이 정확히 몇 명인지는 확실히 발표된 바가 없지만, 보즈먼과 그의 동료들은 더욱 안전한 테이저를 만들고자 한다\n",
      "보즈먼은 테이저의 기본 구조가 EKG 기기와 의외로 유사하다는 데 착안했다\n",
      "두 개의 탐침이 전선을 통해 전자 기기와 연결되어 있는 것이다\n",
      "보즈먼과 동료인 제이슨 스토피라 박사는 두 기기를 결합하는 작업이 가능할 거라고 생각했다.이들은 미국 사법 연구소의 자금 지원을 받아, 테이저에 생체 감시 기능을 부여하는 데 착수했다\n",
      "그들이 도달한 결론은 의외로 간단했다\n",
      "표준형 테이저를 저렴한 기성품 EKG 기기에 연결한 것이다\n",
      "“이들은 기기는 멋지게 작동해 주었습니다\n",
      "표적을 무력화하면서도 표적의 EKG를 획득할 수 있었습니다.”고 주장했다\n",
      "그러나 이 기기는 어디까지나 샘플이다\n",
      "보즈먼과 스토피라는 ‘과학 수사 및 법의학 저널’에 실린 자신들의 연구 결과로 인해, 기존 테이저 제작사들이 의료 기기 제작사들과 협력 관계를 체결해 이와 유사한 기기를 생산하기를 바라고 있다\n",
      "이들은 생체 감시 테이저가 피의자의 심장 정보를 자동적으로 기록하고 심부담이 높을 경우 이를 시청각 수단으로 경고해 주기를 바라고 있다\n",
      "그리고 심장 데이터를 기록한 후 블루투스를 통해 컴퓨터나 스마트폰에 전송하는 후속 기기도 나올 수 있을 것이다\n",
      "보즈먼은 이런 기능이 경찰 및 피의자에게 모두 유용할 거라고 보고 있다\n",
      "“구류 중인 피의자가 급사하는 것은 드물지만 비극적인 일입니다\n",
      "그 경우 경찰은 과실을 저질렀다며 비난을 받게 되죠\n",
      "그런 상황에 대한 걱정은 타당한 것입니다.”\n",
      "그러나 그는 피의자가 약물 사용으로 인한 부정맥이 있는 경우를 예로 든다\n",
      "이 때 테이저로 기록한 피의자의 심장 정보를 분석해 의료 전문가들에게 귀중한 건강 데이터로서 제공한다면, 경찰을 비난으로부터 보호할 수 있는 것이다\n",
      "보즈먼은 “미국에서 매년 수백 명이 구류 중 사망합니다\n",
      "복잡한 경찰 업무에 방해됨이 없이 생체 감시를 실시하여 건강이 좋지 않은 피의자들을 조기에 선별할 수 있다면, 이들의 목숨을 구할 수 있습니다.”라고 말한다\n",
      "33 번 Topic 문장 :\n",
      "‘워싱턴 포스트’ 지의 2015년 보도에 따르면, 경찰에게 테이저로 사격을 당한 후 구속 중 사망하는 사람이 1주에 1명 꼴로 발생한다고 한다\n",
      "전도성 전기 병기인 테이저로 인한 중상자 대부분은 근육 마비에 의한 낙상으로 인해 생긴다\n",
      "현재 여러 연구자들은 테이저에 EKG(심전도) 기기를 추가하면 피의자의 심부담을 측정함으로서 피의자의 심장 위험을 막을 수 있다고 생각한다\n",
      "“테이저에 피격된 사람이 의학적으로 문제가 있음을 알게 된다면, 신속하게 응급조치를 취해 그 사람의 생명을 구할 수 있습니다.”\n",
      "1년에 테이저 때문에 죽는 사람이 정확히 몇 명인지는 확실히 발표된 바가 없지만, 보즈먼과 그의 동료들은 더욱 안전한 테이저를 만들고자 한다\n",
      "보즈먼과 동료인 제이슨 스토피라 박사는 두 기기를 결합하는 작업이 가능할 거라고 생각했다.이들은 미국 사법 연구소의 자금 지원을 받아, 테이저에 생체 감시 기능을 부여하는 데 착수했다\n",
      "보즈먼과 스토피라는 ‘과학 수사 및 법의학 저널’에 실린 자신들의 연구 결과로 인해, 기존 테이저 제작사들이 의료 기기 제작사들과 협력 관계를 체결해 이와 유사한 기기를 생산하기를 바라고 있다\n",
      "이들은 생체 감시 테이저가 피의자의 심장 정보를 자동적으로 기록하고 심부담이 높을 경우 이를 시청각 수단으로 경고해 주기를 바라고 있다\n",
      "이 때 테이저로 기록한 피의자의 심장 정보를 분석해 의료 전문가들에게 귀중한 건강 데이터로서 제공한다면, 경찰을 비난으로부터 보호할 수 있는 것이다\n",
      "34 번 전문 : \n",
      "미래창조과학부는 온실가스를 줄이기 위한 사업인 '기후산업육성모델'의 대상으로 2개 과제를 선정했다고 23일 밝혔다\n",
      "건축물의 곡면 외벽에 적용할 수 있는 고효율의 플렉서블 태양전지를 개발한다는 것이 첫 번째 과제로 꼽혔다\n",
      "이번 과제는 한국에너지기술연구원이 주도하며, 미래부는 1년에 25억 원씩 총 5년을 지원할 예정이다\n",
      "다른 과제로는 한국과학기술연구원(KIST)의 연료전지 기술개발이 꼽혔다\n",
      "KIST 연구진은 연료전지의 부피는 기존의 60% 수준으로 줄이면서도, 발전효율은 최고 수준으로 높인다는 목표를 세웠다\n",
      "미래부는 여기 1년에 22억 원씩, 4년을 투입한다\n",
      "34 번 Topic 문장 :\n",
      "미래창조과학부는 온실가스를 줄이기 위한 사업인 '기후산업육성모델'의 대상으로 2개 과제를 선정했다고 23일 밝혔다\n",
      "건축물의 곡면 외벽에 적용할 수 있는 고효율의 플렉서블 태양전지를 개발한다는 것이 첫 번째 과제로 꼽혔다\n",
      "KIST 연구진은 연료전지의 부피는 기존의 60% 수준으로 줄이면서도, 발전효율은 최고 수준으로 높인다는 목표를 세웠다\n",
      "35 번 전문 : \n",
      "AI로 한국인·중국인·일본인들의 얼굴을 분석한 결과, 각 인종별로 몇가지 패턴이 존재했다\n",
      "(맨 윗줄부터)중국인, 일본인, 한국인./미국 로체스터대 컴퓨터학과 연구팀 논문\n",
      "얼굴 생김이 비슷한 한국인과 중국인, 일본인\n",
      "인공지능(AI)이 사람보다 더 정확하게 한·중·일 3국 인종을 구분한다는 연구 결과가 나왔다\n",
      "미국 워싱턴포스트는 “미국 로체스터대 컴퓨터학과 연구팀이 한국인과 중국인, 일본인의 얼굴 자료 4만여 건을 AI를 통해 구분한 결과 약 75％의 정확도로 국적을 구분했다”고 21일(현지시각) 보도했다\n",
      "75%의 정확도는 사람이 사진을 보고 한·중·일 국적을 구분해내는 확률(약 39％)의 두 배 수준이다\n",
      "연구팀은 리카이푸(李開復) 전 구글 차이나 사장의 트위터를 팔로우하는 중국인 가운데 1만3429명, 아베 신조(安倍晋三) 일본 총리 트위터를 팔로우하는 일본인 1만2914명, 박근혜 대통령 트위터를 팔로우하는 한국인 1만3540명 등 4만여명의 프로필 사진을 활용했다\n",
      "연구팀은 이들의 얼굴을 눈썹, 광대뼈, 머리카락색, 안경, 미소 등 40개 요소로 분류해 차이를 분석했다\n",
      "연구팀은 “얼굴에서는 헤어스타일이나 안경, 표정 등에서 차이가 뚜렷했고, 특히 한·중·일 3국은 패션감각에서 확연하게 다르다”고 밝혔다\n",
      "일본인은 눈 밑에 늘어진 지방층을 가진 경우가 가장 많았다\n",
      "중국인은 숱이 많은 눈썹을 가진 경우가 많았다\n",
      "웃는 얼굴은 남녀불문 일본인이 가장 많았고 중국인이 가장 적었다\n",
      "앞머리는 일본인 얼굴에서 가장 자주 보이고 중국인들 사이에서는 드물었다\n",
      "한국인은 검은 머리카락색이 많고, 일본에서는 상대적으로 검은 머리카락색이 적었다\n",
      "연구진은 “앞으로 이 기술을 활용하면 광고나 소셜미디어 마케팅에서 맞춤형 광고를 할 수 있다”면서 “테러리즘 예방에도 사용할 수 있다”고 했다\n",
      "35 번 Topic 문장 :\n",
      "AI로 한국인·중국인·일본인들의 얼굴을 분석한 결과, 각 인종별로 몇가지 패턴이 존재했다\n",
      "인공지능(AI)이 사람보다 더 정확하게 한·중·일 3국 인종을 구분한다는 연구 결과가 나왔다\n",
      "미국 워싱턴포스트는 “미국 로체스터대 컴퓨터학과 연구팀이 한국인과 중국인, 일본인의 얼굴 자료 4만여 건을 AI를 통해 구분한 결과 약 75％의 정확도로 국적을 구분했다”고 21일(현지시각) 보도했다\n",
      "36 번 전문 : \n",
      "소리를 통과시키는 음향 투명망토가 개발됐다\n",
      "콘서트 홀 중간 중간에 위치한 기둥에 음향 투명망토를 코팅해 놓으면 마치 기둥이 없는 것처럼 소리가 퍼져 나간다\n",
      "멀리서도 더 웅장한 소리를 들을 수 있게 된다\n",
      "기존에는 기둥에 소리가 부딪쳐 막혔다\n",
      "바다 아래 잠수함은 음파를 이용해 탐지한다\n",
      "잠수함에 이 투명망토를 코팅하면 음파를 그대로 통과시켜 잠수함을 찾을 수 없게 된다\n",
      "방과 방 사이 벽에 구멍을 하나 뚫고 음향 투명망토를 코팅하면 그간 막혀서 안 들렸던 소리가 벽이 없는 것처럼 들린다\n",
      "마찬가지로 소리를 막는 것도 가능하다\n",
      "이 모든 것은 메타물질로 가능하다\n",
      "메타물질은 빛의 파장보다 매우 작은 인공 구조체를 `원자`로 해 집합체를 만들었을 때 집합체가 새로운 균일 물질로 새로운 물성을 보이는 것이다\n",
      "자연의 원자를 본뜬 인공구조물(메타원자)을 배열해서 만든 물질이다\n",
      "메타는 사이에, 뒤에, 넘어서와 같은 뜻을 가진 말이다\n",
      "메타물질은 기존 자연계에 존재하는 물질에는 없는 특별한 성질을 갖는 물질을 총칭한다\n",
      "자연물질이 제공하지 못하는 특이한 물리적 성질을 띠기 때문에 다양한 파동 영역에서 에너지의 집속, 고해상도 이미징, 클로킹, 스텔스 등 다양한 응용 연구가 진행되고 있다\n",
      "메타물질 특성을 조작하면 빛이나 전자기파가 반사되지 않고 투과되게 만들 수 있기 때문이다\n",
      "그러면 위의 예처럼 잠수함 등을 `은폐`할 수 있게 돼 전쟁 시 판도가 달라질 수 있다\n",
      "메타물질은 전자기파(광학), 음파, 지진파 메타물질로 구분할 수 있다\n",
      "전자기파 메타물질은 전기적, 자기적 성질을 원하는 대로 가질 수 있다\n",
      "미세 구조체를 만든 메타물질이다\n",
      "음파, 진동, 지진파 메타물질은 음파 등에 대해 원하는 특성을 가지도록 미세 구조체를 만든 메타물질이다\n",
      "메타물질 개념도\n",
      "메타 물질은 1967년 러시아 물리학자 빅토르 베스라고가 제시한 이론이다\n",
      "그는 `빛을 반사시키지 않고 돌아가게 만드는 물질이 존재한다`는 이론을 발표했다\n",
      "2005년 미국 듀크 대학의 데이비드 스미스 교수와 영국의 펜드리 교수는 구리로 만든 작은 원통을 메타물질로 덮고 실험 레이더로 찾아봤다\n",
      "하지만 레이더는 이를 전혀 감지하지 못했다\n",
      "이로써 SF영화에나 나올법한 이론이 현실성을 갖게 됐다\n",
      "그러나 기존 메타물질은 숨기려는 물체를 접히거나 물체에 변형을 일어나면 투명망토 기능을 잃어버렸다\n",
      "그래서 메타물질의 여러 가지 물리적 성질을 원하는 값으로 독립적이고 자유자재로 제어할 수 있는 기술은 지난 수십 년간 계속해서 숙제로 남아있었다\n",
      "2013년에는 김경식 연세대 교수 연구진이 스마트 메타물질을 자체 제작해 신축성 있는 투명망토를 실험적으로 구현하는 데 성공해 현실화 길을 열었다\n",
      "최근에는 박남규 서울대 공대 교수 연구팀은 메타원자를 이용해 음(-)굴절, 영(0)굴절, 고(高)굴절, 은폐(cloaking) 등 특이한 파동전파를 전 영역에서 자유자재로 가능하게 하는 기술을 세계 최초로 개발했다\n",
      "연구팀은 파동 특성 간 상호 작용을 제어할 수 있는 원리를 찾고, 이를 조절해 탄성값과 밀도, 그리고 쌍이방 특성을 완전히 분리해 자유롭게 제어할 수 있는 메타원자를 제작했다\n",
      "개발된 하향설계식 메타원자는 메타물질 응용에 필요한 광범위한 범위의 물질특성 값을 목표에 맞춰 설계하는 데 이용할 수 있다\n",
      "예를 들어 이 메타원자로 구성된 메타물질을 음향실의 기둥이나 벽에 붙이면 소리가 기둥이나 벽을 투과하는 것처럼 전달되도록 하는 음향 투명망토를 만들 수 있다\n",
      "(왼쪽) 제작된 만능형 음향 메타원자 (가운데) 메타원자 내의 압력장 분포와 질량밀도, 압축률 변화 (오른쪽) 쌍이방성과 영(0)굴절률을 적용한 메타원자를 이용하여 넓게 퍼져 진행하는 파동을 회절한계보다 작은 도파로에 손실 없이 강하게 집속시켜 전달하는 것이 가능하다\n",
      "박남규 교수는 “메타 물질의 굴절 값을 자유자재로 변동시키는 게 힘들었다”면서 “메타물질의 물리적 특성 분리제어와 하향식 메타원자 설계가 특성 값 전 영역에 걸쳐서 구현 가능함을 증명했다”고 말했다\n",
      "소리의 진행방향과 초점을 조절하는 음향 박막렌즈, 약한 파도를 좁은 공간에 모아 증폭시켜 터빈을 돌리는 조력발전, 약한 전자파와 태양에너지 집속 등 다양한 분야에 응용 가능할 것으로 보인다\n",
      "메타물질은 외국에서도 지속적으로 투자하는 분야다\n",
      "미국 MURI는 수십여 대학과 정부 연구소가 참여하고 있는, 선정 경쟁이 매우 강한 국가 프로그램이다\n",
      "MURI는 사회과학 분야까지 지원하는 총 21개 지원 분야(2012년 기준) 중 네 개 분야가 메타물질 관련 주제였다\n",
      "미국 메타물질 연구소는 국립과학재단(NSF) 산학 협동연구소 사업의 일환으로 설립됐다\n",
      "메타물질의 △디자인, 시뮬레이션 △고굴절률, 영굴절률, 음굴절률 등 △제작 공정 관련 △차세대 메타물질 탐색 등 메타물질과 관련된 여러 주제를 복합적으로 연구 중이다\n",
      "영국도 메타물질과 플라즈모닉 전문 연구소를 설립했다\n",
      "36 번 Topic 문장 :\n",
      "메타물질은 빛의 파장보다 매우 작은 인공 구조체를 `원자`로 해 집합체를 만들었을 때 집합체가 새로운 균일 물질로 새로운 물성을 보이는 것이다\n",
      "메타물질은 기존 자연계에 존재하는 물질에는 없는 특별한 성질을 갖는 물질을 총칭한다\n",
      "자연물질이 제공하지 못하는 특이한 물리적 성질을 띠기 때문에 다양한 파동 영역에서 에너지의 집속, 고해상도 이미징, 클로킹, 스텔스 등 다양한 응용 연구가 진행되고 있다\n",
      "메타물질 특성을 조작하면 빛이나 전자기파가 반사되지 않고 투과되게 만들 수 있기 때문이다\n",
      "음파, 진동, 지진파 메타물질은 음파 등에 대해 원하는 특성을 가지도록 미세 구조체를 만든 메타물질이다\n",
      "연구팀은 파동 특성 간 상호 작용을 제어할 수 있는 원리를 찾고, 이를 조절해 탄성값과 밀도, 그리고 쌍이방 특성을 완전히 분리해 자유롭게 제어할 수 있는 메타원자를 제작했다\n",
      "(왼쪽) 제작된 만능형 음향 메타원자 (가운데) 메타원자 내의 압력장 분포와 질량밀도, 압축률 변화 (오른쪽) 쌍이방성과 영(0)굴절률을 적용한 메타원자를 이용하여 넓게 퍼져 진행하는 파동을 회절한계보다 작은 도파로에 손실 없이 강하게 집속시켜 전달하는 것이 가능하다\n",
      "박남규 교수는 “메타 물질의 굴절 값을 자유자재로 변동시키는 게 힘들었다”면서 “메타물질의 물리적 특성 분리제어와 하향식 메타원자 설계가 특성 값 전 영역에 걸쳐서 구현 가능함을 증명했다”고 말했다\n",
      "37 번 전문 : \n",
      "- 움직임 재현과 함께 공간의 차이 인지\n",
      "환경에 적응\n",
      "- 증강현실 아바타, 다양한 역할 수행할 것으로 예측\n",
      "국내 연구진에 의해 증강현실 아바타의 발판이 될 신기술이 개발됐다\n",
      "KAIST는 문화기술대학원 이성희 교수 연구팀이 사용자의 움직임을 재현하면서도 원격 공간의 차이를 인지해 바뀐 환경에 적응할 수 있는 증강현실 아바타 기술을 개발했다고 20일 밝혔다\n",
      "이성희 교수 연구팀은 사용자의 공간에는 식탁용 의자, 원격 공간에는 일인용 소파를 놓은 뒤 사용자가 식탁용 의자에 앉으면 아바타는 소파에 적합한 동작과 자세로 변형해 자리에 앉는 실험에 성공했다\n",
      "증강현실 아바타는 사용자를 대신해 가상공간 혹은 원격공간에 존재하며, 사용자의 움직임을 그대로 따라 하고 반영한다\n",
      "그러나 사용자의 공간과 아바타가 존재하는 공간에 차이가 있기 때문에 사용자의 동작을 아바타에 그대로 적용하면 아바타는 가상, 원격 공간의 물체를 그냥 통과해버리는 등 사실성이 떨어지게 된다\n",
      "연구팀은 이런 문제를 해결하기 위해 사용자의 공간에는 식탁용 의자, 아바타의 공간에는 일인용 소파를 설치하고, 깊이 기반 카메라를 이용해 환경 정보를 분석했다\n",
      "또한 각 의자 간 대응점과 공간상 사용자의 움직임 간 대응점을 찾아 이쪽 공간에서의 어느 한 점이 저쪽에서는 어디에 위치한 것인지 확인했다\n",
      "이후 사용자의 식탁용 의자에 앉는 동작을 분석 결과에 비춰 소파에 앉는 동작으로 변형시켜 아바타의 형상을 생성했다\n",
      "연구팀은 이 과정에서 자세(pose)가 아닌 동작(motion)의 대응점을 찾는데 주력했다\n",
      "공간 대응관계를 이용한 증강현실 아바타의 동작 생성 기술은 주어진 공간 안에서 사용자의 움직임이 갖는 의미와 의도를 왜곡시키지 않고, 다른 공간에 있는 증강현실 아바타의 동작으로 재생성할 수 있다\n",
      "이는 사용자가 증강현실 아바타의 공간 환경을 고려하지 않고, 동작을 해도 자연스러운 아바타의 동작이 가능해짐을 의미한다\n",
      "연구팀은 증강현실 아바타가 멀지 않은 미래에 우리 일상 공간을 함께 공유하며, 다양한 역할을 수행할 것이라고 예상했다\n",
      "이 교수는 “이번 연구는 원격지 인간의 동작을 공존 공간의 가구 환경에 맞춰 증강현실 아바타에 적용하기 위한 핵심기술이 될 것”이라고 말했다\n",
      "한편 이번 연구는 지난 9월 19일부터 5일간 멕시코 메리다에서 열린 ‘국제학술대회인 증강 및 혼합현실 학회(ISMAR : International Symposium on Mixed & Augmented Reality) 2016’에서 발표됐다\n",
      "37 번 Topic 문장 :\n",
      "국내 연구진에 의해 증강현실 아바타의 발판이 될 신기술이 개발됐다\n",
      "KAIST는 문화기술대학원 이성희 교수 연구팀이 사용자의 움직임을 재현하면서도 원격 공간의 차이를 인지해 바뀐 환경에 적응할 수 있는 증강현실 아바타 기술을 개발했다고 20일 밝혔다\n",
      "이성희 교수 연구팀은 사용자의 공간에는 식탁용 의자, 원격 공간에는 일인용 소파를 놓은 뒤 사용자가 식탁용 의자에 앉으면 아바타는 소파에 적합한 동작과 자세로 변형해 자리에 앉는 실험에 성공했다\n",
      "공간 대응관계를 이용한 증강현실 아바타의 동작 생성 기술은 주어진 공간 안에서 사용자의 움직임이 갖는 의미와 의도를 왜곡시키지 않고, 다른 공간에 있는 증강현실 아바타의 동작으로 재생성할 수 있다\n",
      "38 번 전문 : \n",
      "16일 화성 궤도에 진입한 유럽우주국(ESA) 무인 화성탐사선 ‘엑소마스(EXoMars)’ 상상도\n",
      "ESA 제공\n",
      "러시아와 유럽이 공동으로 진행하는 화성 생명체 탐사 프로젝트 ‘엑소마스(EXoMars)’의 화성 탐사 착륙선 ‘스키아파렐리’(Schiaparelli)가 화성에 터치다운을 앞두고 교신이 두절됐다\n",
      "유럽우주국(ESA)은 그리니치 표준시(GMT)로 19일 오후 2시 48분께 화성에 착륙할 예정이던 화성 탐사 착륙선 ‘스키아파렐리’와 ESA 간의 교신이 끊겨 안착 여부가 불투명하다고 이날 발표했다\n",
      "ESA는 스키아파렐리가 화성 탐사선을 구성한 궤도선인 ‘가스추적궤도선’(TGO)에서 성공적으로 분리된 후 화성 착륙을 앞두고 특정 지점에서 교신이 끊겼다고 밝혔다\n",
      "TGO는 생명체가 화성에 살아있음을 보여주는 메탄가스를 탐지하는 역할을 한다\n",
      "ESA 과학자들은 “좋은 징후가 아니다”라면서도 “실패라고 판단하기엔 너무 이르다”며 신중한 태도를 보이고 있다\n",
      "화성 생명체 탐사를 위한 무인 탐사선 ‘엑소마스’(ExoMars) 프로젝트의 일환인 스키아파렐리는 올해 3월 14일 카자흐스탄 바이코누르 우주기지에서 프로톤 로켓에 실려 발사됐다\n",
      "약 7개월간 5억 km가량을 날아 화성 궤도에 들어섰다\n",
      "스키아파렐리는 화성 표면의 온도와 습도, 밀도, 전기적 성질 등의 자료와 사진 이미지를 보낼 예정이었다\n",
      "ESA는 러시아 연방우주공사(로스코스모스)와 협력, 2020년 탐사선과 탐사 로봇을 화성에 보내 생명체의 흔적을 본격적으로 탐사하는 것을 목표로 하고 있다\n",
      "한편 지금까지 화성 탐사 착륙선을 화성 표면에 착륙시킨 나라는 미국과 러시아(구소련 포함) 뿐이다\n",
      "38 번 Topic 문장 :\n",
      "러시아와 유럽이 공동으로 진행하는 화성 생명체 탐사 프로젝트 ‘엑소마스(EXoMars)’의 화성 탐사 착륙선 ‘스키아파렐리’(Schiaparelli)가 화성에 터치다운을 앞두고 교신이 두절됐다\n",
      "유럽우주국(ESA)은 그리니치 표준시(GMT)로 19일 오후 2시 48분께 화성에 착륙할 예정이던 화성 탐사 착륙선 ‘스키아파렐리’와 ESA 간의 교신이 끊겨 안착 여부가 불투명하다고 이날 발표했다\n",
      "ESA는 스키아파렐리가 화성 탐사선을 구성한 궤도선인 ‘가스추적궤도선’(TGO)에서 성공적으로 분리된 후 화성 착륙을 앞두고 특정 지점에서 교신이 끊겼다고 밝혔다\n",
      "39 번 전문 : \n",
      "7개국 60명 연구 결과 '네이처' 발표…\"암·선천성 기형 연구에 도움\"\n",
      "실험동물로 알려진 '아프리카발톱개구리(Xenopus laevis)'의 유전체를 UNIST(울산과학기술원) 교수가 포함된 국제 공동연구진이 해독했다\n",
      "UNIST 권태준 생명과학부 교수(울산=연합뉴스) UNIST는 권태준 생명과학부 교수가 제1 저자로 참여하고 미국, 일본 등 총 7개 나라 60명이 함께한 공동연구진은 아프리카발톱개구리의 4만여 개 유전자를 염색체 수준으로 규명해 '네이처(Nature)'에 발표했다고 20일 밝혔다\n",
      "2016.10.20\n",
      "[UNIST 제공=연합뉴스]\n",
      "다양한 생물이 어떻게 진화했는지 풀어낼 수 있는 열쇠를 찾은 것이어서 향후 진화 연구에 도움이 될 것으로 보인다\n",
      "권태준 생명과학부 교수가 제1 저자로 참여하고 미국, 일본 등 총 7개 나라 60명이 함께한 공동연구진은 아프리카발톱개구리의 4만여 개 유전자를 염색체 수준으로 규명해 '네이처(Nature)'에 발표했다\n",
      "유전자 발현 조절이 쉽고 체외수정으로 한 번에 수백 개의 알을 얻을 수 있는 아프리카발톱개구리는 척추동물 유전자 연구에 널리 사용됐다\n",
      "2012년 노벨생리의학상을 수상한 존 고든(Sir John Gordon)이 체세포 핵치환 실험을 통해 '어른 세포가 다시 배아가 될 수 있다'는 걸 처음 보여준 실험에도 아프리카발톱개구리가 사용됐다\n",
      "그러나 정작 이 개구리의 유전체 해독은 다른 동물보다 어려웠다\n",
      "인간이나 다른 동물은 부모로부터 하나씩의 염색체 그룹을 물려받아 2개의 염색체 그룹(2배체)을 가지지만, 이 개구리는 부모에게서 두 개씩 염색체 그룹을 받아 4개 염색체 그룹(4배체)을 가지기 때문에 분석이 복잡했다\n",
      "공동연구진은 지난 2010년 해독된 '서양발톱개구리(Xenopus tropicalis)'를 이용해 분석을 시도했다\n",
      "인간처럼 2개 염색체 그룹을 가지는 서양발톱개구리를 아프리카발톱개구리와 비교해 부모로부터 물려받는 염색체 그룹 수(배체수) 변화에 따른 차이를 분석한 것이다\n",
      "공동연구진은 이 방법을 통해 두 개구리의 조상이 약 4천800만년 전에 2배체로 된 2개의 종으로 분화됐다가 다시 1천700만년 전에 합쳐지면서 현재의 아프리카발톱개구리가 탄생했다는 사실을 밝혀냈다\n",
      "권 교수는 \"합쳐지는 과정에서 모든 유전자가 살아남을지 사라질지 선택의 기로에 놓이게 된다\"며 \"아프리카발톱개구리는 신호전달, 대사, 구조 형성에 작용하는 유전자는 앞선 두 종의 것이 모두 유지됐고, 면역체계나 DNA 손상복구에 관여하는 유전자는 한쪽만 살아남은 것으로 확인됐다\"고 말했다\n",
      "대학 측은 20일 \"진화를 통해 어떤 유전자가 선택되는지 등 기초 연구뿐만 아니라 암이나 선천성 기형처럼 배체수 변화가 흔히 나타나는 질병 연구에 도움이 될 것\"이라고 밝혔다\n",
      "39 번 Topic 문장 :\n",
      "실험동물로 알려진 '아프리카발톱개구리(Xenopus laevis)'의 유전체를 UNIST(울산과학기술원) 교수가 포함된 국제 공동연구진이 해독했다\n",
      "UNIST 권태준 생명과학부 교수(울산=연합뉴스) UNIST는 권태준 생명과학부 교수가 제1 저자로 참여하고 미국, 일본 등 총 7개 나라 60명이 함께한 공동연구진은 아프리카발톱개구리의 4만여 개 유전자를 염색체 수준으로 규명해 '네이처(Nature)'에 발표했다고 20일 밝혔다\n",
      "권태준 생명과학부 교수가 제1 저자로 참여하고 미국, 일본 등 총 7개 나라 60명이 함께한 공동연구진은 아프리카발톱개구리의 4만여 개 유전자를 염색체 수준으로 규명해 '네이처(Nature)'에 발표했다\n",
      "권 교수는 \"합쳐지는 과정에서 모든 유전자가 살아남을지 사라질지 선택의 기로에 놓이게 된다\"며 \"아프리카발톱개구리는 신호전달, 대사, 구조 형성에 작용하는 유전자는 앞선 두 종의 것이 모두 유지됐고, 면역체계나 DNA 손상복구에 관여하는 유전자는 한쪽만 살아남은 것으로 확인됐다\"고 말했다\n",
      "40 번 전문 : \n",
      "파동에너지 마음대로 제어하는 신물질 개발\n",
      "박남규 서울대 교수팀 개발…광학·반도체 등에 적용 가능\n",
      "잔잔한 물에 돌을 던지면 돌 주위로 물결이 인다\n",
      "이는 돌이 일으킨 파동에너지를 물이 전달하기 때문이다\n",
      "상대가 말한 소리를 들을 수 있는 것도 공기가 파동에너지를 전달하기 때문이다\n",
      "이렇게 에너지를 전달하는 것을 '매질'이라고 한다\n",
      "17일 박남규 서울대 전기정보공학부 교수팀에 따르면 파동에너지를 자유롭게 제어할 수 있는 새로운 형태의 매질을 세계 최초로 개발해 국제학술지 '사이언스 어드밴시스'(Science Advances) 최신호에 발표했다\n",
      "이번 연구 결과는 파동에너지를 쓰는 광학, 음향학, 양자역학, 반도체 분야 등에 널리 적용될 수 있을 것으로 기대를 모으고 있다\n",
      "매질은 이를 이루는 구성물의 배열 방식에 따라 크게 두 가지로 나뉜다\n",
      "같은 물질이 균일하게 배열된 '주기적 매질'과 서로 다른 요소가 불규칙하게 배열된 '무질서한 매질'이다\n",
      "무질서한 매질은 주기적 매질보다 만들기 쉽다는 장점이 있지만, 파동에너지를 잘 전파할 수 없어 현실적으로 전자나 광소자에 응용하기는 어려웠다\n",
      "이번 연구에서 연구진은 두 매질의 장점만 조화롭게 섞은 새로운 매질을 만들었다\n",
      "서로 다른 요소를 썼다는 점은 무질서한 매질과 같지만, 배열 방식에 숨은 질서가 있어 파동이 매우 잘 전파된다는 점에서 주기적 매질과 같다\n",
      "이는 바닥에 서로 다른 모양의 타일을 깔 때를 생각하면 된다\n",
      "타일의 모양은 다르지만, 특정한 배열을 통해 틈 없이 바닥을 채우는 방식과 같은 것이다\n",
      "연구진이 새로 개발한 매질은 파동에너지의 특성이 자유롭게 제어돼 원하는 형태의 파동을 전달하는 게 가능한 것으로 확인됐다\n",
      "이번 논문의 제1 저자인 유선규 서울대 박사는 \"질서와 무질서 네트워크의 중간 영역에 존재하는 새로운 매질을 개발했다\"며 \"만들기 쉽다는 무질서 매질의 장점과 효율이 높은 주기적 매질의 장점을 동시에 만족한다\"고 설명했다\n",
      "박남규 교수는 \"앞으로 광학, 반도체 분야에 적용할 수 있고, '투명망토' 같은 메타물질(자연계에 없는 성질을 가진 인공물질)의 개발에도 큰 도움을 줄 것\"이라고 전했다\n",
      "이번 연구는 미래부 글로벌 프론티어 사업(파동에너지 극한제어 연구단), 글로벌 연구실 사업과 교육부 대통령 포스닥 펠로우십 과제의 지원으로 수행했다\n",
      "40 번 Topic 문장 :\n",
      "17일 박남규 서울대 전기정보공학부 교수팀에 따르면 파동에너지를 자유롭게 제어할 수 있는 새로운 형태의 매질을 세계 최초로 개발해 국제학술지 '사이언스 어드밴시스'(Science Advances) 최신호에 발표했다\n",
      "연구진이 새로 개발한 매질은 파동에너지의 특성이 자유롭게 제어돼 원하는 형태의 파동을 전달하는 게 가능한 것으로 확인됐다\n",
      "이번 논문의 제1 저자인 유선규 서울대 박사는 \"질서와 무질서 네트워크의 중간 영역에 존재하는 새로운 매질을 개발했다\"며 \"만들기 쉽다는 무질서 매질의 장점과 효율이 높은 주기적 매질의 장점을 동시에 만족한다\"고 설명했다\n",
      "박남규 교수는 \"앞으로 광학, 반도체 분야에 적용할 수 있고, '투명망토' 같은 메타물질(자연계에 없는 성질을 가진 인공물질)의 개발에도 큰 도움을 줄 것\"이라고 전했다\n",
      "41 번 전문 : \n",
      "KIST 김영수 박사 유전자 변이로 모습을 바꾼 암세포도 감쪽같이 타격하는 표적항암제를 만들 수 있는 기초 연구 성과를 내놓은 KIST 치매DTC융합연구단 김영수 박사\n",
      "KIST 연구진, 유전자 변이 영향없는 새 표적 단백질 발견\n",
      "유전자 변이로 모습을 바꾼 암세포도 감쪽같이 타격하는 표적항암제를 만들 수 있는 기초 연구 성과가 국내에서 나왔다\n",
      "암 치료에서 '마법의 탄환'으로 꼽히지만, 유전자 변이 현상 앞에서는 '오발탄'이 되던 종전 표적항암제의 한계를 극복할 수 있는 성과라 주목된다\n",
      "한국과학기술연구원(KIST)은 치매DTC융합연구단 김영수 박사팀이 뇌종양 세포의 표면에서 과발현하는 단백질인 'GRP78'이 암의 전이를 조절하는 기능이 있다는 사실을 규명했다고 13일 밝혔다\n",
      "이 GRP78은 세포막에 발현되는 단백질이라 유전자 변이의 영향을 받지 않는다\n",
      "이 때문에 이 GRP78을 '표적'으로 삼는 치료제를 만들면 유전자 변이로 암세포가 돌변해도 목표를 놓치지 않고 정밀 타격을 할 수 있다고 김 박사팀은 전했다\n",
      "연구진은 \"GRP78을 표적항암제로 억제하면 뇌종양 전이를 막고 암 치료도 되는 두 가지 효과가 나타나는 것으로 밝혀졌다\"며 \"향후 추가 연구를 통해 뇌종양 외에 다른 암에도 이번 성과를 적용할 수 있을 것으로 기대된다\"고 설명했다\n",
      "표적항암제는 특정 암세포만 골라 공격하는 약으로, 인체의 다른 정상 세포를 해치지 않아 탈모·구토 등의 부작용이 없다는 장점 덕분에 국내외 의약계에서 각광을 받고 있다\n",
      "만성골수성백혈병 치료제인 '글리백'이 대표적 예다\n",
      "이번 연구 성과는 온라인 학술지인 '사이언티픽 리포츠' 7일 자에 게재됐다\n",
      "연구는 'KIST 영 팰로우십' 프로그램의 지원 아래 이뤄졌다\n",
      "41 번 Topic 문장 :\n",
      "유전자 변이로 모습을 바꾼 암세포도 감쪽같이 타격하는 표적항암제를 만들 수 있는 기초 연구 성과가 국내에서 나왔다\n",
      "한국과학기술연구원(KIST)은 치매DTC융합연구단 김영수 박사팀이 뇌종양 세포의 표면에서 과발현하는 단백질인 'GRP78'이 암의 전이를 조절하는 기능이 있다는 사실을 규명했다고 13일 밝혔다\n",
      "이 때문에 이 GRP78을 '표적'으로 삼는 치료제를 만들면 유전자 변이로 암세포가 돌변해도 목표를 놓치지 않고 정밀 타격을 할 수 있다고 김 박사팀은 전했다\n",
      "연구진은 \"GRP78을 표적항암제로 억제하면 뇌종양 전이를 막고 암 치료도 되는 두 가지 효과가 나타나는 것으로 밝혀졌다\"며 \"향후 추가 연구를 통해 뇌종양 외에 다른 암에도 이번 성과를 적용할 수 있을 것으로 기대된다\"고 설명했다\n",
      "42 번 전문 : \n",
      "인공지능(AI) 알파고 개발자 데미스 하사비스 구글 딥마인드 최고경영자(CEO)가 이끄는 연구진이 신경망 컴퓨터와 외장 메모리만을 이용해 복잡한 지하철 노선에서 최단거리 찾기 같은 뇌의 추론 기능을 모방한 AI 기술을 개발했다\n",
      "구글 딥마인드는 신경망과 기존 컴퓨터의 장점을 결합해 아직은 초보적인 수준이지만 정확도가 높은 고차원적 추론이 가능한 하이브리드 기계학습 기술을 개발했다고 국제학술지 네이처 12일자에 발표했다\n",
      "컴퓨터 중앙처리장치(CPU)와 메모리로 이뤄진 일반 컴퓨터는 복잡한 대규모 자료를 처리하는데 유리하다\n",
      "최근 AI에서 주목받는 뇌 신경을 모방한 신경망 역시 기계학습을 통해 대규모 자료를 학습하고 이를 통해 특정한 패턴을 알아내는데 활용된다\n",
      "하지만 전문가들은 이 정도 기술은 뇌 일부 기능에 국한된다고 설명한다\n",
      "즉 뇌는 한 두 개 의자만 보고도 전혀 다른 형태의 의자를 의자로 인식하고 처음 본 노선도를 보고도 빠르게 최단거리를 찾아내는 반면 신경망은 그렇지 못하다는 것이다\n",
      "뇌 연구자들은 뇌가 어떻게 이런 추론 능력을 갖게 됐고 어떻게 작동하는지 알아내지 못하고 있다\n",
      "딥마인드 연구진은 학습이 가능한 신경망과 컴퓨터에 들어가는 외장 메모리를 이용해 이런 능력을 가진 ‘미분가능 신경컴퓨터(DNC)’라는 독특한 컴퓨터를 개발했다\n",
      "이 컴퓨터는 신경망처럼 학습할뿐 아니라 일반 컴퓨터처럼 대규모 복잡한 자료도 처리할 수 있다\n",
      "연구진은 먼저 노선은 11개, 역 숫자만 270개인 런던 지하철 노선표를 학습하게 하고 스스로 최단 거리를 찾게 했다\n",
      "또 한 집 안의 가계도를 학습하게 한 뒤 누가 누구의 사촌인지를 맞추게 했다\n",
      "이밖에 서로 관련성이 있는 20개 질문과 응답을 만들어 학습도 시켰다\n",
      "그리고 질문과 응답에는 나오지 않았지만 그 내용을 통해 답을 유추할 수 있는 문제를 이 신경컴퓨터에 내서 풀게 했다\n",
      "각각 실험에서 이 신경컴퓨터는 99.8% 정확도를 보인 것으로 나타났다\n",
      "이는 다른 신경컴퓨터 연구에서 나타난 37% 정확도보다 약 3배 가까이 높은 수치다\n",
      "조성배 연세대 컴퓨터과학과 교수는 “일반 컴퓨터는 지하철 노선표를 보고 손쉽게 가장 빠른 경로를 찾아내지만 사람의 뇌를 모방한 신경망은 아직까지 스스로 이런 복잡한 문제를 풀지 못한다”며 “일반 연구자보다 훨씬 높은 정확도가 나온 건 구글의 막강한 컴퓨팅 능력이 뒷받침이 된 것 같다”고 말했다\n",
      "42 번 Topic 문장 :\n",
      "인공지능(AI) 알파고 개발자 데미스 하사비스 구글 딥마인드 최고경영자(CEO)가 이끄는 연구진이 신경망 컴퓨터와 외장 메모리만을 이용해 복잡한 지하철 노선에서 최단거리 찾기 같은 뇌의 추론 기능을 모방한 AI 기술을 개발했다\n",
      "구글 딥마인드는 신경망과 기존 컴퓨터의 장점을 결합해 아직은 초보적인 수준이지만 정확도가 높은 고차원적 추론이 가능한 하이브리드 기계학습 기술을 개발했다고 국제학술지 네이처 12일자에 발표했다\n",
      "최근 AI에서 주목받는 뇌 신경을 모방한 신경망 역시 기계학습을 통해 대규모 자료를 학습하고 이를 통해 특정한 패턴을 알아내는데 활용된다\n",
      "딥마인드 연구진은 학습이 가능한 신경망과 컴퓨터에 들어가는 외장 메모리를 이용해 이런 능력을 가진 ‘미분가능 신경컴퓨터(DNC)’라는 독특한 컴퓨터를 개발했다\n",
      "조성배 연세대 컴퓨터과학과 교수는 “일반 컴퓨터는 지하철 노선표를 보고 손쉽게 가장 빠른 경로를 찾아내지만 사람의 뇌를 모방한 신경망은 아직까지 스스로 이런 복잡한 문제를 풀지 못한다”며 “일반 연구자보다 훨씬 높은 정확도가 나온 건 구글의 막강한 컴퓨팅 능력이 뒷받침이 된 것 같다”고 말했다\n",
      "43 번 전문 : \n",
      "KAIST 강정구 교수팀 특급 논문 게재…\"전기차 등에 핵심 기술 전망\"\n",
      "IT(정보기술) 기기와 전기차에 널리 쓰이는 리튬이온 배터리보다 최대 100배 더 빠르게 충전할 수 있는 차세대 전지 기술을 국내 연구진이 개발했다\n",
      "미래창조과학부는 한국과학기술원(KAIST) 신소재공학과 강정구 교수팀이 이런 '하이브리드' 에너지 저장장치 기술을 개발해 해당 성과를 유명 학술지인 '어드밴스드 에너지 매터리얼스' 최근호의 VIP(특급) 논문으로 발표했다고 10일 밝혔다\n",
      "리튬이온 배터리는 전기를 많이 저장할 수 있어 스마트폰·노트북·전기차 등에 많이 쓰이지만, 전기 출력이 200W/㎏으로 작아 충전이 오래 걸리는 것이 단점이다\n",
      "이에 대한 대안으로 출력이 20KW/㎏급으로 훨씬 큰 '슈퍼커패시터' 전지가 연구됐지만, 이 배터리는 에너지 저장밀도가 낮아 리튬이온보다 충전 용량이 적다는 한계가 있었다\n",
      "이 때문에 강 교수팀은 '다공성 나노튜브'라는 소재를 토대로 리튬이온과 슈퍼커패시터의 기술을 섞은 하이브리드(혼혈) 형태의 새 전지를 개발했다\n",
      "이 전지는 에너지 저장밀도는 리튬이온 배터리의 1.5배이면서도 출력은 슈퍼커패시터를 웃도는 23KW/㎏에 달해, 리튬이온 방식보다 100배가량 빠르게 충전을 할 수 있다고 연구진은 설명했다\n",
      "연구진은 \"안정적인 에너지 저장밀도를 구현하면서도 급속충전을 할 수 있어 미래형 전기차와 모바일 기기의 핵심 기술이 될 것으로 기대된다\"고 평했다\n",
      "이 연구는 미래부의 글로벌프런티어사업의 지원을 받았다\n",
      "43 번 Topic 문장 :\n",
      "IT(정보기술) 기기와 전기차에 널리 쓰이는 리튬이온 배터리보다 최대 100배 더 빠르게 충전할 수 있는 차세대 전지 기술을 국내 연구진이 개발했다\n",
      "미래창조과학부는 한국과학기술원(KAIST) 신소재공학과 강정구 교수팀이 이런 '하이브리드' 에너지 저장장치 기술을 개발해 해당 성과를 유명 학술지인 '어드밴스드 에너지 매터리얼스' 최근호의 VIP(특급) 논문으로 발표했다고 10일 밝혔다\n",
      "이 전지는 에너지 저장밀도는 리튬이온 배터리의 1.5배이면서도 출력은 슈퍼커패시터를 웃도는 23KW/㎏에 달해, 리튬이온 방식보다 100배가량 빠르게 충전을 할 수 있다고 연구진은 설명했다\n",
      "44 번 전문 : \n",
      "국내 연구팀, DNA 분석 통해 '황금씨족'으로 확인돼\n",
      "▲'몽골여왕'의 말안장과 황금반지\n",
      "칭기즈 칸 가계 계보의 비밀이 풀렸습니다\n",
      "국내 연구팀이 고인골에 대해 분석한 결과 칭기즈칸 부계 기원과 800년 동안 비밀에 싸여 있던 '몽골 여왕'의 비밀이 풀리는 단서를 제시했습니다\n",
      "몽골여왕은 칭기즈 칸 가계의 일원이라는 사실이 밝혀졌습니다\n",
      "2004년 몽골제국 칭기즈칸 가계로 추정되는 5체의 고인골이 세계 최초로 발굴됩니다\n",
      "발굴 이후 부장품의 종류와 양, 질로 보아 황족 여성인 것으로 추정되는 한 체의 고인골이었습니다\n",
      "발굴에 참여했던 몽골 학자들은 이 한 체이 고인골을 '몽골 여왕'으로 불렀습니다\n",
      "국내 연구팀은 몽골 동부의 타반 톨고이(Tavan Tolgoi) 지역에서 발굴된 5체의 고인골의 고고인류학적 ·미토콘드리아 DNA 분석 등을 통해 몽골시대(12~13세기) 황족 일원일 가능성을 처음으로 제시했습니다\n",
      "고인골이 발견된 타반 톨고이 지역은 몽골의 수도 울란바토르에서 650㎞ 떨어진 몽골 동부에 위치합니다\n",
      "이 곳에서 총 7체가 발굴됐습니다\n",
      "이 가운데 무덤양식과 내부구조, 부장품의 양과 질 등으로 판단했을 때 5체(남성 3체, 여성 2체)는 몽골 황족일 가능성이 제시됐습니다\n",
      "발굴된 고인골은 두개골, 치아, 대퇴골, 골반골 등 체질인류학적 분석 결과 성별이 뚜렷했고 사망 연령은 4체는 20대, 1체는 40~50대로 추정됐습니다\n",
      "신장은 남성은 168.9㎝에 78.1㎏, 여성은 165.6㎝에 68.1㎏ 정도였습니다\n",
      "여성의 경우 평균 신장보다 약 10㎝ 이상 큰 것으로 나타났습니다\n",
      "방사성탄소연대 측정법을 통한 절대연대 분석 결과 5체의 고인골은 칭기즈칸 생존 전후의 칭기즈칸 가계(일명 황금씨족)의 일원일 가능성이 높은 것을 확인됐습니다\n",
      "미토콘드리아 DNA 분석 결과 남성 3체와 여성 1체는 모두 동일한 하플로타입을 갖고 있었습니다\n",
      "극동아시아 집단에서 주로 관찰되는 D4 하플로그룹에 속했습니다\n",
      "남은 여성 1체는 이들 4체와 상이한 하플로타입을 갖고 있었으며 동북아에 널리 퍼져있는 CZ 하플로그룹에 속하는 것으로 밝혀졌습니다\n",
      "'하플로타입'이란 동일 염색체상 복수좌위에서의 대립형질의 조합을 의미합니다\n",
      "예를 들어 세포 내에 한 쌍씩 존재하는 상염색체들과 달리 하나의 염색체만 존재하는 Y 및 미토콘드리아 염색체 상에 존재하는 SNP 또는 STR과 같은 염기서열 변이의 조합을 의미합니다\n",
      "하플로그룹은 유전적 거리가 가까운 하플로타입들의 조합으로 구성됩니다\n",
      "CZ 하플로그룹은 미토콘드리아 DNA 분석결과에 따른 모계 기원의 유형들을 말합니다\n",
      "이 결과를 통해 4체는 극동아시아에 기원을 둔 동일한 모계 조상을 갖고 있고 1체는 모계가 다르다는 것을 나타낸다고 연구팀은 설명했습니다\n",
      "특히 3체의 남성 고인골의 Y-SNP(Y 염색체 상의 단일 핵산염기 다형현상) 분석 결과 놀랍게도 모두 영국 등 유럽에서 가장 높은 빈도로 분포하는 R1b-M343 유형을 가지고 있는 것으로 밝혀졌습니다\n",
      "이 가운데 남성 2체의 Y-STR(Y 염색체에서 관찰되는 짧은 반복수 변이에 대한 프로파일) 조합 분석결과 이들은 동일한 Y-STR 프로파일을 나타내는 것으로 나타났습니다\n",
      "이 결과는 타반 톨고이 남성 고인골들은 모두 동일한 부계 기원임은 물론 한 아버지의 자손일 가능성이 높다는 것을 알려주고 있습니다\n",
      "3체의 남성 고인골에서 영국 등 유럽에서 가장 높은 빈도로 분포하는 R1b-M343 유형을 가지고 있다는 것은 칭기즈 칸의 가계를 역사적으로 거꾸로 거슬러 올라가면 유럽인의 피가 섞여 있다는 것을 의미합니다\n",
      "상염색체 STR(성염색체인 X, Y 염색체를 제외한 나머지 1번부터 22번까지의 총 44개 염색체에 대한 STR), 가족관계 분석 프로그램 분석 결과 D4 미토콘드리아 하플로그룹을 갖고 있는 고인골은 모두 형제 ·자매간이거나 모자관계인 한 가족의 일원으로 확인됐습니다\n",
      "CZ 하플로그룹에 속하는 고인골은 황금씨족으로 추정은 되는데 D4 고인골들과 생물학적으로는 연관이 없는 것으로 밝혀졌습니다\n",
      "D4 황금씨족 고인골과 가장 유사한 현대인은 일본, 중국, 몽골인입니다\n",
      "연구결과를 토대로 연구팀은 황금씨족과 동일한 R1b Y 하플로그룹을 가지고 있는 현대인은 러시아 칼미크인, 중국 회족, 우주베크인, 타지크인들인 것으로 밝혔습니다\n",
      "타반 톨고이 남성 고인골의 부계기원은 몽골을 포함한 동북아시아(C3c-M48 등의 몽골로이드)가 아니라 서유라시아 유형(R1b-M343의 코카서스 기원)일 새로운 가능성을 제시했습니다\n",
      "또 이들의 부계 자손들은 과거 칭기즈 칸의 아들과 손자들이 지배했던 황금군단, 차가타이 칸국, 원나라의 영토였던 현재의 러시아, 중앙아시아, 중국 등에 분포돼 있다는 사실을 나타낸다고 연구팀은 설명했습니다\n",
      "이번 연구는 이광호 중앙대 교수 연구팀이 수행했습니다\n",
      "연구결과는 국제 학술지 플로스원(Plos ONE) 9월14일자(논문명 : Molecular Genealogy of a Mongol Queen’s Family and Her Possible Kinship with Genghis Khan)에 실렸습니다\n",
      "이광호 교수는 \"이번 연구 성과는 칭기즈 칸 가계에 대한 세계 최초의 분자고고학적 연구결과로 칭기즈 칸 계보의 새로운 패러다임을 제시했다\"며 \"고인골의 계보학적, 역사학적, 고고학적 연구 등에 중요한 미토콘드리아, Y와 염색체 DNA 분석 정보 등을 새롭게 제공함으로서 학술적 의미가 크다\"고 말했습니다\n",
      "44 번 Topic 문장 :\n",
      "국내 연구팀이 고인골에 대해 분석한 결과 칭기즈칸 부계 기원과 800년 동안 비밀에 싸여 있던 '몽골 여왕'의 비밀이 풀리는 단서를 제시했습니다\n",
      "몽골여왕은 칭기즈 칸 가계의 일원이라는 사실이 밝혀졌습니다\n",
      "국내 연구팀은 몽골 동부의 타반 톨고이(Tavan Tolgoi) 지역에서 발굴된 5체의 고인골의 고고인류학적 ·미토콘드리아 DNA 분석 등을 통해 몽골시대(12~13세기) 황족 일원일 가능성을 처음으로 제시했습니다\n",
      "방사성탄소연대 측정법을 통한 절대연대 분석 결과 5체의 고인골은 칭기즈칸 생존 전후의 칭기즈칸 가계(일명 황금씨족)의 일원일 가능성이 높은 것을 확인됐습니다\n",
      "3체의 남성 고인골에서 영국 등 유럽에서 가장 높은 빈도로 분포하는 R1b-M343 유형을 가지고 있다는 것은 칭기즈 칸의 가계를 역사적으로 거꾸로 거슬러 올라가면 유럽인의 피가 섞여 있다는 것을 의미합니다\n",
      "연구결과를 토대로 연구팀은 황금씨족과 동일한 R1b Y 하플로그룹을 가지고 있는 현대인은 러시아 칼미크인, 중국 회족, 우주베크인, 타지크인들인 것으로 밝혔습니다\n",
      "또 이들의 부계 자손들은 과거 칭기즈 칸의 아들과 손자들이 지배했던 황금군단, 차가타이 칸국, 원나라의 영토였던 현재의 러시아, 중앙아시아, 중국 등에 분포돼 있다는 사실을 나타낸다고 연구팀은 설명했습니다\n",
      "이광호 교수는 \"이번 연구 성과는 칭기즈 칸 가계에 대한 세계 최초의 분자고고학적 연구결과로 칭기즈 칸 계보의 새로운 패러다임을 제시했다\"며 \"고인골의 계보학적, 역사학적, 고고학적 연구 등에 중요한 미토콘드리아, Y와 염색체 DNA 분석 정보 등을 새롭게 제공함으로서 학술적 의미가 크다\"고 말했습니다\n",
      "45 번 전문 : \n",
      "피어티칭·무감독시험 골자…\"자기 길 가는 '이탈자' 육성이 목표\"\n",
      "매년 노벨상 발표 시즌이 되면 옆 나라 일본과 달리 과학 분야 노벨상을 내지 못하는 한국의 과학 현실을 비판하는 목소리가 터져 나온다\n",
      "국내 연구제도 등과 함께 단골로 지적되는 것이 교육 문제다\n",
      "초등학교, 중학교, 고등학교에 이르기까지 '정답'만을 찾아 문제를 푸는 방식에 익숙해진 학생에게 새로운 분야를 개척할 창의성이 나오기 힘들다는 지적이다\n",
      "서울대 자연과학대학은 학생들이 정형화된 문제 풀이 방식에서 벗어나 창의적인 생각을 할 수 있도록 수업 방식을 바꾸자는 취지로 교육개혁위원회를 꾸렸다고 10일 밝혔다\n",
      "기초교육원 부원장을 역임한 유재준 물리학과 교수에게 위원장을 맡겼다\n",
      "각 학과의 교수들을 추천받아 이달 중 위원회를 구성을 완료할 방침이다\n",
      "내년부터는 각 학과에서 2∼3과목을 시작으로 강의 교수 방법 등에 변화를 모색한다\n",
      "교수가 일방적으로 강의하는 게 아니라 학생들이 미리 수업 내용을 예습하고서 수업 시간에는 질문만 하는 '플립러닝', 동료끼리 서로 가르치는 '피어티칭' 등이 도입된다고 한다\n",
      "평가 방식도 기존 시험 출제와 채점에 더해 동료의 평가를 덧붙이는 것을 검토 중이다\n",
      "이들 수업 중 일부에는 자연대가 지난해부터 준비해온 '무감독시험'도 적용된다\n",
      "자연대는 서울대 단과대학 중 처음으로 시험감독이 없는 상태에서 학생들이 양심에 따라 시험을 치르는 무감독시험과, 이를 위한 전제인 '아너 코드'(Honor code·명예규칙)를 준비해왔다\n",
      "자연대는 이러한 '교육개혁'을 통해 학생 본인의 주관에 따라 자신 있게 연구를 개척하는 '이탈자'를 많이 육성하기를 기대한다\n",
      "이는 서울대 재학생이 고등학생까지의 관성에 젖어 대학에서도 시험문제를 잘 풀지만, 자신의 답이 정답이 아니면 불안해하고 자신 있게 본인의 생각을 밝히지 못하는 경향이 있다는 자연대 교수들의 관찰과 자성이 바탕이 됐다\n",
      "유재준 위원장은 \"과거 우리나라의 성장 방식처럼 선진국의 과학기술을 배우고 쫓아가는 데는 고민이 필요 없지만 새로운 것을 선도하려면 자신만의 색깔과 논리적인 줏대가 필요하다\"며 \"이런 준비를 대학에서 해주려고 한다\"고 설명했다\n",
      "김성근 자연대학장은 \"대학의 지식 문화가 개방적이고 토론을 두려워하지 않아야 독립적인 지식주체로서 자신만의 길을 만들어가는 연구자를 길러낼 수 있다\"며 \"자신만의 문제에 천착하는 '이탈자'를 만들어내는 교육을 하고 싶다\"고 밝혔다\n",
      "서울대의 이러한 변화는 반드시 노벨상 수상자를 배출하려는 '쪽집게식' 대책은 아닐 수 있다\n",
      "하지만 이런 교육 문화가 자연스레 퍼지면 우리나라에도 노벨상을 배출할 토양이 생성될 수 있다고 서울대 측은 자체평가했다\n",
      "김 학장은 \"노벨상을 타기 위해서는 '기록경기'가 아니라서 얼마나 세계적으로 비슷한 수준에 도달했느냐보다 소신 있는 연구를 하는 것이 중요하다\"며 \"지적 호기심을 거침없이 드러내는 교육 환경을 만들다 보면 노벨상을 탈 만한 나라가 될 것으로 생각한다\"고 강조했다\n",
      "45 번 Topic 문장 :\n",
      "매년 노벨상 발표 시즌이 되면 옆 나라 일본과 달리 과학 분야 노벨상을 내지 못하는 한국의 과학 현실을 비판하는 목소리가 터져 나온다\n",
      "초등학교, 중학교, 고등학교에 이르기까지 '정답'만을 찾아 문제를 푸는 방식에 익숙해진 학생에게 새로운 분야를 개척할 창의성이 나오기 힘들다는 지적이다\n",
      "서울대 자연과학대학은 학생들이 정형화된 문제 풀이 방식에서 벗어나 창의적인 생각을 할 수 있도록 수업 방식을 바꾸자는 취지로 교육개혁위원회를 꾸렸다고 10일 밝혔다\n",
      "자연대는 서울대 단과대학 중 처음으로 시험감독이 없는 상태에서 학생들이 양심에 따라 시험을 치르는 무감독시험과, 이를 위한 전제인 '아너 코드'(Honor code·명예규칙)를 준비해왔다\n",
      "김성근 자연대학장은 \"대학의 지식 문화가 개방적이고 토론을 두려워하지 않아야 독립적인 지식주체로서 자신만의 길을 만들어가는 연구자를 길러낼 수 있다\"며 \"자신만의 문제에 천착하는 '이탈자'를 만들어내는 교육을 하고 싶다\"고 밝혔다\n",
      "김 학장은 \"노벨상을 타기 위해서는 '기록경기'가 아니라서 얼마나 세계적으로 비슷한 수준에 도달했느냐보다 소신 있는 연구를 하는 것이 중요하다\"며 \"지적 호기심을 거침없이 드러내는 교육 환경을 만들다 보면 노벨상을 탈 만한 나라가 될 것으로 생각한다\"고 강조했다\n",
      "46 번 전문 : \n",
      "UNIST(울산과학기술원)은 번개가 치는 원리를 이용한 '인공 번개 마찰 전기 발전기'를 개발했다고 6일 밝혔다\n",
      "번개는 구름 속 수증기 분자가 얼음 결정과 마찰하는 과정에서 마이너스 전자가 분리돼 축적됐다가 플러스 전자인 땅으로 떨어지며 순간적으로 엄청난 에너지를 방출하면서 생긴다\n",
      "백정민 신소재공학부 교수와 미국 조지아공대(Georgia Tech), 성균관대, KIST(한국과학기술연구원), 경희대 공동연구팀은 번개 원리를 극대화할 수 있는 3층짜리 구조의 발전기를 만들었다\n",
      "마치 구름 속 수증기와 얼음 결정 사이에 새로운 물질을 넣어 마찰이 더 일어나도록 한 것이다\n",
      "연구팀은 \"접지층은 마찰로 생성된 전하가 유실되는 것을 막는 역할도 한다\"며 \"기존 2층짜리 마찰 전기 발전기보다 16배 이상 출력이 높았다\"고 설명했다\n",
      "이번 연구는 '네이처 커뮤니케이션(Nature Communications)' 온라인판에 실렸다\n",
      "46 번 Topic 문장 :\n",
      "UNIST(울산과학기술원)은 번개가 치는 원리를 이용한 '인공 번개 마찰 전기 발전기'를 개발했다고 6일 밝혔다\n",
      "백정민 신소재공학부 교수와 미국 조지아공대(Georgia Tech), 성균관대, KIST(한국과학기술연구원), 경희대 공동연구팀은 번개 원리를 극대화할 수 있는 3층짜리 구조의 발전기를 만들었다\n",
      "마치 구름 속 수증기와 얼음 결정 사이에 새로운 물질을 넣어 마찰이 더 일어나도록 한 것이다\n",
      "47 번 전문 : \n",
      "- 이해신 교수 연구팀, 신기술 개발에 성공\n",
      "- 홍합이 가진 접착 기능 모방한 생체 재료 이용\n",
      "찔러도 피 한방울 나지 않는 주삿바늘이 국내 연구진에 의해 개발됐다\n",
      "KAIST는 화학과 이해신 교수 연구팀이 홍합이 가진 접착 기능을 모방한 생체 재료를 이용해 출혈이 없는 주삿바늘 개발에 성공했다고 6일 밝혔다\n",
      "모든 의료 처치에서 주삿바늘의 사용은 필수이다\n",
      "혈액채취와 링거, 카테터, 스텐트 삽입, 약물 및 백신 주사 등 상당수 의료적 처치는 모두 주삿바늘을 통해 이뤄진다.처치 후에는 환부를 수분 가량 압박해 지혈한다\n",
      "압박만으로도 건강한 일반인들은 3분 내외로 효과적 지혈을 할 수 있지만 장기 입원 중인 암 환자나 당뇨병, 혈우병, 아스피린 장기 복용 환자 등은 정상적인 지혈이 어렵거나 불가능한 경우가 많다\n",
      "주삿바늘에 코팅되는 지혈 재료는 주사 전에는 주삿바늘의 표면에 단단히 코팅돼야 한다\n",
      "또한 주사 처치 후에는 혈관내벽 또는 피부에 부착돼 지혈 기능을 수행해야 한다.이에 따라 기계적 물성이 강한 필름형태의 지혈 재료를 사용하는 것이 중요하다\n",
      "그러나 기존의 지혈 재료들은 기계적 물성이 약해 주사 과정에서 발생하는 마찰력을 견디지 못하는 한계를 가졌다\n",
      "연구팀은 문제 해결을 위해 홍합의 특성을 이용했다\n",
      "홍합이 섬유 형태의 족사(어패류의 몸에서 나오는 경단백질의 강인한 섬유다발)를 이용해 강한 파도가 치는 해안가의 바위에서도 단단히 붙어 생존하는 현상에 착안해 홍합 족사의 구조를 모방했다\n",
      "이러한 접착성을 의료기술과 결합하면 수분이 70% 이상 존재하는 생체 환경에서도 우수한 접착 능력을 기대할 수 있다\n",
      "연구팀은 이전에도 이를 이용한 다양한 지혈 재료들을 개발해 왔다\n",
      "연구팀의 찔러도 피가 나지 않는 주삿바늘은 일반 주삿바늘에 지혈재료를 코팅해 주사 후에 상처부위를 물리적으로 막아 자발적으로 지혈할 수 있게 만드는 기술이다\n",
      "홍합 족사 구조에 존재하는 카테콜아민 성분을 도입한 접착성 키토산을 이용해 주삿바늘 위에 지혈기능성 필름을 형성했다\n",
      "이후 혈액에 필름이 닿으면 하이드로젤 형태로 순간적으로 전이되면서 지혈 현상이 발생하는 것이다\n",
      "이 기술은 지혈 기능에 문제를 갖는 당뇨병이나 혈우병, 암 환자와 아스피린 복용자 등에게 적용 가능할 것으로 기대된다\n",
      "이해신 교수는 “개발된 기술은 모든 혈관 및 근육 주사에 효과를 보이고, 혈우병 모델에서도 효과적인 기능을 보이기 때문에 혈액 응고 장애가 있는 환자들에게 유용할 것”이라며 “카테터 및 생검바늘 등 다양한 침습 의료기기들과 결합해 새로운 기술의 발전이 가능할 것으로 기대된다”고 말했다\n",
      "한편 이번 연구는 안정성평가연구소의 강선웅·김기석 박사 연구팀 및 ㈜이노테라피와의 공동 연구로 진행됐으며, 연구결과는 재료 분야의 네이처 자매지인 ‘네이처 머티리얼즈(Nature Materials)’ 3일자 온라인판에 게재됐다\n",
      "47 번 Topic 문장 :\n",
      "찔러도 피 한방울 나지 않는 주삿바늘이 국내 연구진에 의해 개발됐다\n",
      "KAIST는 화학과 이해신 교수 연구팀이 홍합이 가진 접착 기능을 모방한 생체 재료를 이용해 출혈이 없는 주삿바늘 개발에 성공했다고 6일 밝혔다\n",
      "연구팀의 찔러도 피가 나지 않는 주삿바늘은 일반 주삿바늘에 지혈재료를 코팅해 주사 후에 상처부위를 물리적으로 막아 자발적으로 지혈할 수 있게 만드는 기술이다\n",
      "이해신 교수는 “개발된 기술은 모든 혈관 및 근육 주사에 효과를 보이고, 혈우병 모델에서도 효과적인 기능을 보이기 때문에 혈액 응고 장애가 있는 환자들에게 유용할 것”이라며 “카테터 및 생검바늘 등 다양한 침습 의료기기들과 결합해 새로운 기술의 발전이 가능할 것으로 기대된다”고 말했다\n",
      "48 번 전문 : \n",
      "분자를 부품처럼 활용한 세상서 가장 작은 기계\n",
      "메모리 소자 기술에 응용\n",
      "올해 노벨화학상은 일상 세계의 기계 장치를 분자 세계에서 구현해 세상에서 가장 작은 기계를 만든 과학자들에게 돌아갔다\n",
      "스웨덴 왕립과학원 노벨위원회는 5일 장피에르 소바주 프랑스 스트라부르대 교수(72)와 프레이저 스토더트 미국 노스웨스턴대 교수(74), 베르나르트 페링하 네덜란드 흐로닝언대 교수(65) 등 세 사람을 올해 노벨화학상 수상자로 선정했다고 발표했다\n",
      "위원회는 이들이 에너지를 운동으로 변환하는 기계장치를 분자 크기에서 구현해 화학과 기계 분야의 새 지평을 마련했다고 평가했다\n",
      "이들은 원자의 덩어리인 분자를 화학 반응이 아니라 기계처럼 사용하는 방법을 탐구했다\n",
      "여기에는 초(超)분자로 불리는 분자보다는 조금 크고 나노물질보다는 조금 작은 탄소 분자를 활용했다\n",
      "이들은 탄소원자를 기계적으로 이어붙여 고리를 만든 뒤 둘을 이어붙여 체인을 제작하거나 분자 막대 위에서 고리 하나가 왔다갔다하는 기계 장치로 구현했다\n",
      "프랑스 출신인 소바주 교수는 1983년 탄소원자로 만든 고리 두 개를 이어붙여 카테난이라는 초기 분자 기계를 개발했다\n",
      "영국 출신인 스토더트 교수는 1991년 분자 막대 하나와 분자 고리 하나를 연결시킨 로택산이란 분자 기계로 한 단계 발전시켰다\n",
      "네덜란드 출신인 페링하 교수는 1999년 세계에서 가장 작은 분자 모터를 개발하고 가장 작은 나노 자동차를 제작했다\n",
      "김기문 포스텍 화학과 교수는 “카테난과 로택산은 스위치 기능을 할 수 있어 집적도의 한계에 이른 메모리 소자를 대체할 기술로 활용하거나 약물 전달 물질의 밸브로 이용하는 연구가 진행되고 있다”고 설명했다\n",
      "노벨화학상 수상자 세 사람은 800만스웨덴크로나(약 10억3900만원)의 상금을 똑같이 나눠 갖는다\n",
      "48 번 Topic 문장 :\n",
      "올해 노벨화학상은 일상 세계의 기계 장치를 분자 세계에서 구현해 세상에서 가장 작은 기계를 만든 과학자들에게 돌아갔다\n",
      "스웨덴 왕립과학원 노벨위원회는 5일 장피에르 소바주 프랑스 스트라부르대 교수(72)와 프레이저 스토더트 미국 노스웨스턴대 교수(74), 베르나르트 페링하 네덜란드 흐로닝언대 교수(65) 등 세 사람을 올해 노벨화학상 수상자로 선정했다고 발표했다\n",
      "위원회는 이들이 에너지를 운동으로 변환하는 기계장치를 분자 크기에서 구현해 화학과 기계 분야의 새 지평을 마련했다고 평가했다\n",
      "김기문 포스텍 화학과 교수는 “카테난과 로택산은 스위치 기능을 할 수 있어 집적도의 한계에 이른 메모리 소자를 대체할 기술로 활용하거나 약물 전달 물질의 밸브로 이용하는 연구가 진행되고 있다”고 설명했다\n",
      "49 번 전문 : \n",
      "<상> 한국과학의 부끄러운 민낯\n",
      "R&D예산비중 세계 최고 불구 기초과학엔 '쥐꼬리 투자'\n",
      "제대로 된 실험실도 없어...인재육성 함께 인프라 확충을\n",
      "공무원들이 쥐락펴락..연구비용배정 체계도 뜯어고쳐야\n",
      "“연구자들이 성과를 보여주기 위해 자잘한 논문을 내는 경우가 많습니다\n",
      "기초과학연구원(IBS) 소속이 아니면 연구비 받기도 힘들다는 얘기도 나옵니다.”(유룡 KAIST 화학과 교수)\n",
      "올해로 일본이 3년 연속 노벨생리의학상 등 그동안 총 22명의 노벨과학상 수상자를 배출하는 사이 한국은 116년 노벨상 역사상 과학 분야에서 한 명의 수상자도 배출하지 못했다\n",
      "중국도 지난해 처음으로 노벨생리의학상을 공동 수상했다\n",
      "연구개발(R&D) 투자 비중이 국내총생산(GDP) 대비 4.29%(86조원)로 세계 최고 수준인 우리나라로서는 근본적인 대책을 세워야 한다는 지적이 나온다\n",
      "연구 일선에서는 정부가 당장 돈벌이가 되는 분야에만 몰리고 기초과학 연구에 상대적으로 소홀하다는 비판이 나온다\n",
      "연구예산이 증가해도 반도체·통신 등 정보기술(IT) 분야에만 매달릴 뿐 응용·첨단기술의 토양인 기초과학은 뒷전이라는 것이다\n",
      "지난 3월 인공지능(AI) 알파고가 주목받자 정부가 ‘한국형 알파고’ 계획을 내놓은 것이 단적인 예다\n",
      "유룡 교수는 “기초과학 투자를 늘리지 않고 노벨상을 바라는 것은 이미 20년 전 나온 AI 기술을 미리 키우지도 않고 당장 하겠다는 것과 같다”고 지적했다\n",
      "한국과학기술기획평가원에 따르면 2015년 우리나라의 R&D 예산 18조8,900억원 중 기초과학 예산은 1조2,081억원으로 6.4%에 불과하다\n",
      "지난해 대통령 주재 과학기술자문회의에서 노벨상을 받을 만한 과학자 1,000명을 육성하겠다는 계획을 발표했으나 우선 인프라에 투자해야 한다는 목소리도 있다\n",
      "김선영 서울대 생명과학부 교수는 “기초과학계는 김연아의 후계자를 꿈꾸는 피겨스케이터들이 제대로 된 빙상장조차 없이 훈련하는 것과 같은 열악한 수준에서 실험을 하고 있다”고 비유했다\n",
      "연구과제를 수주하기 위해 투서 등 과도한 경쟁과 공무원이 절대적인 영향력을 행사하며 공정성 시비가 끊이지 않는 연구예산 배분 과정도 개선돼야 한다는 지적이다\n",
      "박배호 건국대 물리학과 교수는 “과도한 경쟁과 줄서기가 요구되는 상황에서 창의적이고 분야를 이끄는 연구를 수행하기 어렵다”며 “연구자들이 적절한 평가 및 선정 과정을 거쳐 다른 곳에 신경 쓸 필요없이 연구를 수행할 수 있는 생태계가 조성돼야 한다”고 강조했다\n",
      "이 같은 분위기가 만들어져야 과학고등학교 학생들이 의과대로 몰리고 과학기술특성화대 졸업자들이 로스쿨과 의대로 떠나는 것을 막을 수 있다\n",
      "시민단체 ‘사교육 걱정없는 세상’ 등에 따르면 지난 2011~2015학년도 5년간 서울과학고에서 의학계열로 진학한 비율은 20.5%로 졸업생 5명 중 1명에 이른다\n",
      "과학기술을 담당하는 미래창조과학부는 정보통신기술(ICT) 쪽으로 기운 인사를 하고 있다는 비판이 제기된다\n",
      "김경진 국회 미래창조과학방송통신위원(국민의당)은 최근 국정감사에서 2013년 3월 미래부 출범 시 실·국장급 이상 고위공무원 28명 중 과학기술부 출신은 11명(39%), ICT 출신 9명(32%), 기획재정부·지식경제부 외 7명(1명 공석)이었지만 2016년 현재 고위공무원 27명 중 과기부 출신은 8명(29%)으로 3명이 줄었고 ICT 출신은 4명이 늘어 13명(48%)이 됐다고 지적했다\n",
      "1962년 이래 13명의 노벨 수상자를 배출한 영국 분자생물학실험실(LMB)이 연예산을 600억원 정도 쓰면서 시너지를 내는 것은 창의적인 교육을 받은 학생들이 맘 놓고 연구할 수 있는 기초과학 인프라를 구축했기 때문이라는 분석도 나온다\n",
      "김선영 교수는 “듬직한 나이의 중견 과학자들은 좌고우면할 것이 많고 진행 중인 과제의 동력에 함몰돼 결과에 충격과 감동이 없는 경우가 대부분”이라며 “젊은이들은 번뜩이는 아이디어뿐 아니라 모험적인 창의적 과제에 도전할 수 있는 용기와 배짱을 가지고 있다”고 말했다\n",
      "윤종용 한국공학교육인증원 이사장(전 삼성전자 부회장)은 최근 서울경제신문과의 인터뷰에서 “우리나라 연구조직을 보면 여전히 연공서열과 학연을 따지고 연구 활동보다 정부의 프로젝트를 따기 위한 문서작업이나 공무원 응대에 더 많은 시간을 쏟는 것 같다”며 “단기성과 위주의 정량 평가는 연구자들의 자율성을 떨어뜨리고 사기를 저하시킨다”고 지적했다\n",
      "49 번 Topic 문장 :\n",
      "올해로 일본이 3년 연속 노벨생리의학상 등 그동안 총 22명의 노벨과학상 수상자를 배출하는 사이 한국은 116년 노벨상 역사상 과학 분야에서 한 명의 수상자도 배출하지 못했다\n",
      "연구개발(R&D) 투자 비중이 국내총생산(GDP) 대비 4.29%(86조원)로 세계 최고 수준인 우리나라로서는 근본적인 대책을 세워야 한다는 지적이 나온다\n",
      "연구예산이 증가해도 반도체·통신 등 정보기술(IT) 분야에만 매달릴 뿐 응용·첨단기술의 토양인 기초과학은 뒷전이라는 것이다\n",
      "유룡 교수는 “기초과학 투자를 늘리지 않고 노벨상을 바라는 것은 이미 20년 전 나온 AI 기술을 미리 키우지도 않고 당장 하겠다는 것과 같다”고 지적했다\n",
      "박배호 건국대 물리학과 교수는 “과도한 경쟁과 줄서기가 요구되는 상황에서 창의적이고 분야를 이끄는 연구를 수행하기 어렵다”며 “연구자들이 적절한 평가 및 선정 과정을 거쳐 다른 곳에 신경 쓸 필요없이 연구를 수행할 수 있는 생태계가 조성돼야 한다”고 강조했다\n",
      "윤종용 한국공학교육인증원 이사장(전 삼성전자 부회장)은 최근 서울경제신문과의 인터뷰에서 “우리나라 연구조직을 보면 여전히 연공서열과 학연을 따지고 연구 활동보다 정부의 프로젝트를 따기 위한 문서작업이나 공무원 응대에 더 많은 시간을 쏟는 것 같다”며 “단기성과 위주의 정량 평가는 연구자들의 자율성을 떨어뜨리고 사기를 저하시킨다”고 지적했다\n",
      "50 번 전문 : \n",
      "인류가 오늘날 지능을 갖게 된 것은 도구를 이용하면서부터다\n",
      "손을 이용해 복잡한 도구를 만들면서 인간 뇌 용량이 점점 커졌고 복잡한 사고까지 할 수 있게 됐다\n",
      "인류 역사가 도구와 함께 발전한 점을 강조하는 ‘호보파베르(도구의 인간)’란 말이 나온 이유다\n",
      "지구에 사는 모든 생물종을 통틀어 도구를 사용하는 동물은 많지 않다\n",
      "인간과 가까운 영장류와 일부 동물에게서 종종 도구를 이용하는 모습이 발견될 뿐이다\n",
      "인간과 먼 사촌뻘인 침팬지는 돌을 망치처럼 사용한다\n",
      "늪지대 사는 고릴라는 물에 들어가기 전 긴 막대기로 물의 깊이를 잰다\n",
      "코끼리와 벙코돌고래도 도구를 이용해 파리채를 만들거나 먹이를 사냥하는 것으로 알려졌다\n",
      "하지만 동물들이 도구를 직접 만드는 모습이 발견된 적은 없다\n",
      "과학자들이 브라질 밀림에 사는 카푸친 원숭이가 돌을 깨서 망치를 만드는 모습을 세계에서 처음으로 관찰하는데 성공했다\n",
      "영국 옥스퍼드대와 런던대, 브라질 상파울루대 등 국제 공동 연구진은 브라질 세라다카피바라 국립공원에 사는 카푸친원숭이들이 구석기인처럼 돌을 깨서 석기를 만드는 것을 확인했다고 국제학술지 네이처 20일자에 발표했다\n",
      "남미 정글에 주로 사는 카푸친원숭이는 작은 얼굴에 긴 팔다리, 턱에 난 수염이 특징이다\n",
      "연구진은 브라질 동부 피아우이주(州)의 카피바라 산지 일대의 면적 약 1000㎢에 이르는 산악지대에 자리하는 세라다 카피바라 국립공원에 사는 카푸친 원숭이들을 관찰하던 도중 이들이 규암처럼 단단한 돌을 골라 다른 돌을 내리친다는 사실을 발견했다\n",
      "원숭이들이 돌을 내려쳐 조각낸 돌에선 초기 원시 인류가 만든 석기처럼 한쪽에 날카로운 면이 있는 것으로 확인됐다\n",
      "이들 원숭이들은 심지어 자신의 도구를 동료에게 과시하기도 하는 것으로 나타났다\n",
      "연구진은 “원숭이들의 이런 행동은 인간이 도구를 만드는 행동과 같다는 결론을 내렸다”고 설명했다\n",
      "허재원 한국생명공학연구원 국가영장류센터 선임연구원은 “카푸친 원숭이가 만든 석기는 인류가 만든 초기 단계인 ‘외날도끼’ 또는 ‘외날찍개’라고 불리는 형태로 볼 수 있다”고 설명했다\n",
      "지난해 이스라엘 하이파대 연구진은 영장류 일종인 보노보에게 석기를 제작하는 훈련을 시킨 결과 약 170만년전 초기 원시인류가 만들었던 도구와 유사한 수준의 석기를 만들 수 있다는 사실을 알아냈다\n",
      "하지만 이는 훈련을 시킨 결과이지 자연상태에서 이런 능력을 발휘한 것은 처음이다\n",
      "하지만 연구진은 원숭이들이 이 도구를 만들뿐 이를 사용하거나 본격적으로 생산하려는 행동은 하지 않고 있다는 사실을 함께 알아냈다\n",
      "따라서 인류 진화 과정에서 ‘호미니드(사람과 관련된 모든 영장류를 지칭)’가 생산한 도구들과 비교할 수준은 아니라고 전했다\n",
      "다만 이번 연구를 통해 반드시 도구를 만드는데 사람의 손이나 뇌가 필요하다는 건 아니라는 사실을 알게 됐다고 분석했다\n",
      "토머스 프로핏 옥스퍼드대 교수는 “도구를 만드는데는 어느 정도 지능과 물리적 기술이 필요한지 연구를 더 해봐야 한다”고 했다\n",
      "50 번 Topic 문장 :\n",
      "인류가 오늘날 지능을 갖게 된 것은 도구를 이용하면서부터다\n",
      "과학자들이 브라질 밀림에 사는 카푸친 원숭이가 돌을 깨서 망치를 만드는 모습을 세계에서 처음으로 관찰하는데 성공했다\n",
      "영국 옥스퍼드대와 런던대, 브라질 상파울루대 등 국제 공동 연구진은 브라질 세라다카피바라 국립공원에 사는 카푸친원숭이들이 구석기인처럼 돌을 깨서 석기를 만드는 것을 확인했다고 국제학술지 네이처 20일자에 발표했다\n",
      "연구진은 브라질 동부 피아우이주(州)의 카피바라 산지 일대의 면적 약 1000㎢에 이르는 산악지대에 자리하는 세라다 카피바라 국립공원에 사는 카푸친 원숭이들을 관찰하던 도중 이들이 규암처럼 단단한 돌을 골라 다른 돌을 내리친다는 사실을 발견했다\n",
      "원숭이들이 돌을 내려쳐 조각낸 돌에선 초기 원시 인류가 만든 석기처럼 한쪽에 날카로운 면이 있는 것으로 확인됐다\n",
      "연구진은 “원숭이들의 이런 행동은 인간이 도구를 만드는 행동과 같다는 결론을 내렸다”고 설명했다\n",
      "다만 이번 연구를 통해 반드시 도구를 만드는데 사람의 손이나 뇌가 필요하다는 건 아니라는 사실을 알게 됐다고 분석했다\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for i in range(1,51):\n",
    "  if i < 10:\n",
    "    file_path = '/home/lab01/sci-news-sum-kr-50/data/'+'0'+str(i)+'.json'\n",
    "  else:\n",
    "    file_path = '/home/lab01/sci-news-sum-kr-50/data/'+str(i)+'.json'\n",
    "  with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    # print(type(data))\n",
    "    # print(data)\n",
    "    print(i,'번 전문 : ')\n",
    "    data_str = '\\n'.join(data['sentences'])\n",
    "    print(data_str)\n",
    "    #print(type(data_str))\n",
    "\n",
    "    print(i,'번 Topic 문장 :')\n",
    "    for i in data['summaries']:   \n",
    "      print(data['sentences'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "painted-advisory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번 Topic 문장 :\n",
      "소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다\n",
      "1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다\n",
      "오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다\n",
      "연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다\n",
      "2 번 Topic 문장 :\n",
      "러시아·미국·일본 우주인 3명이 지구로 돌아왔다\n",
      "러시아 모스크바 인근 우주비행통제센터는 30일(현지시간) 러시아 우주인 아나톨리 이바니쉰, 미국 여성 우주인 캐슬린 루빈스, 일본 우주인 오니시 다쿠야 등을 태운 소유스 우주선 귀환캡슐이 카자흐스탄 남동부 초원 지대에 무사히 착륙했다고 밝혔다\n",
      "개량형 우주선 `소유스 MS-01`을 타고 지난 7월 지구를 떠난 우주인 3명은 우주정거장에서 40여가지 과학 실험을 수행했다\n",
      "3 번 Topic 문장 :\n",
      "유전 정보를 담은 DNA를 자르고 편집하는 유전자 가위는 최근 생명과학계에서 가장 주목받는 기술로 손꼽힌다\n",
      "2013년 처음 발표된 3세대 크리스퍼 유전자 가위(CRISPR-Cas9)가 등장한 데 이어 지난해 유전자 가위의 절단효소로 사용하는 Cas9을 대체할 새 단백질(Cpf1)을 찾아냈다\n",
      "이 신형 유전자 가위는 올초 기존 유전자 가위보다 정확도가 훨씬 높다는 사실이 입증됐다\n",
      "지난해에 이어 두 번째로 열린 이번 공모전에는 IBS 산하 26개 연구단 연구원들이 한 해 동안 발견한 미시 세계의 신비한 사진과 컴퓨터가 만들어낸 예술 작품 같은 그림 16편이 선정됐다\n",
      "4 번 Topic 문장 :\n",
      "68년만에 지구에 가장 근접하는 `슈퍼문`을 14일 저녁에 볼 수 있다\n",
      "이날 달이 더 크게 보이는 원리는 망(望)인 동시에 달이 지구와 가장 가까워지는 근지점을 통과해 달과 지구 거리가 짧아지기 때문이다\n",
      "지구를 기준으로 태양과 달이 정반대편에 일직선으로 위치할 때 보름달을 볼 수 있으며, 타원 궤도를 도는 달이 근지점을 통과할 때 달이 더 커보인다\n",
      "월식은 달이 지구 그림자에 들어가는 현상이다\n",
      "개기월식이 일어날 때 달이 붉게 보인다\n",
      "일식이란 달이 지구와 태양 사이를 지나면서 달이 태양을 가리는 현상이다\n",
      "5 번 Topic 문장 :\n",
      "애니메이션에서나 볼 수 있었던 자동차 변신 로봇이 일본에서 실제로 만들어진다\n",
      "11일 소프트뱅크 계열 로봇 제조업체인 아스라테크(Asratec)와 산세이 테크놀로지, 브레이브 로보틱스가 3사 합작으로 변신 로봇 '제이 다이트 라이드(J-deite RIDE)'를 제작한다고 발표했다\n",
      "이 로봇은 아스라테크와 브레이브 로보틱스가 참여한 로봇 제조 계획 \"프로젝트 제이 다이트'의 일환으로 지난해 6월부터 개발이 진행되고 있다\n",
      "6 번 Topic 문장 :\n",
      "접는 스마트폰 개발 전쟁이 치열하게 붙었다\n",
      "삼성전자가 지난 4월 접는 스마트폰의 특허를 특허청에 출원했다고 독일의 온라인 매체 ‘갤럭시 클럽’이 9일(현지시간) 보도했다\n",
      "갤럭시 클럽이 입수한 특허 신청서의 도면에 따르면 이 스마트폰은 반으로 접거나 휠 수 있다\n",
      "지난해 삼성전자가 특허출원한 스마트폰은 화면을 접을 수 있을 뿐 아니라 두루마리 형태로 둘둘 말 수 있는 형태였다\n",
      "7 번 Topic 문장 :\n",
      "국내 연구진이 페로브스카이트(Perovskite) 태양전지가 내구성이 부족한 이유를 처음으로 밝혔다\n",
      "서울대 공대는 기계항공공학부 최만수 교수 연구팀이 페로브스카이트 태양전지의 내구성 저하에 대한 메커니즘을 최초로 규명하고, 고효율 및 고안정성 페로브스카이트 태양전지를 개발했다고 10일 밝혔다\n",
      "연구팀이 실험을 통해 태양전지를 잘라 분석해 본 결과, 다결정 구조인 페브로스카이트의 계면(결정과 결정이 만나는 면)에 전하가 축적돼 필름을 변화시키는 것으로 나타났다\n",
      "8 번 Topic 문장 :\n",
      "나노·바이오·에너지가 공학과 만나 새로운 학문이 속속 등장하고 있으며 기계공학자들이 이들 신생 연구 분야에 뛰어들고 있다\n",
      "조맹효 서울대 기계항공공학부 교수는 “고전적 기계공학의 외연을 넓히려는 시도가 지난 10여년 동안 급박하게 진행됐다”며 “융합·협력 연구는 이미 세계적인 추세”라고 말했다\n",
      "데이터 활용은 필연적으로 컴퓨터가 데이터 분석으로 스스로 학습해 궁극적으로 수많은 데이터를 분석하도록 하는 딥러닝 인공지능(AI)과의 접점을 형성한다\n",
      "조 교수는 “예를 들어 미국 항공우주국(NASA)에는 그동안의 비행 관련 실험이 무수히 쌓여 있는데 이를 데이터베이스화해서 데이터를 추출하고 의미 있는 정보로 만드는 ‘역순’으로 계산식을 도출하는 형태”라고 설명했다\n",
      "9 번 Topic 문장 :\n",
      "이 사고에서는 테슬라 모델 S를 타고 오토파일럿을 작동시킨 채로 운전을 하던 한 오하이오 주민이 숨졌다\n",
      "필자는 오토파일럿 시스템이 가장 발전된 인간-기계 상호작용 실험 중 왜 오류를 일으켰는지 알고 싶었다\n",
      "피해자의 차는 플로리다의 27A 고속도로에서 트랙터 트레일러와 충돌했다\n",
      "테슬라의 초기 사고 보고서에 따르면, 차량의 비상 제동장치가 맑은 하늘과 트랙터 트레일러의 흰색 옆구리를 분간하지 못했기 때문이라고 한다\n",
      "그러나 자동 안전장치 전문가들과 테슬라에게 더 중요한 사실은 운전자가 임박한 충돌을 눈치 채지 못했다는 것이다\n",
      "자율주행 자동차가 거리에 나서기 시작하면서 일상 속 로봇에 대해 오랫동안 갖고 있던 잘못된 개념을 다시 돌아볼 때가 되었다\n",
      "자동차 회사들도 그것과 비슷한 단기 교육 프로그램을 만들어 운전자들에게 자동화 시스템의 작동방식은 물론, 이 시스템이 어떤 상황에서는 작동되고 어떤 상황에서는 작동되지 않으며, 인간이 필요시 개입해야 하는 이유가 뭔지 가르쳐야 한다\n",
      "“오류가 발생했을 때 사람이 명령 체계를 떠나 있는 경우가 많다는 것, 그리고 오류를 발견하고 시정하는 데 시간이 많이 걸린다는 것이 오토파일럿과 같은 자동화 기술의 문제입니다.”\n",
      "멈추십시오.” 같은), 제어 장치의 물리적 변화(운전대의 각도 변화 등)를 사용해 운전자들에게 상황의 변화(끼어들기)를 알리고, 아무 것도 모르고 지나가다가 사고를 내는 것을 예방해야 한다고 한다\n",
      "기술이 고속도로 주행 중 사람들의 주의력을 낮추거나 졸게까지 할 수 있다면, 그것을 운용하는 인간은 더 많은 훈련을 받아야 하며 더욱 지능적인 경고 시스템도 필요하다\n",
      "10 번 Topic 문장 :\n",
      "DNA의 염기서열 정보를 이용해 움직이는 초미세로봇 기술이 개발됐다\n",
      "박소정 이화여대 교수와 이대연·존 크로커 미국 펜실베이니아대 교수 연구진으로 구성된 한미 공동연구팀이 DNA의 염기서열 정보를 이용해 원하는 대로 구동하는 ‘연성재질 미세로봇’ 핵심 기술을 세계 처음으로 개발하는 데 성공했다고 7일 밝혔다\n",
      "박소정 교수는 “DNA의 염기서열 조작과 반응을 통해 다양한 방식으로 움직이는 나노 구조체를 최초로 구현했다”이라며 “정해진 자극에 따라 복잡한 움직임을 수행할 수 있는 나노로봇 제작 가능성을 열었다”고 설명했다\n",
      "이번 연구 논문의 제1저자인 심태섭(사진) 아주대 교수는 “0과 1의 2진수로 제어하는 컴퓨터와 달리 A와 T, G, C 등 4진수의 정보를 갖는 DNA 염기서열을 통해 보다 다양하고 복잡한 명령을 내릴 수 있는 나노로봇”이라며 “제어기술이 더욱 발전하면 약물 전달이나 혈관 확장 등 복잡하고 까다로운 환경에서도 정교한 구동이 가능한 미세로봇 제작이 가능할 것”이라고 말했다\n",
      "11 번 Topic 문장 :\n",
      "미국 국방부는 지난달 말 인공지능(AI)을 이용해 인간 도움 없이 적을 식별해 타격하는 드론(무인 항공기)을 시연했다\n",
      "이 드론은 카메라 화면에서 총으로 무장한 사람과 무기가 없는 사람을 구분할 수 있다\n",
      "조만간 원격 조종 없이도 전장에서 특수부대 군인들처럼 임무를 수행하는 드론이 등장할 전망이다\n",
      "이 드론이 사람 도움 없이 카메라 영상에서 목표물을 인식하고 추적할 수 있는 것은 바로 ‘머신러닝’ 덕분이다\n",
      "머신러닝은 AI의 한 분야로 컴퓨터가 인간처럼 스스로 학습할 수 있는 능력을 부여하는 작업을 말한다\n",
      "머신러닝의 원리는 인간을 포함한 영장류 두뇌의 정보 처리 구조인 ‘신경망’을 모사하는 방식이다\n",
      "AI 과학자들은 나선형 신경망에서 아이디어를 얻어 이미지에서 사물을 판별하는 알고리즘을 설계했다\n",
      "제프 딘 구글 수석연구원은 “나선형 신경망은 다른 머신러닝 구조들과 비교할 때 영상, 음성 분야에서 좋은 성능을 보인다”며 “이를 이용하면 컴퓨터가 처음 본 사물도 무엇인지 파악할 수 있다”고 설명했다\n",
      "과학자들은 나선형 신경망을 본뜬 머신러닝 기술을 응용해 인간 삶을 윤택하게 할 수 있는 기술을 개발하고 있다\n",
      "연구팀이 개발한 AI 드론은 카메라가 촬영한 이미지를 이용해 숲이 우거진 곳과 등산로를 구분한다\n",
      "신경망 학습 기술은 다양한 용도로 활용할 수 있다\n",
      "12 번 Topic 문장 :\n",
      "인텔은 4일(현지시간) ‘슈팅스타(Shooting Star)’라고 불리는 자사의 드론으로 ‘가짜 불꽃놀이’를 시연하는 데 성공했다고 밝혔다\n",
      "이들 드론은 자율 알고리즘이 내장돼 있기 때문에 하늘에 그릴 그림이나 글자를 지정해주면 개별 드론이 알아서 적절한 위치로 비행을 한다\n",
      "13 번 Topic 문장 :\n",
      "남이 자신을 위협한다든가 남의 물건을 훔치는 등 피해망상에 사로잡히거나 헛것을 보고 듣는 것도 알츠하이머병의 증상입니다\n",
      "혈관성 치매는 뇌경색 뇌출혈 뇌졸중 등 뇌혈관 질환으로 뇌가 손상돼 나타나는 병입니다\n",
      "혈관성 치매도 알츠하이머병처럼 기억력과 판단력 등 인지능력이 떨어집니다\n",
      "최근 미국 제약사 머크가 알츠하이머병 치매 치료제 ‘베루베세스타트’ 초기 임상에서 알츠하이머병 치매 원인 단백질인 베타아밀로이드를 최대 90%까지 감소시킨 것으로 알려졌습니다\n",
      "14 번 Topic 문장 :\n",
      "차세대 우주선 오리온(Orion)의 승무원 모듈에 대한 실험이 태평양에서 이뤄져 관심을 모으고 있다\n",
      "미국 항공우주국(NASA)은 지난달 27일 캘리포니아 해변에서 오리온의 승무원 모듈에 대한 실험을 진행했다\n",
      "오리온은 계획된 실험이 끝나면 차세대발사시스템인 SLS(Space Launch System)로켓에 실려 우주로 발사된다\n",
      "15 번 Topic 문장 :\n",
      "대학과 산업계, 공공연구기관에서 일하는 기술경영 전문가 10명 중 7명은 박근혜 정부의 과학기술 정책이 실패했다고 평가하는 것으로 나타났다\n",
      "10명 중 8명은 과학기술 전담 부처의 필요성에 공감했다\n",
      "과학기술처에서 과학기술부, 교육과학기술부를 거쳐 미래창조과학부로 전담 부처 이름을 바꾸고 정책 기조가 바뀌면서 일관성 있는 과학기술 정책을 추진하지 못했다는 것이다\n",
      "16 번 Topic 문장 :\n",
      "UNIST(울산과학기술원)는 수소차에 쓰이는 수소 연료전지를 저렴하게 만들 수 있는 촉매 합성법을 개발했다고 3일 밝혔다\n",
      "백금을 대체할 물질로 탄소 촉매가 거론됐지만 700도 이상의 고온 열처리를 통해 합성되기 때문에 촉매 활성점이 파괴돼 촉매 효율이 떨어지는 문제가 있었다\n",
      "주 교수팀은 촉매 활성점이 파괴되는 것을 막기 위한 '실리카 보호층'을 도입해 이런 문제를 해결했다\n",
      "주 교수는 \"연료전지 상용화에 한 단계 접근할 수 있을 것으로 기대된다\"며 \"이번 연구에서 개발한 합성법은 연료전지 외에도 다양한 에너지 변환 및 저장 장치에 적용될 수 있을 것이다\"고 강조했다\n",
      "17 번 Topic 문장 :\n",
      "\"우리는 인공지능(AI)이 갖는 잠재력과 힘, 영향력을 모든 사람이 쉽게 사용하고 접근할 수 있도록 민주화하길 바랍니다\"\n",
      "피터 리(Peter Lee) 마이크로소프트연구소 총괄 부사장은 2일 서울 서대문구 연세대에서 열린 '21세기 컴퓨팅 콘퍼런스 2016'에서 AI를 향한 미래 비전을 이같이 강조했다\n",
      "이 행사는 올해로 18번째로, '인간과 AI가 공존하는 시대'라는 주제로 열렸다\n",
      "컨퍼런스 기조연설하는 피터 리 부사장 (서울=연합뉴스) 윤동진 기자 = 3일 오전 서울 연세대학교 대강당에서 '인간과 AI가 공존하는 시대'를 주제로 열린 21세기 컴퓨팅 컨퍼런스 2016에서 피터 리 마이크로소프트연구소 총괄 부사장이 4차 산업혁명에서 AI가 가져올 변화에 관해 기조연설을 하고 있다\n",
      "기조연설하는 피터 리 부사장 (서울=연합뉴스) 윤동진 기자 = 3일 오전 서울 연세대학교 대강당에서 '인간과 AI가 공존하는 시대'를 주제로 열린 21세기 컴퓨팅 컨퍼런스 2016에서 피터 리 마이크로소프트연구소 총괄 부사장이 4차 산업혁명에서 AI가 가져올 변화에 관해 기조연설을 하고 있다\n",
      "샤오우엔 혼 마이크로소프트 부사장샤오우엔 혼 부사장(마이크로소프트연구소 아시아 소장)이 3일 연세대학교 신촌캠퍼스에서 열린 '21세기 컴퓨팅 컨퍼런스 2016’에서 발표를 하고 있다\n",
      "18 번 Topic 문장 :\n",
      "우리나라 기초연구의 문제가 국가혁신시스템에서 기초연구 전략이 부족하다는 지적이 나왔다\n",
      "과학기술정책연구원(STEPI)이 3일 한국과학기술회관에서 열린 `기초연구 경쟁력, 질적 혁명에서부터`라는 주제 정책포럼에서 이민형 STEPI 선임연구위원은 “정부가 풀뿌리 지원만 강조하는데 `왜 기초연구를 하는가`에 대한 근본적 질문이 없다”고 비판했다\n",
      "기초과학이 국가 성장동력 핵심으로 강조되면서 세계 각 국은 기초연구 투자를 확대하고 있다\n",
      "이 위원은 “연구를 하려면 장비 인프라를 다루는 전문적 엔지니어가 있어서 연구자와 함께 협업을 해야 하는데 이 부분은 지원이 안 된다”면서 “지금은 논문 낸 사람만 칭찬 받는데, 논문 결과는 `부분적`이고 한 나라의 과학 활동의 토대를 닦는 것은 인프라로, 이게 갖춰지지 않으면 노벨상은 기대하기 어렵다”고 전했다\n",
      "19 번 Topic 문장 :\n",
      "흡연이 폐에 어떤 영향을 미치는 지 정확히 연구할 수 있는 흡연로봇이 개발돼 주목을 받고 있다\n",
      "미국 하버드 대학 위스 응용 생물학 공학 연구소(Wyss Institute for Biologically Inspired Engineering)가 개발한 흡연로봇은 흡입된 연기가 인간의 기관을 모방한 마이크로칩을 통과하기 때문에 흡연이 폐에 어떻게 영향을 미치는지 정확하게 연구할 수 있다\n",
      "흡연이 사람들에게 어떤 영향을 미치는지에 대해 연구해온 와이즈 응용 생물학 공학 연구소의 연구팀은 기존 방식보다 정확한 테스트를 위해 흡연로봇을 개발했다\n",
      "이에 생리적 호흡과 인공 폐를 결합한 흡연로봇이 개발된 것으로, 환자의 병세가 유전자에 의한 것인지, 가정환경이나 작업환경에 관련된 것인지 등 개별 흡연자의 조건 비교가 가능해 만성 폐쇄성 폐질환이 악화되는 원인을 밝히는 데 도움이 될 것으로 연구진은 기대하고 있다\n",
      "20 번 Topic 문장 :\n",
      "기계가 인간에 가깝게 진화하는 것으로 음성인식 기술의 궁극적 발전 단계에 속한다\n",
      "삼성전자는 지난달 시리를 만든 비브랩스(VIV Labs)를 인수하고 새로운 서비스 출시를 예고하며 음성인식 기술에 대한 관심을 고조시켰다\n",
      "박범근 연구성과실용화진흥원 매니저는 “음성인식은 음성으로부터 추출한 독특한 특성을 이용하는 인식기술”이라며 “비강과 구강·구강 모양 등에 의한 음성학적 특성을 이용한다”고 설명했다\n",
      "21 번 Topic 문장 :\n",
      "인공지능(AI)이 인간의 일자리를 대거 대체하는 '4차 산업혁명'으로 발생할 수 있는 대규모 실업 문제를 해결하려면 현행 노동시간부터 줄여야 한다는 전문가 진단이 나왔다\n",
      "연세대 바른ICT연구소의 임지선 박사는 2일 연세대 신촌 캠퍼스에서 열리는 '바른 ICT 리서치 컨퍼런스 2016'의 발표 자료에서 \"4차 산업혁명 시대에서는 수동적 노동자가 능동적 생산자로 바뀔 수 있는 재교육 기회가 매우 중요하다\"며 이처럼 주장했다\n",
      "특히 정보기술의 발달로 교육에 대한 진입장벽과 비용이 떨어지는 만큼, 각 노동자의 지적 필요에 맞게 부담 없이 재교육·직업교육을 받을 수 있는 환경을 마련해야 한다고 임 박사는 당부했다\n",
      "22 번 Topic 문장 :\n",
      "미래창조과학부는 박재형 성균관대 교수 연구팀이 나노로봇(10억분의 1ｍ 크기의 초미세 로봇)을 이용해 외과 수술 없이 종양을 치료하는 기술을 개발했다고 1일 발표했다\n",
      "이번에 개발된 금·티타늄 재질의 나노로봇은 체내에 주입되면 종양을 추적해 달라붙는다\n",
      "박 교수는 “나노로봇은 정확하게 암을 선별해 공격할 수 있다”며 “정상 세포를 해칠 수 있는 방사선 치료 등에 비해 부작용이 훨씬 줄어들 것으로 보인다”고 말했다\n",
      "23 번 Topic 문장 :\n",
      "서울대 연구팀 \"뿌리가 햇빛 분석해 잎과 줄기 생장에 영향 끼쳐\"\n",
      "식물 뿌리가 햇빛을 모니터링해 최적의 생장 환경을 만드는 것으로 파악됐다.잎이 흡수한 햇빛은 줄기와 뿌리의 관다발을 통해 지하의 뿌리까지 전달된다\n",
      "국내 연구팀이 식물 뿌리가 햇빛을 모니터링하면서 잎과 줄기 생장에 큰 영향을 끼친다는 사실을 밝혀냈습니다\n",
      "연구팀은 최근 광화학적 분자생물학적 연구 기술을 융합해 잎에서 흡수된 빛이 광섬유와 비슷한 물리적 구조를 가지는 관다발을 통해 직접 지하의 뿌리까지 전달된다는 사실을 처음으로 증명했습니다\n",
      "이번 연구 결과는 식물 뿌리가 빛을 포함한 다양한 외부 환경 정보를 수집하고 적절하게 반응한다는 사실을 밝혀냄으로써 앞으로 'root-brain' 가설의 타당성 검증에 크게 기여할 것으로 기대됩니다\n",
      "박충모 교수는 \"찰스 다윈은 자신의 연구를 종합했을 때 식물도 지능행동을 하고 그 중심에는 뿌리가 있을 것이란 가설을 세웠다\"며 \"이번 연구결과를 통해 외부 신호를 받아 프로세싱하고 분석하고 명령을 내리는 기능을 뿌리가 하고 있다는 것을 확인했다\"고 말했습니다\n",
      "24 번 Topic 문장 :\n",
      "포스텍은 기계공학과 4학년에 다니는 유재원씨(가운데)가 같은 과 김동성 교수(왼쪽)와 최동휘 연구교수(오른쪽)의 지도를 받아 소금을 이용해 물을 흡수하지 않고 튕겨내는 초소수성 표면을 간단히 제작하는 방법을 개발했다고 1일 발표했다\n",
      "반면 유씨가 개발한 방법은 흔히 주변에서 손쉽게 구할 수 있는 소금과 물만을 이용한다\n",
      "액상 실리콘과 폴리디메틸실록산(PDMS)으로 만든 표면에 소금을 뿌려 건조시킨 뒤 물에 녹이면 소금 입자가 있던 자리에 마치 돌기처럼 다양한 크기 미세 구조물이 생긴다\n",
      "25 번 Topic 문장 :\n",
      "김 박사는 “한국에 알파고 이후 인공지능(AI) 열풍이 불고 있는데, 이미 미국에서는 AI가 체스를 이겨 충격을 받은 지 오래”라며 “AI는 슈퍼컴퓨터 없이는 구현할 수가 없는데, 한국이 개발하겠다는 AI 소프트웨어만 갖고는 할 수 있는 게 없다”고 지적했다\n",
      "김 박사는 “AI를 구현하려면 하드웨어는 당연히 같이 개발돼야 한다”며 “한국 프로젝트는 한국적인 슈퍼컴퓨터 플랫폼을 만들어 핵심(Core) 기술을 개발하려는 것이 아니라 외국 컴퓨터를 몇 대 사오려고 하는 것 같다”고 말했다\n",
      "그는 “현재 위, 담낭 등의 사이즈를 엑스레이로 정확히 측정하기 어렵고 슈퍼컴퓨터로 구현하려면 10~11시간을 기다려야 하는데, 이를 1분 안에 할 수 있으면 개인 맞춤형 의료가 가능해진다”고 말했다\n",
      "김 박사는 “슈퍼컴퓨터 공통 플랫폼(Common Platform)을 먼저 만들어야 한다”면서 “집을 지을 때 상세한 청사진이 있는 것처럼 한국적인 플랫폼을 우선 만들고 필요한 부가 기능은 API로 연결하면 자연적으로 기술 산업화가 이뤄질 수 있다”고 말했다\n",
      "26 번 Topic 문장 :\n",
      "공룡의 뇌 화석(사진)이 세계 최초로 확인됐다\n",
      "데이비드 노먼 영국 케임브리지대 지구과학부 교수팀은 2004년 영국 서식스 주에서 발견된 화석을 분석한 결과 1억3300만 년 전에 살았던 것으로 추정되는 공룡의 뇌 조직인 것으로 밝혀졌다고 27일(현지 시간) 발표했다\n",
      "노먼 교수팀의 공룡 뇌가 화석으로 남아 있을 수 있었던 까닭은 공룡이 사망 직후 산소가 거의 없고 산성도가 높은 물에 머리가 잠겼기 때문이다\n",
      "27 번 Topic 문장 :\n",
      "뉴호라이즌호가 작년 7월부터 수집한 명왕성의 데이터를 모두 지구로 전송하는데 성공했다\n",
      "스페이스닷컴 등 외신은 나사 우주선 뉴호라이즌호가 명왕성을 저공비행하며 촬영한 데이터의 마지막 조각까지 전송했다고 28일 보도했다\n",
      "나사의 앨런 스턴 뉴호라이즌 연구 책임자는 \"수집한 데이터를 통해 확인한 명왕성과 주변 위성의 아름다움과 복잡성은 우리를 깜짝 놀라게했다\"며 \"이제 지구로 보내진 데이터를 과학적인 관찰을 통해 이해하는 큰 작업이 남아있다\"고 말했다\n",
      "28 번 Topic 문장 :\n",
      "자외선 영역의 파장에서는 태양의 '코로나 홀'을 더 쉽게 관찰할 수 있다\n",
      "미국 항공우주국(NASA)의 태양활동관측위성(SDO)이 최근 태양의 비교되는 이미지를 촬영해 28일(현지 시간) 홈페이지에 공개했다\n",
      "태양에 대해 다양한 파장 영역으로 관찰하면 상세한 데이터를 얻을 수 있다\n",
      "29 번 Topic 문장 :\n",
      "자석 아닌 물질에 자성(磁性)을 갖게 하는 기술이 개발됐다\n",
      "카이스트(KAIST) 물리학과 양찬호 교수 연구팀이 전기장을 통해 자석이 아닌 물질이 자성을 갖게 하거나 그 반대로 자석 내의 자성을 없앨 수 있는 기술을 내놓아 눈길을 끈다\n",
      "이번 연구를 응용하면 자성 물질 기반의 저장 매체를 개발해 대용량의 정보를 빠른 속도로 이용할 수 있을 것으로 기대된다\n",
      "자기전기 상호작용은 자기장이 아닌 전기장을 이용해 전류의 흐름 없이 자성 상태를 조절하는 방식으로 에너지 소모가 적다는 장점을 갖는다\n",
      "이번 기술은 화학적 도핑을 통해 상온에서도 작동이 가능하고, 변환이 가역적이며 비휘발성을 갖기 때문에 차세대 정보 저장 소자 개발의 발판이 될 것으로 기대된다\n",
      "30 번 Topic 문장 :\n",
      "　1969년 인류가 달에 첫발을 내디딘 후, 사람들은 다음 목표로 화성을 주목해 왔다\n",
      "47년이 흐른 지금, 40대 이상의 무인 우주선이 화성으로 떠났지만 아직 인류의 발자국을 남기지는 못했다\n",
      "　현시점에서 가장 빨리 화성에 도달할 나라는 미국이다\n",
      "여기에 질세라 민간 우주기업 스페이스X도 화성 유인 탐사를 준비하고 있어 둘 중 누가 먼저 화성에 도착하게 될지 관심이 모아지고 있다\n",
      "　NASA는 화성 탐사를 위해 신형 2단 로켓 ‘우주발사시스템(SLS)’ 로켓을 개발 중이다\n",
      "2단으로 구성돼 있고 지구를 탈출할 힘을 얻는 1단 추진체는 여러 대의 로켓을 하나로 묶는 ‘클러스터링’ 기법으로 만든다\n",
      "화성 탐사 유인 우주선 ‘오리온’이 포함된 2단 로켓에는 발사에 문제가 생길 경우 승무원을 안전한 거리까지 이동시킬 발사 중단 시스템(LAS)이 포함돼 있다\n",
      "　현실적인 기술로 화성에 도전하는 NASA와 달리 스페이스X는 기술 혁신을 통한 비용 절감을 최대 기치로 내걸고 있다\n",
      "스페이스X가 개발 중인 ‘행성 간 이동 시스템(ITS)’ 로켓의 핵심은 최근 신기술로 각광받고 있는 ‘로켓 재사용’ 기술이다\n",
      "　옥호남 한국항공우주연구원 발사체기술개발단장은 “NASA와 스페이스X는 서로 간의 경쟁을 통해 유인 화성 탐사를 앞당기고 있다”라며 “지금으로선 NASA의 계획이 좀 더 현실성이 있지만 스페이스X의 계획도 아주 허황되지는 않다”라고 말했다\n",
      "31 번 Topic 문장 :\n",
      "하지만 이 헬리콥터는 폐기처분을 면하고 수륙양용 자동차로 제2의 삶을 살게 되었다\n",
      "그는 이 헬리콥터를 기증받자 친구와 가족 등 16명의 도움으로 폐기 처분된 헬리콥터를 주행가능한 자동차로 개조했다\n",
      "이제 이 차량은 하늘을 제외하면 어디라도 갈 수 있다.지난 5월, 블로크가 만든 이 <레이스콥터>는 뉴 저지 주 밀빌에서 열린 24시간 레몬스 레이스 대회에서 주최자 상을 탔다\n",
      "32 번 Topic 문장 :\n",
      "국내 연구팀, 특정 단백질 증가 현상 찾아내…폐암 조기 진단 키트·신약 개발 기대\n",
      "[아시아경제 정종오 기자] 폐암을 조기에 진단할 수 있는 생화학 마커를 국내 연구팀이 발견했습니다\n",
      "폐암환자의 92.5%에서 'USE1' 단백질이 증가돼 있고 이중 13%에서는 USE1 유전자에 돌연변이가 발생해 폐암이 발생한다는 사실을 발견했습니다\n",
      "수십 년 동안 진단과 치료 기술이 개발됐는데 특별한 자각증상이 없고 대부분 진행 암 또는 다른 부위에까지도 전이된 상태에서 발견돼 폐암 환자의 완치율은 30% 이하로 낮습니다\n",
      "폐암 진단을 위해 바이오 마커라는 이름으로 제시된 물질들이 존재하는데 여전히 충분한 특이성(specificity)과 민감성(sensitivity)을 나타내지 못하고 있습니다\n",
      "연구팀은 106명의 폐암환자의 폐암 조직과 정상조직의 단백질의 발현 양을 비교 분석한 결과 폐암조직의 92.5%에서 USE1의 발현양이 증가돼 있음을 확인했습니다\n",
      "초고속 질량 분석기를 이용해 USE1의 결합 단백질을 확인한 결과 세포주기 조절에 중요한 역할을 하는 'APC/C'에 의해 USE1의 발현양이 조절됨을 규명했습니다\n",
      "이창환 교수는 \"이번 연구 성과는 폐암의 발병과 관련된 중요한 핵심 단백질을 발견한 것\"이라며 \"폐암을 진단할 수 있는 특이적 바이오 마커로서 사용할 수 있어 폐암에 관한 이해를 높이고 폐암의 조기 진단 키트와 신약개발 등이 가능하다\"고 말했습니다\n",
      "33 번 Topic 문장 :\n",
      "‘워싱턴 포스트’ 지의 2015년 보도에 따르면, 경찰에게 테이저로 사격을 당한 후 구속 중 사망하는 사람이 1주에 1명 꼴로 발생한다고 한다\n",
      "전도성 전기 병기인 테이저로 인한 중상자 대부분은 근육 마비에 의한 낙상으로 인해 생긴다\n",
      "현재 여러 연구자들은 테이저에 EKG(심전도) 기기를 추가하면 피의자의 심부담을 측정함으로서 피의자의 심장 위험을 막을 수 있다고 생각한다\n",
      "“테이저에 피격된 사람이 의학적으로 문제가 있음을 알게 된다면, 신속하게 응급조치를 취해 그 사람의 생명을 구할 수 있습니다.”\n",
      "1년에 테이저 때문에 죽는 사람이 정확히 몇 명인지는 확실히 발표된 바가 없지만, 보즈먼과 그의 동료들은 더욱 안전한 테이저를 만들고자 한다\n",
      "보즈먼과 동료인 제이슨 스토피라 박사는 두 기기를 결합하는 작업이 가능할 거라고 생각했다.이들은 미국 사법 연구소의 자금 지원을 받아, 테이저에 생체 감시 기능을 부여하는 데 착수했다\n",
      "보즈먼과 스토피라는 ‘과학 수사 및 법의학 저널’에 실린 자신들의 연구 결과로 인해, 기존 테이저 제작사들이 의료 기기 제작사들과 협력 관계를 체결해 이와 유사한 기기를 생산하기를 바라고 있다\n",
      "이들은 생체 감시 테이저가 피의자의 심장 정보를 자동적으로 기록하고 심부담이 높을 경우 이를 시청각 수단으로 경고해 주기를 바라고 있다\n",
      "이 때 테이저로 기록한 피의자의 심장 정보를 분석해 의료 전문가들에게 귀중한 건강 데이터로서 제공한다면, 경찰을 비난으로부터 보호할 수 있는 것이다\n",
      "34 번 Topic 문장 :\n",
      "미래창조과학부는 온실가스를 줄이기 위한 사업인 '기후산업육성모델'의 대상으로 2개 과제를 선정했다고 23일 밝혔다\n",
      "건축물의 곡면 외벽에 적용할 수 있는 고효율의 플렉서블 태양전지를 개발한다는 것이 첫 번째 과제로 꼽혔다\n",
      "KIST 연구진은 연료전지의 부피는 기존의 60% 수준으로 줄이면서도, 발전효율은 최고 수준으로 높인다는 목표를 세웠다\n",
      "35 번 Topic 문장 :\n",
      "AI로 한국인·중국인·일본인들의 얼굴을 분석한 결과, 각 인종별로 몇가지 패턴이 존재했다\n",
      "인공지능(AI)이 사람보다 더 정확하게 한·중·일 3국 인종을 구분한다는 연구 결과가 나왔다\n",
      "미국 워싱턴포스트는 “미국 로체스터대 컴퓨터학과 연구팀이 한국인과 중국인, 일본인의 얼굴 자료 4만여 건을 AI를 통해 구분한 결과 약 75％의 정확도로 국적을 구분했다”고 21일(현지시각) 보도했다\n",
      "36 번 Topic 문장 :\n",
      "메타물질은 빛의 파장보다 매우 작은 인공 구조체를 `원자`로 해 집합체를 만들었을 때 집합체가 새로운 균일 물질로 새로운 물성을 보이는 것이다\n",
      "메타물질은 기존 자연계에 존재하는 물질에는 없는 특별한 성질을 갖는 물질을 총칭한다\n",
      "자연물질이 제공하지 못하는 특이한 물리적 성질을 띠기 때문에 다양한 파동 영역에서 에너지의 집속, 고해상도 이미징, 클로킹, 스텔스 등 다양한 응용 연구가 진행되고 있다\n",
      "메타물질 특성을 조작하면 빛이나 전자기파가 반사되지 않고 투과되게 만들 수 있기 때문이다\n",
      "음파, 진동, 지진파 메타물질은 음파 등에 대해 원하는 특성을 가지도록 미세 구조체를 만든 메타물질이다\n",
      "연구팀은 파동 특성 간 상호 작용을 제어할 수 있는 원리를 찾고, 이를 조절해 탄성값과 밀도, 그리고 쌍이방 특성을 완전히 분리해 자유롭게 제어할 수 있는 메타원자를 제작했다\n",
      "(왼쪽) 제작된 만능형 음향 메타원자 (가운데) 메타원자 내의 압력장 분포와 질량밀도, 압축률 변화 (오른쪽) 쌍이방성과 영(0)굴절률을 적용한 메타원자를 이용하여 넓게 퍼져 진행하는 파동을 회절한계보다 작은 도파로에 손실 없이 강하게 집속시켜 전달하는 것이 가능하다\n",
      "박남규 교수는 “메타 물질의 굴절 값을 자유자재로 변동시키는 게 힘들었다”면서 “메타물질의 물리적 특성 분리제어와 하향식 메타원자 설계가 특성 값 전 영역에 걸쳐서 구현 가능함을 증명했다”고 말했다\n",
      "37 번 Topic 문장 :\n",
      "국내 연구진에 의해 증강현실 아바타의 발판이 될 신기술이 개발됐다\n",
      "KAIST는 문화기술대학원 이성희 교수 연구팀이 사용자의 움직임을 재현하면서도 원격 공간의 차이를 인지해 바뀐 환경에 적응할 수 있는 증강현실 아바타 기술을 개발했다고 20일 밝혔다\n",
      "이성희 교수 연구팀은 사용자의 공간에는 식탁용 의자, 원격 공간에는 일인용 소파를 놓은 뒤 사용자가 식탁용 의자에 앉으면 아바타는 소파에 적합한 동작과 자세로 변형해 자리에 앉는 실험에 성공했다\n",
      "공간 대응관계를 이용한 증강현실 아바타의 동작 생성 기술은 주어진 공간 안에서 사용자의 움직임이 갖는 의미와 의도를 왜곡시키지 않고, 다른 공간에 있는 증강현실 아바타의 동작으로 재생성할 수 있다\n",
      "38 번 Topic 문장 :\n",
      "러시아와 유럽이 공동으로 진행하는 화성 생명체 탐사 프로젝트 ‘엑소마스(EXoMars)’의 화성 탐사 착륙선 ‘스키아파렐리’(Schiaparelli)가 화성에 터치다운을 앞두고 교신이 두절됐다\n",
      "유럽우주국(ESA)은 그리니치 표준시(GMT)로 19일 오후 2시 48분께 화성에 착륙할 예정이던 화성 탐사 착륙선 ‘스키아파렐리’와 ESA 간의 교신이 끊겨 안착 여부가 불투명하다고 이날 발표했다\n",
      "ESA는 스키아파렐리가 화성 탐사선을 구성한 궤도선인 ‘가스추적궤도선’(TGO)에서 성공적으로 분리된 후 화성 착륙을 앞두고 특정 지점에서 교신이 끊겼다고 밝혔다\n",
      "39 번 Topic 문장 :\n",
      "실험동물로 알려진 '아프리카발톱개구리(Xenopus laevis)'의 유전체를 UNIST(울산과학기술원) 교수가 포함된 국제 공동연구진이 해독했다\n",
      "UNIST 권태준 생명과학부 교수(울산=연합뉴스) UNIST는 권태준 생명과학부 교수가 제1 저자로 참여하고 미국, 일본 등 총 7개 나라 60명이 함께한 공동연구진은 아프리카발톱개구리의 4만여 개 유전자를 염색체 수준으로 규명해 '네이처(Nature)'에 발표했다고 20일 밝혔다\n",
      "권태준 생명과학부 교수가 제1 저자로 참여하고 미국, 일본 등 총 7개 나라 60명이 함께한 공동연구진은 아프리카발톱개구리의 4만여 개 유전자를 염색체 수준으로 규명해 '네이처(Nature)'에 발표했다\n",
      "권 교수는 \"합쳐지는 과정에서 모든 유전자가 살아남을지 사라질지 선택의 기로에 놓이게 된다\"며 \"아프리카발톱개구리는 신호전달, 대사, 구조 형성에 작용하는 유전자는 앞선 두 종의 것이 모두 유지됐고, 면역체계나 DNA 손상복구에 관여하는 유전자는 한쪽만 살아남은 것으로 확인됐다\"고 말했다\n",
      "40 번 Topic 문장 :\n",
      "17일 박남규 서울대 전기정보공학부 교수팀에 따르면 파동에너지를 자유롭게 제어할 수 있는 새로운 형태의 매질을 세계 최초로 개발해 국제학술지 '사이언스 어드밴시스'(Science Advances) 최신호에 발표했다\n",
      "연구진이 새로 개발한 매질은 파동에너지의 특성이 자유롭게 제어돼 원하는 형태의 파동을 전달하는 게 가능한 것으로 확인됐다\n",
      "이번 논문의 제1 저자인 유선규 서울대 박사는 \"질서와 무질서 네트워크의 중간 영역에 존재하는 새로운 매질을 개발했다\"며 \"만들기 쉽다는 무질서 매질의 장점과 효율이 높은 주기적 매질의 장점을 동시에 만족한다\"고 설명했다\n",
      "박남규 교수는 \"앞으로 광학, 반도체 분야에 적용할 수 있고, '투명망토' 같은 메타물질(자연계에 없는 성질을 가진 인공물질)의 개발에도 큰 도움을 줄 것\"이라고 전했다\n",
      "41 번 Topic 문장 :\n",
      "유전자 변이로 모습을 바꾼 암세포도 감쪽같이 타격하는 표적항암제를 만들 수 있는 기초 연구 성과가 국내에서 나왔다\n",
      "한국과학기술연구원(KIST)은 치매DTC융합연구단 김영수 박사팀이 뇌종양 세포의 표면에서 과발현하는 단백질인 'GRP78'이 암의 전이를 조절하는 기능이 있다는 사실을 규명했다고 13일 밝혔다\n",
      "이 때문에 이 GRP78을 '표적'으로 삼는 치료제를 만들면 유전자 변이로 암세포가 돌변해도 목표를 놓치지 않고 정밀 타격을 할 수 있다고 김 박사팀은 전했다\n",
      "연구진은 \"GRP78을 표적항암제로 억제하면 뇌종양 전이를 막고 암 치료도 되는 두 가지 효과가 나타나는 것으로 밝혀졌다\"며 \"향후 추가 연구를 통해 뇌종양 외에 다른 암에도 이번 성과를 적용할 수 있을 것으로 기대된다\"고 설명했다\n",
      "42 번 Topic 문장 :\n",
      "인공지능(AI) 알파고 개발자 데미스 하사비스 구글 딥마인드 최고경영자(CEO)가 이끄는 연구진이 신경망 컴퓨터와 외장 메모리만을 이용해 복잡한 지하철 노선에서 최단거리 찾기 같은 뇌의 추론 기능을 모방한 AI 기술을 개발했다\n",
      "구글 딥마인드는 신경망과 기존 컴퓨터의 장점을 결합해 아직은 초보적인 수준이지만 정확도가 높은 고차원적 추론이 가능한 하이브리드 기계학습 기술을 개발했다고 국제학술지 네이처 12일자에 발표했다\n",
      "최근 AI에서 주목받는 뇌 신경을 모방한 신경망 역시 기계학습을 통해 대규모 자료를 학습하고 이를 통해 특정한 패턴을 알아내는데 활용된다\n",
      "딥마인드 연구진은 학습이 가능한 신경망과 컴퓨터에 들어가는 외장 메모리를 이용해 이런 능력을 가진 ‘미분가능 신경컴퓨터(DNC)’라는 독특한 컴퓨터를 개발했다\n",
      "조성배 연세대 컴퓨터과학과 교수는 “일반 컴퓨터는 지하철 노선표를 보고 손쉽게 가장 빠른 경로를 찾아내지만 사람의 뇌를 모방한 신경망은 아직까지 스스로 이런 복잡한 문제를 풀지 못한다”며 “일반 연구자보다 훨씬 높은 정확도가 나온 건 구글의 막강한 컴퓨팅 능력이 뒷받침이 된 것 같다”고 말했다\n",
      "43 번 Topic 문장 :\n",
      "IT(정보기술) 기기와 전기차에 널리 쓰이는 리튬이온 배터리보다 최대 100배 더 빠르게 충전할 수 있는 차세대 전지 기술을 국내 연구진이 개발했다\n",
      "미래창조과학부는 한국과학기술원(KAIST) 신소재공학과 강정구 교수팀이 이런 '하이브리드' 에너지 저장장치 기술을 개발해 해당 성과를 유명 학술지인 '어드밴스드 에너지 매터리얼스' 최근호의 VIP(특급) 논문으로 발표했다고 10일 밝혔다\n",
      "이 전지는 에너지 저장밀도는 리튬이온 배터리의 1.5배이면서도 출력은 슈퍼커패시터를 웃도는 23KW/㎏에 달해, 리튬이온 방식보다 100배가량 빠르게 충전을 할 수 있다고 연구진은 설명했다\n",
      "44 번 Topic 문장 :\n",
      "국내 연구팀이 고인골에 대해 분석한 결과 칭기즈칸 부계 기원과 800년 동안 비밀에 싸여 있던 '몽골 여왕'의 비밀이 풀리는 단서를 제시했습니다\n",
      "몽골여왕은 칭기즈 칸 가계의 일원이라는 사실이 밝혀졌습니다\n",
      "국내 연구팀은 몽골 동부의 타반 톨고이(Tavan Tolgoi) 지역에서 발굴된 5체의 고인골의 고고인류학적 ·미토콘드리아 DNA 분석 등을 통해 몽골시대(12~13세기) 황족 일원일 가능성을 처음으로 제시했습니다\n",
      "방사성탄소연대 측정법을 통한 절대연대 분석 결과 5체의 고인골은 칭기즈칸 생존 전후의 칭기즈칸 가계(일명 황금씨족)의 일원일 가능성이 높은 것을 확인됐습니다\n",
      "3체의 남성 고인골에서 영국 등 유럽에서 가장 높은 빈도로 분포하는 R1b-M343 유형을 가지고 있다는 것은 칭기즈 칸의 가계를 역사적으로 거꾸로 거슬러 올라가면 유럽인의 피가 섞여 있다는 것을 의미합니다\n",
      "연구결과를 토대로 연구팀은 황금씨족과 동일한 R1b Y 하플로그룹을 가지고 있는 현대인은 러시아 칼미크인, 중국 회족, 우주베크인, 타지크인들인 것으로 밝혔습니다\n",
      "또 이들의 부계 자손들은 과거 칭기즈 칸의 아들과 손자들이 지배했던 황금군단, 차가타이 칸국, 원나라의 영토였던 현재의 러시아, 중앙아시아, 중국 등에 분포돼 있다는 사실을 나타낸다고 연구팀은 설명했습니다\n",
      "이광호 교수는 \"이번 연구 성과는 칭기즈 칸 가계에 대한 세계 최초의 분자고고학적 연구결과로 칭기즈 칸 계보의 새로운 패러다임을 제시했다\"며 \"고인골의 계보학적, 역사학적, 고고학적 연구 등에 중요한 미토콘드리아, Y와 염색체 DNA 분석 정보 등을 새롭게 제공함으로서 학술적 의미가 크다\"고 말했습니다\n",
      "45 번 Topic 문장 :\n",
      "매년 노벨상 발표 시즌이 되면 옆 나라 일본과 달리 과학 분야 노벨상을 내지 못하는 한국의 과학 현실을 비판하는 목소리가 터져 나온다\n",
      "초등학교, 중학교, 고등학교에 이르기까지 '정답'만을 찾아 문제를 푸는 방식에 익숙해진 학생에게 새로운 분야를 개척할 창의성이 나오기 힘들다는 지적이다\n",
      "서울대 자연과학대학은 학생들이 정형화된 문제 풀이 방식에서 벗어나 창의적인 생각을 할 수 있도록 수업 방식을 바꾸자는 취지로 교육개혁위원회를 꾸렸다고 10일 밝혔다\n",
      "자연대는 서울대 단과대학 중 처음으로 시험감독이 없는 상태에서 학생들이 양심에 따라 시험을 치르는 무감독시험과, 이를 위한 전제인 '아너 코드'(Honor code·명예규칙)를 준비해왔다\n",
      "김성근 자연대학장은 \"대학의 지식 문화가 개방적이고 토론을 두려워하지 않아야 독립적인 지식주체로서 자신만의 길을 만들어가는 연구자를 길러낼 수 있다\"며 \"자신만의 문제에 천착하는 '이탈자'를 만들어내는 교육을 하고 싶다\"고 밝혔다\n",
      "김 학장은 \"노벨상을 타기 위해서는 '기록경기'가 아니라서 얼마나 세계적으로 비슷한 수준에 도달했느냐보다 소신 있는 연구를 하는 것이 중요하다\"며 \"지적 호기심을 거침없이 드러내는 교육 환경을 만들다 보면 노벨상을 탈 만한 나라가 될 것으로 생각한다\"고 강조했다\n",
      "46 번 Topic 문장 :\n",
      "UNIST(울산과학기술원)은 번개가 치는 원리를 이용한 '인공 번개 마찰 전기 발전기'를 개발했다고 6일 밝혔다\n",
      "백정민 신소재공학부 교수와 미국 조지아공대(Georgia Tech), 성균관대, KIST(한국과학기술연구원), 경희대 공동연구팀은 번개 원리를 극대화할 수 있는 3층짜리 구조의 발전기를 만들었다\n",
      "마치 구름 속 수증기와 얼음 결정 사이에 새로운 물질을 넣어 마찰이 더 일어나도록 한 것이다\n",
      "47 번 Topic 문장 :\n",
      "찔러도 피 한방울 나지 않는 주삿바늘이 국내 연구진에 의해 개발됐다\n",
      "KAIST는 화학과 이해신 교수 연구팀이 홍합이 가진 접착 기능을 모방한 생체 재료를 이용해 출혈이 없는 주삿바늘 개발에 성공했다고 6일 밝혔다\n",
      "연구팀의 찔러도 피가 나지 않는 주삿바늘은 일반 주삿바늘에 지혈재료를 코팅해 주사 후에 상처부위를 물리적으로 막아 자발적으로 지혈할 수 있게 만드는 기술이다\n",
      "이해신 교수는 “개발된 기술은 모든 혈관 및 근육 주사에 효과를 보이고, 혈우병 모델에서도 효과적인 기능을 보이기 때문에 혈액 응고 장애가 있는 환자들에게 유용할 것”이라며 “카테터 및 생검바늘 등 다양한 침습 의료기기들과 결합해 새로운 기술의 발전이 가능할 것으로 기대된다”고 말했다\n",
      "48 번 Topic 문장 :\n",
      "올해 노벨화학상은 일상 세계의 기계 장치를 분자 세계에서 구현해 세상에서 가장 작은 기계를 만든 과학자들에게 돌아갔다\n",
      "스웨덴 왕립과학원 노벨위원회는 5일 장피에르 소바주 프랑스 스트라부르대 교수(72)와 프레이저 스토더트 미국 노스웨스턴대 교수(74), 베르나르트 페링하 네덜란드 흐로닝언대 교수(65) 등 세 사람을 올해 노벨화학상 수상자로 선정했다고 발표했다\n",
      "위원회는 이들이 에너지를 운동으로 변환하는 기계장치를 분자 크기에서 구현해 화학과 기계 분야의 새 지평을 마련했다고 평가했다\n",
      "김기문 포스텍 화학과 교수는 “카테난과 로택산은 스위치 기능을 할 수 있어 집적도의 한계에 이른 메모리 소자를 대체할 기술로 활용하거나 약물 전달 물질의 밸브로 이용하는 연구가 진행되고 있다”고 설명했다\n",
      "49 번 Topic 문장 :\n",
      "올해로 일본이 3년 연속 노벨생리의학상 등 그동안 총 22명의 노벨과학상 수상자를 배출하는 사이 한국은 116년 노벨상 역사상 과학 분야에서 한 명의 수상자도 배출하지 못했다\n",
      "연구개발(R&D) 투자 비중이 국내총생산(GDP) 대비 4.29%(86조원)로 세계 최고 수준인 우리나라로서는 근본적인 대책을 세워야 한다는 지적이 나온다\n",
      "연구예산이 증가해도 반도체·통신 등 정보기술(IT) 분야에만 매달릴 뿐 응용·첨단기술의 토양인 기초과학은 뒷전이라는 것이다\n",
      "유룡 교수는 “기초과학 투자를 늘리지 않고 노벨상을 바라는 것은 이미 20년 전 나온 AI 기술을 미리 키우지도 않고 당장 하겠다는 것과 같다”고 지적했다\n",
      "박배호 건국대 물리학과 교수는 “과도한 경쟁과 줄서기가 요구되는 상황에서 창의적이고 분야를 이끄는 연구를 수행하기 어렵다”며 “연구자들이 적절한 평가 및 선정 과정을 거쳐 다른 곳에 신경 쓸 필요없이 연구를 수행할 수 있는 생태계가 조성돼야 한다”고 강조했다\n",
      "윤종용 한국공학교육인증원 이사장(전 삼성전자 부회장)은 최근 서울경제신문과의 인터뷰에서 “우리나라 연구조직을 보면 여전히 연공서열과 학연을 따지고 연구 활동보다 정부의 프로젝트를 따기 위한 문서작업이나 공무원 응대에 더 많은 시간을 쏟는 것 같다”며 “단기성과 위주의 정량 평가는 연구자들의 자율성을 떨어뜨리고 사기를 저하시킨다”고 지적했다\n",
      "50 번 Topic 문장 :\n",
      "인류가 오늘날 지능을 갖게 된 것은 도구를 이용하면서부터다\n",
      "과학자들이 브라질 밀림에 사는 카푸친 원숭이가 돌을 깨서 망치를 만드는 모습을 세계에서 처음으로 관찰하는데 성공했다\n",
      "영국 옥스퍼드대와 런던대, 브라질 상파울루대 등 국제 공동 연구진은 브라질 세라다카피바라 국립공원에 사는 카푸친원숭이들이 구석기인처럼 돌을 깨서 석기를 만드는 것을 확인했다고 국제학술지 네이처 20일자에 발표했다\n",
      "연구진은 브라질 동부 피아우이주(州)의 카피바라 산지 일대의 면적 약 1000㎢에 이르는 산악지대에 자리하는 세라다 카피바라 국립공원에 사는 카푸친 원숭이들을 관찰하던 도중 이들이 규암처럼 단단한 돌을 골라 다른 돌을 내리친다는 사실을 발견했다\n",
      "원숭이들이 돌을 내려쳐 조각낸 돌에선 초기 원시 인류가 만든 석기처럼 한쪽에 날카로운 면이 있는 것으로 확인됐다\n",
      "연구진은 “원숭이들의 이런 행동은 인간이 도구를 만드는 행동과 같다는 결론을 내렸다”고 설명했다\n",
      "다만 이번 연구를 통해 반드시 도구를 만드는데 사람의 손이나 뇌가 필요하다는 건 아니라는 사실을 알게 됐다고 분석했다\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for i in range(1,51):\n",
    "  if i < 10:\n",
    "    file_path = '/home/lab01/sci-news-sum-kr-50/data/'+'0'+str(i)+'.json'\n",
    "  else:\n",
    "    file_path = '/home/lab01/sci-news-sum-kr-50/data/'+str(i)+'.json'\n",
    "\n",
    "\n",
    "  with open(file_path, 'r') as file:\n",
    "      data = json.load(file)\n",
    "      #print(i,'번 전문 :')\n",
    "      data_str = '\\n'.join(data['sentences'])\n",
    "      #print(data_str)\n",
    "\n",
    "      print(i,'번 Topic 문장 :')\n",
    "      for i in data['summaries']:   \n",
    "        print(data['sentences'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-choice",
   "metadata": {},
   "source": [
    "## 6. Performance (성능평가)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-graduate",
   "metadata": {},
   "source": [
    "### metric 1. Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-doctor",
   "metadata": {},
   "source": [
    "Rouge(Recall-Oriented Understudy for Gisting Evaluation)\n",
    "https://velog.io/@jochedda/Rouge-Score-Text-Summarization%EC%9D%98-%ED%8F%89%EA%B0%80%EC%A7%80%ED%91%9C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-headline",
   "metadata": {},
   "source": [
    "다시말해, Semantic하게 성능을 분석하기 위해서는 영어와 달리 단어의 순서를 비교하는 것이 적절한 지표가 되지 않을 수도 있다는 이야기.\n",
    "'순서'가 아닌 '조합'으로 성능을 판단할 수 있는 ROUGE-U, ROUGE-SU가 적절해보임\n",
    "RDASS 도 추가로 고려하여 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "monetary-forest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages (from rouge) (1.15.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "insured-brook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.5528035775713794,\n",
       "  'p': 0.8539562289562289,\n",
       "  'f': 0.6512670259900423},\n",
       " 'rouge-2': {'r': 0.3353174603174603,\n",
       "  'p': 0.5244559362206421,\n",
       "  'f': 0.3928074411537155},\n",
       " 'rouge-l': {'r': 0.5369305616983636,\n",
       "  'p': 0.8122895622895623,\n",
       "  'f': 0.6282785202429159}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "model_out = [\"he began by starting a five person war cabinet and included chamberlain as lord president of the council\",\n",
    "             \"the siege lasted from 250 to 241 bc, the romans laid siege to lilybaeum\",\n",
    "             \"the original ocean water was found in aquaculture\"]\n",
    "\n",
    "reference = [\"he began his premiership by forming a five-man war cabinet which included chamberlain as lord president of the council\",\n",
    "             \"the siege of lilybaeum lasted from 250 to 241 bc, as the roman army laid siege to the carthaginian-held sicilian city of lilybaeum\",\n",
    "             \"the original mission was for research into the uses of deep ocean water in ocean thermal energy conversion (otec) renewable energy production and in aquaculture\"]\n",
    "rouge = Rouge()\n",
    "rouge.get_scores(model_out, reference, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "recognized-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small model: {'rouge-1': {'r': 0.050505050505050504, 'p': 0.16666666666666666, 'f': 0.07751937627546439}, 'rouge-2': {'r': 0.0392156862745098, 'p': 0.13793103448275862, 'f': 0.06106869884272498}, 'rouge-l': {'r': 0.050505050505050504, 'p': 0.16666666666666666, 'f': 0.07751937627546439}}\n",
      "large model: {'rouge-1': {'r': 0.5656565656565656, 'p': 0.7368421052631579, 'f': 0.6399999950863674}, 'rouge-2': {'r': 0.5294117647058824, 'p': 0.6923076923076923, 'f': 0.5999999950888889}, 'rouge-l': {'r': 0.5656565656565656, 'p': 0.7368421052631579, 'f': 0.6399999950863674}}\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "small_model_out = ['지카바이러스는 태아에게 소두증을 유발한다고 알려진 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춘 연구들이 많았다 소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다 최근에는 미국, 동남아시아에서도 환자가 발생하고 있다']\n",
    "large_model_out = ['소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다 지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다 오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자 수와 성호르몬 수치도 정상에 비해 적었다.']\n",
    "reference = ['소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다 오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다 연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다']\n",
    "rouge = Rouge()\n",
    "\n",
    "print('small model:', rouge.get_scores(small_model_out, reference, avg=True))\n",
    "print('large model:',rouge.get_scores(large_model_out, reference, avg=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-lebanon",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1,51)\n",
    "\n",
    "plt.figure(figsize = (15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs, score, 'b-')\n",
    "plt.plot(epochs, score, 'r--')\n",
    "plt.title('ROUGE-1')\n",
    "plt.xlabel('Test Set')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs, score, 'b-')\n",
    "plt.plot(epochs, score, 'r--')\n",
    "plt.title('ROUGE-2')\n",
    "plt.xlabel('Test Set')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(['Test Set No', 'Score'])\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs, Hist_model.history['accuracy'], 'b-')\n",
    "plt.plot(epochs, Hist_model.history['val_accuracy'], 'r--')\n",
    "plt.title('Training & Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-lighting",
   "metadata": {},
   "source": [
    "### metric2. RDASS\n",
    "Reference and Document Aware Semantic Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-reynolds",
   "metadata": {},
   "source": [
    "https://kakaoenterprise.github.io/deepdive/210729#dfdf:fn:2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-avenue",
   "metadata": {},
   "source": [
    "### metric3. BLEU : 토큰형태, 하나 이상의 참조문장이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-tower",
   "metadata": {},
   "source": [
    "https://ko.linux-console.net/?p=6105#gsc.tab=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-angola",
   "metadata": {},
   "source": [
    "https://ko.linux-console.net/?p=6105#gsc.tab=0\n",
    "\n",
    "문장을 일치시키는 동안 모델이 한 번에 일치시킬 단어 수를 선택할 수 있습니다. 예를 들어 한 번에 하나씩(1그램) 일치하는 단어를 선택할 수 있습니다. 또는 쌍(2-그램) 또는 세 쌍(3-그램)의 단어를 일치시키도록 선택할 수도 있습니다.\n",
    "\n",
    "이 섹션에서는 이러한 n-gram 점수를 계산하는 방법을 배웁니다.\n",
    "\n",
    "sentence_bleu() 함수에서 개별 그램에 해당하는 가중치가 있는 인수를 전달할 수 있습니다.\n",
    "\n",
    "예를 들어 그램 점수를 개별적으로 계산하려면 다음 가중치를 사용할 수 있습니다.\n",
    "\n",
    "Individual 1-gram: (1, 0, 0, 0)\n",
    "Individual 2-gram: (0, 1, 0, 0). \n",
    "Individual 3-gram: (1, 0, 1, 0). \n",
    "Individual 4-gram: (0, 0, 0, 1). \n",
    "\n",
    "```\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [\n",
    "    'this is a dog'.split(),\n",
    "    'it is dog'.split(),\n",
    "    'dog it is'.split(),\n",
    "    'a dog, it is'.split() \n",
    "]\n",
    "candidate = 'it is a dog'.split()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-customs",
   "metadata": {},
   "source": [
    "http://incredible.ai/nlp/2020/02/29/BLEU/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coordinated-white",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ubuntu/anaconda3/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from nltk) (4.46.0)\n",
      "Requirement already satisfied: regex in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-baking",
   "metadata": {},
   "source": [
    "konlpy & mecab 설치 <br>\n",
    "https://yuddomack.tistory.com/entry/%EC%B2%98%EC%9D%8C%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-EC2-konlpy-mecab-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0ubuntu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-there",
   "metadata": {},
   "source": [
    "정상 설치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "important-wonder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('안녕', 'IC'), (',', 'SC'), ('테스', 'NNG'), ('트', 'VV'), ('야', 'EC')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "m = Mecab()\n",
    "m.pos(\"안녕, 테스트야\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "amended-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[mecab.morphs(str(topic))]  #reference = [[mecab.morphs(s) for s in topic]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-mexico",
   "metadata": {},
   "source": [
    "평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "gothic-radio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference: [[['소두증', '을', '유발', '한다고', '알려진', '지카', '바이러스', '가', '남성', '의', '생식', '능력', '도', '저하', '시킬', '수', '있', '다는', '동물', '실험', '결과', '가', '나왔', '다', '1', '일', '국제', '학술지', '네이처', '에', '따르', '면', '미', '워싱턴', '대', '의대', '연구', '진', '은', '수컷', '쥐', '가', '지카', '바이러스', '에', '감염', '되', '면', '고환', '크기', '가', '눈', '에', '띄', '게', '작아지', '며', '정자', '수', '가', '감소', '하', '고', ',', '성', '호르몬', '인', '테스토스테론', '의', '양', '도', '줄어든다는', '연구', '결과', '를', '발표', '했', '다', '오명돈', '서울대', '병원', '감염', '내', '과', '교수', '는', '“', '동물', '모델', '을', '이용해', '지카', '바이러스', '가', '정모', '세포', '(', '정자', '로', '성장', '하', '는', '세포', ')', ',', '정세', '관', '(', '정자', '가', '나오', '는', '작', '은', '튜브', ')', '세포', '손상', '을', '일으킨다는', '것', '과', '남성', '호르몬', '과', '정자', '수', ',', '고환', '크기', ',', '가임', '력', '을', '모두', '감소', '시킨다는', '것', '을', '구체', '적', '으로', '밝혔', '다', '”', '며', '“', '다만', '쥐', '실험', '이', '므로', '사람', '에게', '도', '그대로', '적용', '되', '는지', '는', '알', '수', '없', '다', '”', '고', '설명', '했', '다', '연구', '를', '진행', '한', '마이클', '다이아몬드', '교수', '도', '“', '수컷', '쥐', '에서', '확인', '된', '결과', '가', '사람', '에게', '도', '나타나', '는지', '는', '아직', '알', '지', '못한다', '”', '며', '“', '사람', '에게', '도', '같', '은', '영향', '이', '있', '는지', '를', '확인', '하', '기', '위해선', '추가', '연구', '가', '필요', '하', '다', '”', '고', '밝혔', '다']]]\n",
      "candidate: [['[', \"'\", '지카', '바이러스', '는', '태아', '에게', '소두증', '을', '유발', '한다고', '알려진', '지카', '바이러스', '가', '남성', '의', '생식', '기관', '에', '미치', '는', '영향', '에', '초점', '을', '맞춘', '연구', '들', '이', '많', '았', '다', '소두증', '은', '태아', '의', '뇌', '가', '다', '자라', '지', '않', '아', '머리', '가', '비', '정상', '적', '으로', '작아지', '는', '질환', '이', '다', '최근', '에', '는', '미국', ',', '동남아시아', '에서', '도', '환자', '가', '발생', '하', '고', '있', '다', \"']\"]]\n",
      "BLEU :  0.025\n",
      "Individual 1-gram :  0.076\n",
      "Individual 2-gram :  0.022\n",
      "Individual 3-gram :  0.016\n",
      "Individual 4-gram :  0.014\n",
      "4-gram cumulative BLEU :  0.025\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "#from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "mecab = Mecab()\n",
    "\n",
    "\n",
    "small_model_out = ['지카바이러스는 태아에게 소두증을 유발한다고 알려진 지카바이러스가 남성의 생식기관에 미치는 영향에 초점을 맞춘 연구들이 많았다 소두증은 태아의 뇌가 다 자라지 않아 머리가 비정상적으로 작아지는 질환이다 최근에는 미국, 동남아시아에서도 환자가 발생하고 있다']\n",
    "topic = ['소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다 오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자로 성장하는 세포), 정세관(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자수, 고환크기, 가임력을 모두 감소시킨다는 것을 구체적으로 밝혔다”며 “다만 쥐 실험이므로 사람에게도 그대로 적용되는지는 알 수 없다”고 설명했다 연구를 진행한 마이클 다이아몬드 교수도 “수컷 쥐에서 확인된 결과가 사람에게도 나타나는지는 아직 알지 못한다”며 “사람에게도 같은 영향이 있는지를 확인하기 위해선 추가 연구가 필요하다”고 밝혔다']\n",
    "large_model_out = ['소두증을 유발한다고 알려진 지카바이러스가 남성의 생식능력도 저하시킬 수 있다는 동물 실험 결과가 나왔다 1일 국제학술지 네이처에 따르면 미 워싱턴대 의대 연구진은 수컷 쥐가 지카바이러스에 감염되면 고환 크기가 눈에 띄게 작아지며 정자 수가 감소하고, 성 호르몬인 테스토스테론의 양도 줄어든다는 연구 결과를 발표했다 지금까지 지카바이러스는 태아에게 소두증을 일으킨다고 알려져 태아와 여성의 생식기관 감염에 초점을 맞춘 연구들이 많았다 오명돈 서울대병원 감염내과 교수는 “동물 모델을 이용해 지카바이러스가 정모세포(정자가 나오는 작은 튜브) 세포 손상을 일으킨다는 것과 남성호르몬과 정자 수와 성호르몬 수치도 정상에 비해 적었다.']\n",
    "\n",
    "\n",
    "candidate = [mecab.morphs(str(small_model_out))]\n",
    "reference = [[mecab.morphs(s) for s in topic]]\n",
    "\n",
    "print(f'reference: {reference}')\n",
    "print('candidate:', candidate)\n",
    "\n",
    "\n",
    "score = corpus_bleu(reference, candidate)\n",
    "score1 = corpus_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "score2 = corpus_bleu(reference, candidate, weights=(0, 1, 0, 0))\n",
    "score3 = corpus_bleu(reference, candidate, weights=(0, 0, 1, 0))\n",
    "score4 = corpus_bleu(reference, candidate, weights=(0, 0, 0, 1))\n",
    "score5 = corpus_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "#기본적으로 sentence_bleu() 함수는 BLEU-4라고도 하는 누적 4그램 BLEU 점수를 계산합니다. \n",
    "#이것이 n-gram 가중치를 추가하지 않고 얻은 정확한 점수입니다.\n",
    "\n",
    "\n",
    "print(\"BLEU : \", round(score,3))\n",
    "print(\"Individual 1-gram : \", round(score1,3))  \n",
    "print(\"Individual 2-gram : \", round(score2,3))  \n",
    "print(\"Individual 3-gram : \", round(score3,3))  \n",
    "print(\"Individual 4-gram : \", round(score4,3))  \n",
    "print(\"4-gram cumulative BLEU : \", round(score5,3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-audit",
   "metadata": {},
   "source": [
    "### metric4 . Human evalutaion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-contribution",
   "metadata": {},
   "source": [
    "## bibtex\n",
    "KE-T5를 이용하여 연구를 진행하실 경우 아래와 같이 인용해주시길 바랍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "@inproceedings{kim-etal-2021-model-cross,\n",
    "    title = \"A Model of Cross-Lingual Knowledge-Grounded Response Generation for Open-Domain Dialogue Systems\",\n",
    "    author = \"Kim, San  and\n",
    "      Jang, Jin Yea  and\n",
    "      Jung, Minyoung  and\n",
    "      Shin, Saim\",\n",
    "    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2021\",\n",
    "    month = nov,\n",
    "    year = \"2021\",\n",
    "    address = \"Punta Cana, Dominican Republic\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://aclanthology.org/2021.findings-emnlp.33\",\n",
    "    doi = \"10.18653/v1/2021.findings-emnlp.33\",\n",
    "    pages = \"352--365\",\n",
    "    abstract = \"Research on open-domain dialogue systems that allow free topics is challenging in the field of natural language processing (NLP). The performance of the dialogue system has been improved recently by the method utilizing dialogue-related knowledge; however, non-English dialogue systems suffer from reproducing the performance of English dialogue systems because securing knowledge in the same language with the dialogue system is relatively difficult. Through experiments with a Korean dialogue system, this paper proves that the performance of a non-English dialogue system can be improved by utilizing English knowledge, highlighting the system uses cross-lingual knowledge. For the experiments, we 1) constructed a Korean version of the Wizard of Wikipedia dataset, 2) built Korean-English T5 (KE-T5), a language model pre-trained with Korean and English corpus, and 3) developed a knowledge-grounded Korean dialogue model based on KE-T5. We observed the performance improvement in the open-domain Korean dialogue model even only English knowledge was given. The experimental results showed that the knowledge inherent in cross-lingual language models can be helpful for generating responses in open dialogue systems.\",\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "@misc{ke_t5,\n",
    "    author       = {KETI AIRC},\n",
    "    title        = {KE-T5: Korean English T5},\n",
    "    month        = mar,\n",
    "    year         = 2021,\n",
    "    url          = {https://github.com/AIRC-KETI/ke-t5}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-zealand",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jewish-fashion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KETI-AIR/ke-t5-large-newslike were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "model = AutoModel.from_pretrained(\"KETI-AIR/ke-t5-large-newslike\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KETI-AIR/ke-t5-large-newslike\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "turned-crystal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x7f6bf8a00860>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attached-inspiration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Model(\n",
       "  (shared): Embedding(64128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(64128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(64128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (gelu_act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "known-antibody",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1000,), dtype=int32, numpy=\n",
       " array([  677,  2668,  1567,  2668,    50,     7,    31, 63942, 27907,\n",
       "         4274,   116,   270, 19715,  9853,    22, 62850,    32, 54823,\n",
       "         4118,    26, 11867,   205,    18, 53942, 36743,  1007,  8156,\n",
       "        13180,    47, 48571,    12, 12345,  2421,  8321,   521,  9821,\n",
       "        47729,    11,  3832,    50,  3880,   131, 21635,  1883,  2370,\n",
       "         9853,    21, 26876,    25,  6128,    74,  8321,   521,  3183,\n",
       "          221,     7, 27824, 20609,   189, 32005, 16280, 57356,  1024,\n",
       "           48,   919,  9601,    57,  2353, 12345,  2421,  8321,   521,\n",
       "          268,    26,   497, 35332, 16555,    28, 30051,     8,   753,\n",
       "           18,    22, 10479,   369,   185,   201,  8321,   521,  9821,\n",
       "        35181,  2791,   379,    34,  4104, 33716,   753,    11, 26988,\n",
       "          560, 13127,    26,   497,   823,  1461, 10399,    11, 55839,\n",
       "           47, 11493,  8321,   521,  3183,   594,   741,   737,  8321,\n",
       "          521,   268,   286, 36205,    22,  2413, 15026,  2293,  6286,\n",
       "          463, 36205,    22,  7587,     7,    31, 63942, 44337, 52153,\n",
       "        35327, 37157,   737,  8321,   521,   882,  4351,    72,     4,\n",
       "            7,    31, 63942, 13330,  3008, 36522,    31, 40751,  8759,\n",
       "           19,   560,  8321,   521,  9821, 36205,    21, 16844,  8321,\n",
       "          521,  9821, 36205,    21,   299,   666,  3924,    45,  9815,\n",
       "           50,    47,  3880,    19,    95,   133,    63, 58014, 50522,\n",
       "         4677, 38907, 23028,    21, 41334,   323, 40920,   296, 10022,\n",
       "         7275,  3599,  8156, 15078,  2410,    33,   535, 11987,    17,\n",
       "           19, 62691,   182,  5019,   307,   307,   778,  4384,     9,\n",
       "           53,   303, 13127,    11, 15152,  2381, 17006,    83, 16563,\n",
       "           22,   329,   495,    30, 22307,    77,  4884,  9753,  1790,\n",
       "         3478, 17781, 11052, 22628,    42, 11028,  1508,     7, 23726,\n",
       "           24,  1816, 27692,  1956, 24966,   185,   152,  8493,   440,\n",
       "          160, 10140,   202,    83, 16563,  5518,   645,   132,  1007,\n",
       "          570, 12887,   164,    59,   347,   395, 17567,   423,    98,\n",
       "        12605, 15553,    50, 17781,  4185,    22, 19445,  3287,  2410,\n",
       "          161,  3880,   377, 20514,  6407,   323, 40920,   296, 10022,\n",
       "         7275,  3599,  8156, 15078,  2410,    42,   535, 11987,    24,\n",
       "           19,  1488,  1726,  1680,  7085, 24151,   630,   779, 21947,\n",
       "         2350, 22467, 11052, 38860,   129, 62691,   182,  5019,   307,\n",
       "          307,   778,  4384,     9, 12421,   303, 13127,    15, 36522,\n",
       "           26,   640,  2111,  2197,   291,   652,    18,    31, 53697,\n",
       "           26,   781, 20239, 12010,   637,   138, 40751,    26, 57830,\n",
       "         3560,  1820, 13127,    18,    49, 10028,  9355,     6, 22467,\n",
       "          447,   611, 30801,    36, 10022,    37, 12647, 28093, 10159,\n",
       "        13596, 17960,  4527,  7695,     6, 13127,    15, 40619,    11,\n",
       "         3946, 27988, 22467,   447,   611,    39,    25,   108,   631,\n",
       "         1009,   841, 45285,  4927,  3982,  2263,   415, 15399,  1516,\n",
       "        61127, 10677,  2709,  8448,  3085, 40176,    21, 15078,    33,\n",
       "         3066,   393,   427,   183,    17,   517,   278,  4001,  8683,\n",
       "         3599,  5451,  3404,  1009,   841,    56,   741,    25,   214,\n",
       "          857,  4927,  3982,  2263,   415,  2859,  1516, 61127, 10677,\n",
       "           37,  8448,  6269,  3085,     6,  6992, 11078,   107, 15152,\n",
       "         2381,  8448,  3085, 40176, 12680, 20714,  7085, 32815,   883,\n",
       "        20129, 29268,  1082,     6, 40933,    42,  1691,  1351,    24,\n",
       "            9, 10793,   152,  2161, 10427,  4861, 46115, 22747,    12,\n",
       "         5443,  3249,   769,     1,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0], dtype=int32)>,\n",
       " 'attention_mask': <tf.Tensor: shape=(1000,), dtype=int32, numpy=\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'decoder_input_ids': <tf.Tensor: shape=(1000,), dtype=int32, numpy=\n",
       " array([21635,  1883,  2370,  9853,    21, 26876,    25,  6128,    74,\n",
       "         8321,   521,  3183,   221,     7, 27824, 20609,   189, 32005,\n",
       "        16280, 57356,  1024,    48,   919,  9601,    57,  2353, 12345,\n",
       "         2421,  8321,   521,   268,    26,   497, 35332, 16555,    28,\n",
       "        30051,     8,   753,    18,    22, 10479,   369,   185,   201,\n",
       "         8321,   521,  9821, 35181,  2791,   379,    34,  4104, 33716,\n",
       "          753,    11, 26988,   560, 13127,    26,   497,   823,  1461,\n",
       "        10399,    11, 55839,    47, 11493,  8321,   521,  3183,   594,\n",
       "          741,   737,  8321,   521,   268,   286, 36205,    22,  2413,\n",
       "        15026,  2293,  6286,   463, 24966,   185,   152,  8493,   440,\n",
       "          160, 10140,   202,    83, 16563,  5518,   645,   132,  1007,\n",
       "          570, 12887,   164,    59,   347,   395, 17567,   423,    98,\n",
       "        12605, 15553,    50, 17781,  4185,    22, 19445,  3287,  2410,\n",
       "          161,  3880,   377, 20514,  6407,     1,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0], dtype=int32)>,\n",
       " 'decoder_attention_mask': <tf.Tensor: shape=(1000,), dtype=int32, numpy=\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       " 'decoder_target_ids': <tf.Tensor: shape=(999,), dtype=int32, numpy=\n",
       " array([ 1883,  2370,  9853,    21, 26876,    25,  6128,    74,  8321,\n",
       "          521,  3183,   221,     7, 27824, 20609,   189, 32005, 16280,\n",
       "        57356,  1024,    48,   919,  9601,    57,  2353, 12345,  2421,\n",
       "         8321,   521,   268,    26,   497, 35332, 16555,    28, 30051,\n",
       "            8,   753,    18,    22, 10479,   369,   185,   201,  8321,\n",
       "          521,  9821, 35181,  2791,   379,    34,  4104, 33716,   753,\n",
       "           11, 26988,   560, 13127,    26,   497,   823,  1461, 10399,\n",
       "           11, 55839,    47, 11493,  8321,   521,  3183,   594,   741,\n",
       "          737,  8321,   521,   268,   286, 36205,    22,  2413, 15026,\n",
       "         2293,  6286,   463, 24966,   185,   152,  8493,   440,   160,\n",
       "        10140,   202,    83, 16563,  5518,   645,   132,  1007,   570,\n",
       "        12887,   164,    59,   347,   395, 17567,   423,    98, 12605,\n",
       "        15553,    50, 17781,  4185,    22, 19445,  3287,  2410,   161,\n",
       "         3880,   377, 20514,  6407,     1,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       dtype=int32)>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prerequisite-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (relative_attention_bias): Embedding(32, 16)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 1: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 2: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 3: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 4: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 5: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 6: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 7: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 8: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 9: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 10: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 11: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 12: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 13: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 14: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 15: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 16: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 17: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 18: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 19: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 20: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 21: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 22: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 23: T5Block(\n",
      "  (layer): ModuleList(\n",
      "    (0): T5LayerSelfAttention(\n",
      "      (SelfAttention): T5Attention(\n",
      "        (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): T5LayerFF(\n",
      "      (DenseReluDense): T5DenseGatedGeluDense(\n",
      "        (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "        (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (gelu_act): NewGELUActivation()\n",
      "      )\n",
      "      (layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.encoder.block):\n",
    "    print(f\"Layer {i}: {layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "casual-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(model.encoder.block))\n",
    "print(len(model.decoder.block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hydraulic-colors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.0.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.1.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.1.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.2.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.2.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.3.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.3.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.4.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.4.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.5.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.5.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.6.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.6.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.7.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.7.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.8.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.8.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.8.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.8.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.8.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.8.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.8.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.9.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.9.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.9.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.9.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.9.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.9.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.9.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.10.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.10.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.10.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.10.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.10.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.10.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.10.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.11.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.11.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.11.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.11.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.11.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.11.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.11.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.12.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.12.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.12.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.12.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.12.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.12.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.12.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.12.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.12.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.13.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.13.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.13.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.13.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.13.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.13.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.13.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.13.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.13.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.14.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.14.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.14.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.14.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.14.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.14.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.14.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.14.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.14.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.15.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.15.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.15.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.15.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.15.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.15.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.15.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.15.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.15.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.16.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.16.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.16.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.16.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.16.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.16.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.16.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.16.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.16.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.17.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.17.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.17.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.17.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.17.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.17.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.17.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.17.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.17.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.18.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.18.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.18.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.18.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.18.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.18.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.18.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.18.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.18.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.19.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.19.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.19.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.19.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.19.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.19.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.19.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.19.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.19.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.20.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.20.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.20.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.20.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.20.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.20.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.20.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.20.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.20.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.21.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.21.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.21.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.21.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.21.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.21.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.21.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.21.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.21.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.22.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.22.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.22.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.22.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.22.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.22.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.22.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.22.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.22.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.23.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "encoder.block.23.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "encoder.block.23.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "encoder.block.23.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "encoder.block.23.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.block.23.layer.1.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "encoder.block.23.layer.1.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "encoder.block.23.layer.1.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "encoder.block.23.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "encoder.final_layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.0.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.1.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.2.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.3.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.4.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.5.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.6.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.7.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.8.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.9.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.10.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.11.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.12.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.13.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.14.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.15.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.16.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.17.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.18.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.19.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.20.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.21.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.22.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.0.SelfAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.0.SelfAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.0.SelfAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.0.SelfAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.0.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.1.EncDecAttention.q.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.1.EncDecAttention.k.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.1.EncDecAttention.v.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.1.EncDecAttention.o.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.1.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.2.DenseReluDense.wi_0.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.2.DenseReluDense.wi_1.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.2.DenseReluDense.wo.weight은(는) 학습 가능합니다\n",
      "decoder.block.23.layer.2.layer_norm.weight은(는) 학습 가능합니다\n",
      "decoder.final_layer_norm.weight은(는) 학습 가능합니다\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}은(는) 학습 가능합니다\")\n",
    "    else:\n",
    "        print(f\"{name}은(는) 학습 불가능합니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "qualified-projection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f621ced0db0>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
